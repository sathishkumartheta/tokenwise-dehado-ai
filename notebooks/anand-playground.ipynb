{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ae87c5",
   "metadata": {},
   "source": [
    "<H4># GPU Config for local workstation<H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a1332a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow =>  2.10.0\n",
      "Keras      =>  2.10.0\n",
      "Numpy      =>  1.25.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf### models\n",
    "import numpy as np### math computations\n",
    "print('Tensorflow => ',tf.__version__)\n",
    "print('Keras      => ',tf.keras.__version__)\n",
    "print('Numpy      => ',np.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83753330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "tf_device='/gpu:1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de1e1f",
   "metadata": {},
   "source": [
    "<H4># Yolo Pre-processing to detect bounding boxes for handwritten texts from dataset<H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3dc17e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (8.3.138)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from ultralytics) (1.25.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from ultralytics) (3.9.1.post1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from ultralytics) (2.7.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from ultralytics) (0.22.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from ultralytics) (1.2.4)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (6.4.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2ff3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "934a935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "MODEL_PATH = 'best_yolov8s.pt' # Use a trained handwritten region detection model if available or use the default one given by Challenge organizers\n",
    "IMAGE_DIR = 'D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750'\n",
    "RESULT_DIR = 'results6'\n",
    "LABEL_DIR = os.path.join(RESULT_DIR, 'labels')\n",
    "CONFIDENCE_THRESHOLD = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b98386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PREPARE DIRECTORIES ---\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "os.makedirs(LABEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7353508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LOAD MODEL ---\n",
    "model = YOLO(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "72bf604d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb9f981b7bf40e8a0b05e46980df1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing images:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_1.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_1.jpg: 640x480 21 handwrittens, 154.1ms\n",
      "Speed: 2.0ms preprocess, 154.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_1.jpg\n",
      "Saved labels to: results6\\labels\\MIT_1.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_10.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_10.jpg: 640x480 24 handwrittens, 100.5ms\n",
      "Speed: 2.2ms preprocess, 100.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_10.jpg\n",
      "Saved labels to: results6\\labels\\MIT_10.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_100.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_100.jpg: 640x480 20 handwrittens, 101.3ms\n",
      "Speed: 2.9ms preprocess, 101.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_100.jpg\n",
      "Saved labels to: results6\\labels\\MIT_100.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_101.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_101.jpg: 640x480 20 handwrittens, 91.5ms\n",
      "Speed: 3.0ms preprocess, 91.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_101.jpg\n",
      "Saved labels to: results6\\labels\\MIT_101.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_102.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_102.jpg: 640x480 28 handwrittens, 88.2ms\n",
      "Speed: 2.9ms preprocess, 88.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_102.jpg\n",
      "Saved labels to: results6\\labels\\MIT_102.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_103.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_103.jpg: 640x480 22 handwrittens, 130.6ms\n",
      "Speed: 3.0ms preprocess, 130.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_103.jpg\n",
      "Saved labels to: results6\\labels\\MIT_103.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_104.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_104.jpg: 640x480 23 handwrittens, 93.4ms\n",
      "Speed: 2.9ms preprocess, 93.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_104.jpg\n",
      "Saved labels to: results6\\labels\\MIT_104.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_105.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_105.jpg: 640x480 25 handwrittens, 98.0ms\n",
      "Speed: 2.8ms preprocess, 98.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_105.jpg\n",
      "Saved labels to: results6\\labels\\MIT_105.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_106.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_106.jpg: 640x480 22 handwrittens, 90.2ms\n",
      "Speed: 1.8ms preprocess, 90.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_106.jpg\n",
      "Saved labels to: results6\\labels\\MIT_106.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_107.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_107.jpg: 640x480 20 handwrittens, 83.3ms\n",
      "Speed: 3.2ms preprocess, 83.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_107.jpg\n",
      "Saved labels to: results6\\labels\\MIT_107.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_108.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_108.jpg: 640x480 21 handwrittens, 95.5ms\n",
      "Speed: 3.0ms preprocess, 95.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_108.jpg\n",
      "Saved labels to: results6\\labels\\MIT_108.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_109.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_109.jpg: 640x480 23 handwrittens, 92.6ms\n",
      "Speed: 3.0ms preprocess, 92.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_109.jpg\n",
      "Saved labels to: results6\\labels\\MIT_109.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_11.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_11.jpg: 640x480 23 handwrittens, 142.0ms\n",
      "Speed: 3.7ms preprocess, 142.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_11.jpg\n",
      "Saved labels to: results6\\labels\\MIT_11.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_110.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_110.jpg: 640x480 26 handwrittens, 103.8ms\n",
      "Speed: 3.5ms preprocess, 103.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_110.jpg\n",
      "Saved labels to: results6\\labels\\MIT_110.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_111.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_111.jpg: 640x480 20 handwrittens, 93.5ms\n",
      "Speed: 2.3ms preprocess, 93.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_111.jpg\n",
      "Saved labels to: results6\\labels\\MIT_111.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_112.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_112.jpg: 640x480 21 handwrittens, 91.3ms\n",
      "Speed: 2.6ms preprocess, 91.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_112.jpg\n",
      "Saved labels to: results6\\labels\\MIT_112.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_113.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_113.jpg: 640x480 22 handwrittens, 139.9ms\n",
      "Speed: 3.5ms preprocess, 139.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_113.jpg\n",
      "Saved labels to: results6\\labels\\MIT_113.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_114.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_114.jpg: 640x480 29 handwrittens, 124.9ms\n",
      "Speed: 3.1ms preprocess, 124.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_114.jpg\n",
      "Saved labels to: results6\\labels\\MIT_114.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_115.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_115.jpg: 640x480 25 handwrittens, 124.7ms\n",
      "Speed: 3.2ms preprocess, 124.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_115.jpg\n",
      "Saved labels to: results6\\labels\\MIT_115.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_116.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_116.jpg: 640x480 23 handwrittens, 104.6ms\n",
      "Speed: 2.7ms preprocess, 104.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_116.jpg\n",
      "Saved labels to: results6\\labels\\MIT_116.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_117.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_117.jpg: 640x480 21 handwrittens, 113.4ms\n",
      "Speed: 3.1ms preprocess, 113.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_117.jpg\n",
      "Saved labels to: results6\\labels\\MIT_117.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_118.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_118.jpg: 640x480 25 handwrittens, 109.0ms\n",
      "Speed: 3.2ms preprocess, 109.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_118.jpg\n",
      "Saved labels to: results6\\labels\\MIT_118.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_119.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_119.jpg: 640x480 20 handwrittens, 119.9ms\n",
      "Speed: 2.2ms preprocess, 119.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_119.jpg\n",
      "Saved labels to: results6\\labels\\MIT_119.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_12.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_12.jpg: 640x480 21 handwrittens, 101.6ms\n",
      "Speed: 3.7ms preprocess, 101.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_12.jpg\n",
      "Saved labels to: results6\\labels\\MIT_12.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_120.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_120.jpg: 640x480 22 handwrittens, 90.7ms\n",
      "Speed: 2.9ms preprocess, 90.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_120.jpg\n",
      "Saved labels to: results6\\labels\\MIT_120.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_121.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_121.jpg: 640x480 21 handwrittens, 89.7ms\n",
      "Speed: 1.9ms preprocess, 89.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_121.jpg\n",
      "Saved labels to: results6\\labels\\MIT_121.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_122.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_122.jpg: 640x480 22 handwrittens, 90.1ms\n",
      "Speed: 2.2ms preprocess, 90.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_122.jpg\n",
      "Saved labels to: results6\\labels\\MIT_122.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_123.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_123.jpg: 640x480 20 handwrittens, 100.2ms\n",
      "Speed: 2.3ms preprocess, 100.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_123.jpg\n",
      "Saved labels to: results6\\labels\\MIT_123.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_124.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_124.jpg: 640x480 20 handwrittens, 91.5ms\n",
      "Speed: 2.1ms preprocess, 91.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_124.jpg\n",
      "Saved labels to: results6\\labels\\MIT_124.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_125.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_125.jpg: 640x480 21 handwrittens, 87.6ms\n",
      "Speed: 2.1ms preprocess, 87.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_125.jpg\n",
      "Saved labels to: results6\\labels\\MIT_125.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_126.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_126.jpg: 640x480 22 handwrittens, 86.8ms\n",
      "Speed: 1.8ms preprocess, 86.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_126.jpg\n",
      "Saved labels to: results6\\labels\\MIT_126.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_127.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_127.jpg: 640x480 22 handwrittens, 92.7ms\n",
      "Speed: 1.9ms preprocess, 92.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_127.jpg\n",
      "Saved labels to: results6\\labels\\MIT_127.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_128.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_128.jpg: 640x480 24 handwrittens, 114.3ms\n",
      "Speed: 4.5ms preprocess, 114.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_128.jpg\n",
      "Saved labels to: results6\\labels\\MIT_128.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_129.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_129.jpg: 640x480 21 handwrittens, 108.6ms\n",
      "Speed: 3.1ms preprocess, 108.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_129.jpg\n",
      "Saved labels to: results6\\labels\\MIT_129.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_13.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_13.jpg: 640x480 21 handwrittens, 128.0ms\n",
      "Speed: 3.1ms preprocess, 128.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_13.jpg\n",
      "Saved labels to: results6\\labels\\MIT_13.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_130.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_130.jpg: 640x480 23 handwrittens, 100.9ms\n",
      "Speed: 2.6ms preprocess, 100.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_130.jpg\n",
      "Saved labels to: results6\\labels\\MIT_130.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_131.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_131.jpg: 640x480 22 handwrittens, 119.5ms\n",
      "Speed: 2.8ms preprocess, 119.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_131.jpg\n",
      "Saved labels to: results6\\labels\\MIT_131.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_132.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_132.jpg: 640x480 21 handwrittens, 97.4ms\n",
      "Speed: 3.0ms preprocess, 97.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_132.jpg\n",
      "Saved labels to: results6\\labels\\MIT_132.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_133.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_133.jpg: 640x480 20 handwrittens, 114.0ms\n",
      "Speed: 3.0ms preprocess, 114.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_133.jpg\n",
      "Saved labels to: results6\\labels\\MIT_133.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_134.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_134.jpg: 640x480 22 handwrittens, 133.8ms\n",
      "Speed: 9.5ms preprocess, 133.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_134.jpg\n",
      "Saved labels to: results6\\labels\\MIT_134.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_135.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_135.jpg: 640x480 20 handwrittens, 96.0ms\n",
      "Speed: 3.4ms preprocess, 96.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_135.jpg\n",
      "Saved labels to: results6\\labels\\MIT_135.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_136.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_136.jpg: 640x480 20 handwrittens, 100.1ms\n",
      "Speed: 1.9ms preprocess, 100.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_136.jpg\n",
      "Saved labels to: results6\\labels\\MIT_136.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_137.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_137.jpg: 640x480 21 handwrittens, 103.2ms\n",
      "Speed: 3.0ms preprocess, 103.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_137.jpg\n",
      "Saved labels to: results6\\labels\\MIT_137.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_138.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_138.jpg: 640x480 22 handwrittens, 113.7ms\n",
      "Speed: 3.1ms preprocess, 113.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_138.jpg\n",
      "Saved labels to: results6\\labels\\MIT_138.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_139.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_139.jpg: 640x480 22 handwrittens, 96.2ms\n",
      "Speed: 3.1ms preprocess, 96.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_139.jpg\n",
      "Saved labels to: results6\\labels\\MIT_139.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_14.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_14.jpg: 640x480 26 handwrittens, 105.7ms\n",
      "Speed: 2.8ms preprocess, 105.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_14.jpg\n",
      "Saved labels to: results6\\labels\\MIT_14.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_140.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_140.jpg: 640x480 20 handwrittens, 116.9ms\n",
      "Speed: 8.6ms preprocess, 116.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_140.jpg\n",
      "Saved labels to: results6\\labels\\MIT_140.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_141.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_141.jpg: 640x480 24 handwrittens, 97.7ms\n",
      "Speed: 2.6ms preprocess, 97.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_141.jpg\n",
      "Saved labels to: results6\\labels\\MIT_141.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_142.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_142.jpg: 640x480 25 handwrittens, 101.1ms\n",
      "Speed: 3.5ms preprocess, 101.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_142.jpg\n",
      "Saved labels to: results6\\labels\\MIT_142.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_143.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_143.jpg: 640x480 22 handwrittens, 87.6ms\n",
      "Speed: 2.1ms preprocess, 87.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_143.jpg\n",
      "Saved labels to: results6\\labels\\MIT_143.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_144.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_144.jpg: 640x480 20 handwrittens, 99.6ms\n",
      "Speed: 3.3ms preprocess, 99.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_144.jpg\n",
      "Saved labels to: results6\\labels\\MIT_144.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_145.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_145.jpg: 640x480 22 handwrittens, 89.6ms\n",
      "Speed: 3.0ms preprocess, 89.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_145.jpg\n",
      "Saved labels to: results6\\labels\\MIT_145.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_146.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_146.jpg: 640x480 20 handwrittens, 88.2ms\n",
      "Speed: 3.1ms preprocess, 88.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_146.jpg\n",
      "Saved labels to: results6\\labels\\MIT_146.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_147.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_147.jpg: 640x480 23 handwrittens, 216.5ms\n",
      "Speed: 4.6ms preprocess, 216.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_147.jpg\n",
      "Saved labels to: results6\\labels\\MIT_147.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_148.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_148.jpg: 640x480 21 handwrittens, 131.5ms\n",
      "Speed: 3.2ms preprocess, 131.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_148.jpg\n",
      "Saved labels to: results6\\labels\\MIT_148.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_149.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_149.jpg: 640x480 21 handwrittens, 93.4ms\n",
      "Speed: 3.7ms preprocess, 93.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_149.jpg\n",
      "Saved labels to: results6\\labels\\MIT_149.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_15.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_15.jpg: 640x480 23 handwrittens, 111.8ms\n",
      "Speed: 2.8ms preprocess, 111.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_15.jpg\n",
      "Saved labels to: results6\\labels\\MIT_15.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_150.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_150.jpg: 640x480 25 handwrittens, 119.5ms\n",
      "Speed: 3.0ms preprocess, 119.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_150.jpg\n",
      "Saved labels to: results6\\labels\\MIT_150.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_151.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_151.jpg: 640x480 25 handwrittens, 109.3ms\n",
      "Speed: 3.5ms preprocess, 109.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_151.jpg\n",
      "Saved labels to: results6\\labels\\MIT_151.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_152.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_152.jpg: 640x480 20 handwrittens, 106.6ms\n",
      "Speed: 3.0ms preprocess, 106.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_152.jpg\n",
      "Saved labels to: results6\\labels\\MIT_152.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_153.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_153.jpg: 640x480 19 handwrittens, 157.5ms\n",
      "Speed: 4.0ms preprocess, 157.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_153.jpg\n",
      "Saved labels to: results6\\labels\\MIT_153.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_154.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_154.jpg: 640x480 22 handwrittens, 91.7ms\n",
      "Speed: 2.0ms preprocess, 91.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_154.jpg\n",
      "Saved labels to: results6\\labels\\MIT_154.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_155.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_155.jpg: 640x480 21 handwrittens, 102.9ms\n",
      "Speed: 2.3ms preprocess, 102.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_155.jpg\n",
      "Saved labels to: results6\\labels\\MIT_155.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_156.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_156.jpg: 640x480 22 handwrittens, 108.2ms\n",
      "Speed: 2.9ms preprocess, 108.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_156.jpg\n",
      "Saved labels to: results6\\labels\\MIT_156.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_157.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_157.jpg: 640x480 20 handwrittens, 107.3ms\n",
      "Speed: 3.4ms preprocess, 107.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_157.jpg\n",
      "Saved labels to: results6\\labels\\MIT_157.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_158.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_158.jpg: 640x480 20 handwrittens, 102.4ms\n",
      "Speed: 3.2ms preprocess, 102.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_158.jpg\n",
      "Saved labels to: results6\\labels\\MIT_158.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_159.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_159.jpg: 640x480 19 handwrittens, 97.5ms\n",
      "Speed: 3.0ms preprocess, 97.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_159.jpg\n",
      "Saved labels to: results6\\labels\\MIT_159.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_16.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_16.jpg: 640x480 21 handwrittens, 179.8ms\n",
      "Speed: 3.5ms preprocess, 179.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_16.jpg\n",
      "Saved labels to: results6\\labels\\MIT_16.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_160.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_160.jpg: 640x480 22 handwrittens, 103.2ms\n",
      "Speed: 3.0ms preprocess, 103.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_160.jpg\n",
      "Saved labels to: results6\\labels\\MIT_160.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_161.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_161.jpg: 640x480 20 handwrittens, 104.9ms\n",
      "Speed: 2.0ms preprocess, 104.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_161.jpg\n",
      "Saved labels to: results6\\labels\\MIT_161.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_162.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_162.jpg: 640x480 24 handwrittens, 100.2ms\n",
      "Speed: 2.3ms preprocess, 100.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_162.jpg\n",
      "Saved labels to: results6\\labels\\MIT_162.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_163.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_163.jpg: 640x480 23 handwrittens, 157.6ms\n",
      "Speed: 3.5ms preprocess, 157.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_163.jpg\n",
      "Saved labels to: results6\\labels\\MIT_163.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_164.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_164.jpg: 640x480 23 handwrittens, 289.1ms\n",
      "Speed: 3.2ms preprocess, 289.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_164.jpg\n",
      "Saved labels to: results6\\labels\\MIT_164.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_165.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_165.jpg: 640x480 23 handwrittens, 115.3ms\n",
      "Speed: 4.2ms preprocess, 115.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_165.jpg\n",
      "Saved labels to: results6\\labels\\MIT_165.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_166.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_166.jpg: 640x480 25 handwrittens, 137.6ms\n",
      "Speed: 3.3ms preprocess, 137.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_166.jpg\n",
      "Saved labels to: results6\\labels\\MIT_166.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_167.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_167.jpg: 640x480 23 handwrittens, 121.7ms\n",
      "Speed: 3.3ms preprocess, 121.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_167.jpg\n",
      "Saved labels to: results6\\labels\\MIT_167.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_168.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_168.jpg: 640x480 22 handwrittens, 356.8ms\n",
      "Speed: 5.0ms preprocess, 356.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_168.jpg\n",
      "Saved labels to: results6\\labels\\MIT_168.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_169.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_169.jpg: 640x480 21 handwrittens, 153.7ms\n",
      "Speed: 4.0ms preprocess, 153.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_169.jpg\n",
      "Saved labels to: results6\\labels\\MIT_169.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_17.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_17.jpg: 640x480 21 handwrittens, 370.3ms\n",
      "Speed: 5.7ms preprocess, 370.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_17.jpg\n",
      "Saved labels to: results6\\labels\\MIT_17.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_170.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_170.jpg: 640x480 26 handwrittens, 103.6ms\n",
      "Speed: 2.3ms preprocess, 103.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_170.jpg\n",
      "Saved labels to: results6\\labels\\MIT_170.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_171.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_171.jpg: 640x480 21 handwrittens, 119.8ms\n",
      "Speed: 2.8ms preprocess, 119.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_171.jpg\n",
      "Saved labels to: results6\\labels\\MIT_171.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_172.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_172.jpg: 640x480 21 handwrittens, 205.3ms\n",
      "Speed: 3.6ms preprocess, 205.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_172.jpg\n",
      "Saved labels to: results6\\labels\\MIT_172.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_173.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_173.jpg: 640x480 22 handwrittens, 136.7ms\n",
      "Speed: 3.2ms preprocess, 136.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_173.jpg\n",
      "Saved labels to: results6\\labels\\MIT_173.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_174.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_174.jpg: 640x480 24 handwrittens, 140.2ms\n",
      "Speed: 4.0ms preprocess, 140.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_174.jpg\n",
      "Saved labels to: results6\\labels\\MIT_174.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_175.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_175.jpg: 640x480 25 handwrittens, 130.5ms\n",
      "Speed: 3.2ms preprocess, 130.5ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_175.jpg\n",
      "Saved labels to: results6\\labels\\MIT_175.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_176.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_176.jpg: 640x480 22 handwrittens, 207.0ms\n",
      "Speed: 3.0ms preprocess, 207.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_176.jpg\n",
      "Saved labels to: results6\\labels\\MIT_176.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_177.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_177.jpg: 640x480 22 handwrittens, 135.7ms\n",
      "Speed: 5.2ms preprocess, 135.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_177.jpg\n",
      "Saved labels to: results6\\labels\\MIT_177.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_178.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_178.jpg: 640x480 24 handwrittens, 103.1ms\n",
      "Speed: 3.6ms preprocess, 103.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_178.jpg\n",
      "Saved labels to: results6\\labels\\MIT_178.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_179.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_179.jpg: 640x480 22 handwrittens, 100.4ms\n",
      "Speed: 3.0ms preprocess, 100.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_179.jpg\n",
      "Saved labels to: results6\\labels\\MIT_179.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_18.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_18.jpg: 640x480 25 handwrittens, 109.3ms\n",
      "Speed: 1.9ms preprocess, 109.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_18.jpg\n",
      "Saved labels to: results6\\labels\\MIT_18.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_180.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_180.jpg: 640x480 22 handwrittens, 105.3ms\n",
      "Speed: 3.1ms preprocess, 105.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_180.jpg\n",
      "Saved labels to: results6\\labels\\MIT_180.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_181.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_181.jpg: 640x480 23 handwrittens, 127.5ms\n",
      "Speed: 2.4ms preprocess, 127.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_181.jpg\n",
      "Saved labels to: results6\\labels\\MIT_181.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_182.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_182.jpg: 640x480 27 handwrittens, 100.4ms\n",
      "Speed: 2.7ms preprocess, 100.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_182.jpg\n",
      "Saved labels to: results6\\labels\\MIT_182.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_183.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_183.jpg: 640x480 23 handwrittens, 94.6ms\n",
      "Speed: 2.1ms preprocess, 94.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_183.jpg\n",
      "Saved labels to: results6\\labels\\MIT_183.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_184.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_184.jpg: 640x480 21 handwrittens, 131.2ms\n",
      "Speed: 3.2ms preprocess, 131.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_184.jpg\n",
      "Saved labels to: results6\\labels\\MIT_184.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_185.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_185.jpg: 640x480 24 handwrittens, 116.4ms\n",
      "Speed: 3.1ms preprocess, 116.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_185.jpg\n",
      "Saved labels to: results6\\labels\\MIT_185.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_186.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_186.jpg: 640x480 22 handwrittens, 130.5ms\n",
      "Speed: 2.0ms preprocess, 130.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_186.jpg\n",
      "Saved labels to: results6\\labels\\MIT_186.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_187.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_187.jpg: 640x480 25 handwrittens, 106.8ms\n",
      "Speed: 2.2ms preprocess, 106.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_187.jpg\n",
      "Saved labels to: results6\\labels\\MIT_187.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_188.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_188.jpg: 640x480 21 handwrittens, 146.2ms\n",
      "Speed: 3.3ms preprocess, 146.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_188.jpg\n",
      "Saved labels to: results6\\labels\\MIT_188.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_189.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_189.jpg: 640x480 23 handwrittens, 118.5ms\n",
      "Speed: 3.4ms preprocess, 118.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_189.jpg\n",
      "Saved labels to: results6\\labels\\MIT_189.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_19.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_19.jpg: 640x480 23 handwrittens, 117.7ms\n",
      "Speed: 3.1ms preprocess, 117.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_19.jpg\n",
      "Saved labels to: results6\\labels\\MIT_19.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_190.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_190.jpg: 640x480 21 handwrittens, 125.3ms\n",
      "Speed: 2.9ms preprocess, 125.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_190.jpg\n",
      "Saved labels to: results6\\labels\\MIT_190.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_191.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_191.jpg: 640x480 20 handwrittens, 93.0ms\n",
      "Speed: 2.1ms preprocess, 93.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_191.jpg\n",
      "Saved labels to: results6\\labels\\MIT_191.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_192.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_192.jpg: 640x480 21 handwrittens, 120.3ms\n",
      "Speed: 3.8ms preprocess, 120.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_192.jpg\n",
      "Saved labels to: results6\\labels\\MIT_192.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_193.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_193.jpg: 640x480 22 handwrittens, 143.5ms\n",
      "Speed: 4.6ms preprocess, 143.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_193.jpg\n",
      "Saved labels to: results6\\labels\\MIT_193.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_194.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_194.jpg: 640x480 24 handwrittens, 115.7ms\n",
      "Speed: 2.6ms preprocess, 115.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_194.jpg\n",
      "Saved labels to: results6\\labels\\MIT_194.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_195.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_195.jpg: 640x480 21 handwrittens, 180.7ms\n",
      "Speed: 5.9ms preprocess, 180.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_195.jpg\n",
      "Saved labels to: results6\\labels\\MIT_195.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_196.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_196.jpg: 640x480 22 handwrittens, 128.9ms\n",
      "Speed: 3.7ms preprocess, 128.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_196.jpg\n",
      "Saved labels to: results6\\labels\\MIT_196.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_197.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_197.jpg: 640x480 22 handwrittens, 118.2ms\n",
      "Speed: 3.3ms preprocess, 118.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_197.jpg\n",
      "Saved labels to: results6\\labels\\MIT_197.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_198.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_198.jpg: 640x480 20 handwrittens, 105.8ms\n",
      "Speed: 3.6ms preprocess, 105.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_198.jpg\n",
      "Saved labels to: results6\\labels\\MIT_198.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_199.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_199.jpg: 640x480 21 handwrittens, 118.9ms\n",
      "Speed: 3.4ms preprocess, 118.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_199.jpg\n",
      "Saved labels to: results6\\labels\\MIT_199.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_2.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_2.jpg: 640x480 23 handwrittens, 101.5ms\n",
      "Speed: 2.4ms preprocess, 101.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_2.jpg\n",
      "Saved labels to: results6\\labels\\MIT_2.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_20.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_20.jpg: 640x480 21 handwrittens, 109.6ms\n",
      "Speed: 3.2ms preprocess, 109.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_20.jpg\n",
      "Saved labels to: results6\\labels\\MIT_20.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_200.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_200.jpg: 640x480 21 handwrittens, 102.8ms\n",
      "Speed: 3.0ms preprocess, 102.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_200.jpg\n",
      "Saved labels to: results6\\labels\\MIT_200.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_201.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_201.jpg: 640x480 20 handwrittens, 156.2ms\n",
      "Speed: 3.5ms preprocess, 156.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_201.jpg\n",
      "Saved labels to: results6\\labels\\MIT_201.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_202.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_202.jpg: 640x480 24 handwrittens, 117.8ms\n",
      "Speed: 3.0ms preprocess, 117.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_202.jpg\n",
      "Saved labels to: results6\\labels\\MIT_202.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_203.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_203.jpg: 640x480 21 handwrittens, 114.5ms\n",
      "Speed: 3.2ms preprocess, 114.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_203.jpg\n",
      "Saved labels to: results6\\labels\\MIT_203.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_204.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_204.jpg: 640x480 20 handwrittens, 104.6ms\n",
      "Speed: 3.1ms preprocess, 104.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_204.jpg\n",
      "Saved labels to: results6\\labels\\MIT_204.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_205.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_205.jpg: 640x480 23 handwrittens, 102.2ms\n",
      "Speed: 3.1ms preprocess, 102.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_205.jpg\n",
      "Saved labels to: results6\\labels\\MIT_205.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_206.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_206.jpg: 640x480 23 handwrittens, 114.2ms\n",
      "Speed: 3.4ms preprocess, 114.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_206.jpg\n",
      "Saved labels to: results6\\labels\\MIT_206.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_207.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_207.jpg: 640x480 22 handwrittens, 93.5ms\n",
      "Speed: 3.3ms preprocess, 93.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_207.jpg\n",
      "Saved labels to: results6\\labels\\MIT_207.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_208.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_208.jpg: 640x480 20 handwrittens, 144.3ms\n",
      "Speed: 2.4ms preprocess, 144.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_208.jpg\n",
      "Saved labels to: results6\\labels\\MIT_208.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_209.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_209.jpg: 640x480 23 handwrittens, 117.4ms\n",
      "Speed: 3.0ms preprocess, 117.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_209.jpg\n",
      "Saved labels to: results6\\labels\\MIT_209.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_21.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_21.jpg: 640x480 22 handwrittens, 136.6ms\n",
      "Speed: 4.2ms preprocess, 136.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_21.jpg\n",
      "Saved labels to: results6\\labels\\MIT_21.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_210.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_210.jpg: 640x480 23 handwrittens, 124.3ms\n",
      "Speed: 2.9ms preprocess, 124.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_210.jpg\n",
      "Saved labels to: results6\\labels\\MIT_210.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_211.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_211.jpg: 640x480 24 handwrittens, 113.5ms\n",
      "Speed: 3.1ms preprocess, 113.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_211.jpg\n",
      "Saved labels to: results6\\labels\\MIT_211.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_212.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_212.jpg: 640x480 20 handwrittens, 113.8ms\n",
      "Speed: 3.2ms preprocess, 113.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_212.jpg\n",
      "Saved labels to: results6\\labels\\MIT_212.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_213.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_213.jpg: 640x480 21 handwrittens, 100.1ms\n",
      "Speed: 2.3ms preprocess, 100.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_213.jpg\n",
      "Saved labels to: results6\\labels\\MIT_213.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_214.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_214.jpg: 640x480 19 handwrittens, 107.0ms\n",
      "Speed: 3.0ms preprocess, 107.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_214.jpg\n",
      "Saved labels to: results6\\labels\\MIT_214.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_215.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_215.jpg: 640x480 23 handwrittens, 112.0ms\n",
      "Speed: 3.3ms preprocess, 112.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_215.jpg\n",
      "Saved labels to: results6\\labels\\MIT_215.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_216.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_216.jpg: 640x480 20 handwrittens, 176.4ms\n",
      "Speed: 4.4ms preprocess, 176.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_216.jpg\n",
      "Saved labels to: results6\\labels\\MIT_216.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_217.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_217.jpg: 640x480 21 handwrittens, 105.3ms\n",
      "Speed: 3.1ms preprocess, 105.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_217.jpg\n",
      "Saved labels to: results6\\labels\\MIT_217.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_218.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_218.jpg: 640x480 22 handwrittens, 116.1ms\n",
      "Speed: 3.8ms preprocess, 116.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_218.jpg\n",
      "Saved labels to: results6\\labels\\MIT_218.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_219.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_219.jpg: 640x480 20 handwrittens, 112.2ms\n",
      "Speed: 3.0ms preprocess, 112.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_219.jpg\n",
      "Saved labels to: results6\\labels\\MIT_219.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_22.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_22.jpg: 640x480 22 handwrittens, 137.6ms\n",
      "Speed: 3.9ms preprocess, 137.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_22.jpg\n",
      "Saved labels to: results6\\labels\\MIT_22.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_220.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_220.jpg: 640x480 22 handwrittens, 164.0ms\n",
      "Speed: 3.1ms preprocess, 164.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_220.jpg\n",
      "Saved labels to: results6\\labels\\MIT_220.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_221.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_221.jpg: 640x480 23 handwrittens, 110.9ms\n",
      "Speed: 2.8ms preprocess, 110.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_221.jpg\n",
      "Saved labels to: results6\\labels\\MIT_221.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_222.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_222.jpg: 640x480 22 handwrittens, 100.7ms\n",
      "Speed: 3.0ms preprocess, 100.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_222.jpg\n",
      "Saved labels to: results6\\labels\\MIT_222.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_223.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_223.jpg: 640x480 22 handwrittens, 110.8ms\n",
      "Speed: 3.4ms preprocess, 110.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_223.jpg\n",
      "Saved labels to: results6\\labels\\MIT_223.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_224.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_224.jpg: 640x480 22 handwrittens, 130.1ms\n",
      "Speed: 3.5ms preprocess, 130.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_224.jpg\n",
      "Saved labels to: results6\\labels\\MIT_224.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_225.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_225.jpg: 640x480 21 handwrittens, 100.5ms\n",
      "Speed: 2.8ms preprocess, 100.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_225.jpg\n",
      "Saved labels to: results6\\labels\\MIT_225.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_226.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_226.jpg: 640x480 23 handwrittens, 118.7ms\n",
      "Speed: 3.1ms preprocess, 118.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_226.jpg\n",
      "Saved labels to: results6\\labels\\MIT_226.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_227.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_227.jpg: 640x480 24 handwrittens, 132.3ms\n",
      "Speed: 3.5ms preprocess, 132.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_227.jpg\n",
      "Saved labels to: results6\\labels\\MIT_227.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_228.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_228.jpg: 640x480 24 handwrittens, 149.7ms\n",
      "Speed: 3.1ms preprocess, 149.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_228.jpg\n",
      "Saved labels to: results6\\labels\\MIT_228.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_229.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_229.jpg: 640x480 29 handwrittens, 102.9ms\n",
      "Speed: 2.2ms preprocess, 102.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_229.jpg\n",
      "Saved labels to: results6\\labels\\MIT_229.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_23.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_23.jpg: 640x480 22 handwrittens, 105.3ms\n",
      "Speed: 3.7ms preprocess, 105.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_23.jpg\n",
      "Saved labels to: results6\\labels\\MIT_23.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_230.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_230.jpg: 640x480 21 handwrittens, 97.6ms\n",
      "Speed: 3.2ms preprocess, 97.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_230.jpg\n",
      "Saved labels to: results6\\labels\\MIT_230.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_231.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_231.jpg: 640x480 24 handwrittens, 104.3ms\n",
      "Speed: 3.3ms preprocess, 104.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_231.jpg\n",
      "Saved labels to: results6\\labels\\MIT_231.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_232.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_232.jpg: 640x480 25 handwrittens, 166.0ms\n",
      "Speed: 3.0ms preprocess, 166.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_232.jpg\n",
      "Saved labels to: results6\\labels\\MIT_232.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_233.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_233.jpg: 640x480 20 handwrittens, 95.6ms\n",
      "Speed: 3.1ms preprocess, 95.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_233.jpg\n",
      "Saved labels to: results6\\labels\\MIT_233.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_234.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_234.jpg: 640x480 21 handwrittens, 101.7ms\n",
      "Speed: 4.7ms preprocess, 101.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_234.jpg\n",
      "Saved labels to: results6\\labels\\MIT_234.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_235.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_235.jpg: 640x480 22 handwrittens, 105.0ms\n",
      "Speed: 3.0ms preprocess, 105.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_235.jpg\n",
      "Saved labels to: results6\\labels\\MIT_235.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_236.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_236.jpg: 640x480 22 handwrittens, 117.1ms\n",
      "Speed: 2.3ms preprocess, 117.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_236.jpg\n",
      "Saved labels to: results6\\labels\\MIT_236.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_237.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_237.jpg: 640x480 22 handwrittens, 112.3ms\n",
      "Speed: 3.0ms preprocess, 112.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_237.jpg\n",
      "Saved labels to: results6\\labels\\MIT_237.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_238.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_238.jpg: 640x480 24 handwrittens, 140.7ms\n",
      "Speed: 4.4ms preprocess, 140.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_238.jpg\n",
      "Saved labels to: results6\\labels\\MIT_238.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_239.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_239.jpg: 640x480 20 handwrittens, 135.5ms\n",
      "Speed: 11.2ms preprocess, 135.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_239.jpg\n",
      "Saved labels to: results6\\labels\\MIT_239.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_24.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_24.jpg: 640x480 24 handwrittens, 108.0ms\n",
      "Speed: 3.3ms preprocess, 108.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_24.jpg\n",
      "Saved labels to: results6\\labels\\MIT_24.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_240.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_240.jpg: 640x480 25 handwrittens, 171.4ms\n",
      "Speed: 5.3ms preprocess, 171.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_240.jpg\n",
      "Saved labels to: results6\\labels\\MIT_240.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_241.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_241.jpg: 640x480 23 handwrittens, 136.2ms\n",
      "Speed: 3.5ms preprocess, 136.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_241.jpg\n",
      "Saved labels to: results6\\labels\\MIT_241.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_242.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_242.jpg: 640x480 22 handwrittens, 139.8ms\n",
      "Speed: 5.4ms preprocess, 139.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_242.jpg\n",
      "Saved labels to: results6\\labels\\MIT_242.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_243.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_243.jpg: 640x480 23 handwrittens, 126.4ms\n",
      "Speed: 3.1ms preprocess, 126.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_243.jpg\n",
      "Saved labels to: results6\\labels\\MIT_243.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_244.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_244.jpg: 640x480 22 handwrittens, 153.8ms\n",
      "Speed: 3.8ms preprocess, 153.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_244.jpg\n",
      "Saved labels to: results6\\labels\\MIT_244.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_245.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_245.jpg: 640x480 20 handwrittens, 112.6ms\n",
      "Speed: 3.0ms preprocess, 112.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_245.jpg\n",
      "Saved labels to: results6\\labels\\MIT_245.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_246.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_246.jpg: 640x480 21 handwrittens, 113.9ms\n",
      "Speed: 3.3ms preprocess, 113.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_246.jpg\n",
      "Saved labels to: results6\\labels\\MIT_246.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_247.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_247.jpg: 640x480 20 handwrittens, 122.2ms\n",
      "Speed: 3.2ms preprocess, 122.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_247.jpg\n",
      "Saved labels to: results6\\labels\\MIT_247.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_248.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_248.jpg: 640x480 21 handwrittens, 246.6ms\n",
      "Speed: 3.4ms preprocess, 246.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_248.jpg\n",
      "Saved labels to: results6\\labels\\MIT_248.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_249.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_249.jpg: 640x480 21 handwrittens, 165.9ms\n",
      "Speed: 3.0ms preprocess, 165.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_249.jpg\n",
      "Saved labels to: results6\\labels\\MIT_249.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_25.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_25.jpg: 640x480 21 handwrittens, 117.7ms\n",
      "Speed: 2.3ms preprocess, 117.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_25.jpg\n",
      "Saved labels to: results6\\labels\\MIT_25.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_250.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_250.jpg: 640x480 20 handwrittens, 167.7ms\n",
      "Speed: 15.4ms preprocess, 167.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_250.jpg\n",
      "Saved labels to: results6\\labels\\MIT_250.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_251.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_251.jpg: 640x480 21 handwrittens, 131.4ms\n",
      "Speed: 2.8ms preprocess, 131.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_251.jpg\n",
      "Saved labels to: results6\\labels\\MIT_251.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_252.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_252.jpg: 640x480 21 handwrittens, 117.4ms\n",
      "Speed: 3.9ms preprocess, 117.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_252.jpg\n",
      "Saved labels to: results6\\labels\\MIT_252.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_253.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_253.jpg: 640x480 22 handwrittens, 109.3ms\n",
      "Speed: 2.3ms preprocess, 109.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_253.jpg\n",
      "Saved labels to: results6\\labels\\MIT_253.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_254.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_254.jpg: 640x480 25 handwrittens, 116.0ms\n",
      "Speed: 2.2ms preprocess, 116.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_254.jpg\n",
      "Saved labels to: results6\\labels\\MIT_254.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_255.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_255.jpg: 640x480 21 handwrittens, 115.2ms\n",
      "Speed: 3.1ms preprocess, 115.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_255.jpg\n",
      "Saved labels to: results6\\labels\\MIT_255.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_256.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_256.jpg: 640x480 21 handwrittens, 149.9ms\n",
      "Speed: 3.3ms preprocess, 149.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_256.jpg\n",
      "Saved labels to: results6\\labels\\MIT_256.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_257.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_257.jpg: 640x480 21 handwrittens, 99.1ms\n",
      "Speed: 3.1ms preprocess, 99.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_257.jpg\n",
      "Saved labels to: results6\\labels\\MIT_257.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_258.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_258.jpg: 640x480 22 handwrittens, 107.1ms\n",
      "Speed: 2.9ms preprocess, 107.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_258.jpg\n",
      "Saved labels to: results6\\labels\\MIT_258.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_259.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_259.jpg: 640x480 22 handwrittens, 95.3ms\n",
      "Speed: 3.0ms preprocess, 95.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_259.jpg\n",
      "Saved labels to: results6\\labels\\MIT_259.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_26.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_26.jpg: 640x480 22 handwrittens, 109.7ms\n",
      "Speed: 2.4ms preprocess, 109.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_26.jpg\n",
      "Saved labels to: results6\\labels\\MIT_26.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_260.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_260.jpg: 640x480 21 handwrittens, 101.9ms\n",
      "Speed: 4.7ms preprocess, 101.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_260.jpg\n",
      "Saved labels to: results6\\labels\\MIT_260.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_261.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_261.jpg: 640x480 23 handwrittens, 97.6ms\n",
      "Speed: 3.3ms preprocess, 97.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_261.jpg\n",
      "Saved labels to: results6\\labels\\MIT_261.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_262.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_262.jpg: 640x480 21 handwrittens, 115.9ms\n",
      "Speed: 1.9ms preprocess, 115.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_262.jpg\n",
      "Saved labels to: results6\\labels\\MIT_262.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_263.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_263.jpg: 640x480 21 handwrittens, 128.3ms\n",
      "Speed: 3.3ms preprocess, 128.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_263.jpg\n",
      "Saved labels to: results6\\labels\\MIT_263.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_264.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_264.jpg: 640x480 22 handwrittens, 107.9ms\n",
      "Speed: 3.2ms preprocess, 107.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_264.jpg\n",
      "Saved labels to: results6\\labels\\MIT_264.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_265.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_265.jpg: 640x480 21 handwrittens, 168.1ms\n",
      "Speed: 3.1ms preprocess, 168.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_265.jpg\n",
      "Saved labels to: results6\\labels\\MIT_265.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_266.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_266.jpg: 640x480 20 handwrittens, 107.5ms\n",
      "Speed: 3.1ms preprocess, 107.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_266.jpg\n",
      "Saved labels to: results6\\labels\\MIT_266.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_267.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_267.jpg: 640x480 20 handwrittens, 104.8ms\n",
      "Speed: 3.0ms preprocess, 104.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_267.jpg\n",
      "Saved labels to: results6\\labels\\MIT_267.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_268.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_268.jpg: 640x480 24 handwrittens, 105.8ms\n",
      "Speed: 2.4ms preprocess, 105.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_268.jpg\n",
      "Saved labels to: results6\\labels\\MIT_268.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_269.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_269.jpg: 640x480 22 handwrittens, 114.1ms\n",
      "Speed: 3.2ms preprocess, 114.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_269.jpg\n",
      "Saved labels to: results6\\labels\\MIT_269.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_27.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_27.jpg: 640x480 23 handwrittens, 87.8ms\n",
      "Speed: 3.1ms preprocess, 87.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_27.jpg\n",
      "Saved labels to: results6\\labels\\MIT_27.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_270.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_270.jpg: 640x480 20 handwrittens, 93.7ms\n",
      "Speed: 2.9ms preprocess, 93.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_270.jpg\n",
      "Saved labels to: results6\\labels\\MIT_270.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_271.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_271.jpg: 640x480 21 handwrittens, 113.2ms\n",
      "Speed: 3.1ms preprocess, 113.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_271.jpg\n",
      "Saved labels to: results6\\labels\\MIT_271.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_272.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_272.jpg: 640x480 20 handwrittens, 123.4ms\n",
      "Speed: 2.7ms preprocess, 123.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_272.jpg\n",
      "Saved labels to: results6\\labels\\MIT_272.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_273.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_273.jpg: 640x480 21 handwrittens, 134.6ms\n",
      "Speed: 3.2ms preprocess, 134.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_273.jpg\n",
      "Saved labels to: results6\\labels\\MIT_273.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_274.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_274.jpg: 640x480 21 handwrittens, 158.6ms\n",
      "Speed: 3.1ms preprocess, 158.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_274.jpg\n",
      "Saved labels to: results6\\labels\\MIT_274.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_275.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_275.jpg: 640x480 21 handwrittens, 105.8ms\n",
      "Speed: 2.3ms preprocess, 105.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_275.jpg\n",
      "Saved labels to: results6\\labels\\MIT_275.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_276.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_276.jpg: 640x480 20 handwrittens, 108.2ms\n",
      "Speed: 3.3ms preprocess, 108.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_276.jpg\n",
      "Saved labels to: results6\\labels\\MIT_276.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_277.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_277.jpg: 640x480 22 handwrittens, 115.7ms\n",
      "Speed: 3.1ms preprocess, 115.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_277.jpg\n",
      "Saved labels to: results6\\labels\\MIT_277.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_278.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_278.jpg: 640x480 25 handwrittens, 99.5ms\n",
      "Speed: 3.1ms preprocess, 99.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_278.jpg\n",
      "Saved labels to: results6\\labels\\MIT_278.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_279.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_279.jpg: 640x480 20 handwrittens, 91.2ms\n",
      "Speed: 3.0ms preprocess, 91.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_279.jpg\n",
      "Saved labels to: results6\\labels\\MIT_279.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_28.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_28.jpg: 640x480 22 handwrittens, 94.9ms\n",
      "Speed: 3.2ms preprocess, 94.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_28.jpg\n",
      "Saved labels to: results6\\labels\\MIT_28.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_280.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_280.jpg: 640x480 19 handwrittens, 105.8ms\n",
      "Speed: 3.6ms preprocess, 105.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_280.jpg\n",
      "Saved labels to: results6\\labels\\MIT_280.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_281.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_281.jpg: 640x480 22 handwrittens, 95.5ms\n",
      "Speed: 3.1ms preprocess, 95.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_281.jpg\n",
      "Saved labels to: results6\\labels\\MIT_281.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_282.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_282.jpg: 640x480 22 handwrittens, 118.0ms\n",
      "Speed: 3.1ms preprocess, 118.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_282.jpg\n",
      "Saved labels to: results6\\labels\\MIT_282.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_283.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_283.jpg: 640x480 22 handwrittens, 104.7ms\n",
      "Speed: 3.7ms preprocess, 104.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_283.jpg\n",
      "Saved labels to: results6\\labels\\MIT_283.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_284.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_284.jpg: 640x480 21 handwrittens, 102.7ms\n",
      "Speed: 2.5ms preprocess, 102.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_284.jpg\n",
      "Saved labels to: results6\\labels\\MIT_284.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_285.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_285.jpg: 640x480 24 handwrittens, 109.7ms\n",
      "Speed: 3.0ms preprocess, 109.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_285.jpg\n",
      "Saved labels to: results6\\labels\\MIT_285.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_286.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_286.jpg: 640x480 21 handwrittens, 161.5ms\n",
      "Speed: 3.2ms preprocess, 161.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_286.jpg\n",
      "Saved labels to: results6\\labels\\MIT_286.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_287.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_287.jpg: 640x480 20 handwrittens, 102.7ms\n",
      "Speed: 2.2ms preprocess, 102.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_287.jpg\n",
      "Saved labels to: results6\\labels\\MIT_287.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_288.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_288.jpg: 640x480 22 handwrittens, 100.2ms\n",
      "Speed: 1.9ms preprocess, 100.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_288.jpg\n",
      "Saved labels to: results6\\labels\\MIT_288.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_289.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_289.jpg: 640x480 20 handwrittens, 135.2ms\n",
      "Speed: 3.5ms preprocess, 135.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_289.jpg\n",
      "Saved labels to: results6\\labels\\MIT_289.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_29.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_29.jpg: 640x480 22 handwrittens, 101.1ms\n",
      "Speed: 3.3ms preprocess, 101.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_29.jpg\n",
      "Saved labels to: results6\\labels\\MIT_29.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_290.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_290.jpg: 640x480 24 handwrittens, 118.9ms\n",
      "Speed: 3.0ms preprocess, 118.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_290.jpg\n",
      "Saved labels to: results6\\labels\\MIT_290.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_291.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_291.jpg: 640x480 21 handwrittens, 114.5ms\n",
      "Speed: 3.1ms preprocess, 114.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_291.jpg\n",
      "Saved labels to: results6\\labels\\MIT_291.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_292.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_292.jpg: 640x480 20 handwrittens, 107.4ms\n",
      "Speed: 2.9ms preprocess, 107.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_292.jpg\n",
      "Saved labels to: results6\\labels\\MIT_292.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_293.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_293.jpg: 640x480 21 handwrittens, 94.4ms\n",
      "Speed: 3.0ms preprocess, 94.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_293.jpg\n",
      "Saved labels to: results6\\labels\\MIT_293.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_294.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_294.jpg: 640x480 23 handwrittens, 109.3ms\n",
      "Speed: 3.0ms preprocess, 109.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_294.jpg\n",
      "Saved labels to: results6\\labels\\MIT_294.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_295.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_295.jpg: 640x480 23 handwrittens, 105.3ms\n",
      "Speed: 3.2ms preprocess, 105.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_295.jpg\n",
      "Saved labels to: results6\\labels\\MIT_295.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_296.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_296.jpg: 640x480 22 handwrittens, 105.4ms\n",
      "Speed: 2.8ms preprocess, 105.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_296.jpg\n",
      "Saved labels to: results6\\labels\\MIT_296.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_297.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_297.jpg: 640x480 20 handwrittens, 103.1ms\n",
      "Speed: 3.2ms preprocess, 103.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_297.jpg\n",
      "Saved labels to: results6\\labels\\MIT_297.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_298.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_298.jpg: 640x480 22 handwrittens, 159.2ms\n",
      "Speed: 3.0ms preprocess, 159.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_298.jpg\n",
      "Saved labels to: results6\\labels\\MIT_298.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_299.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_299.jpg: 640x480 22 handwrittens, 102.2ms\n",
      "Speed: 2.5ms preprocess, 102.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_299.jpg\n",
      "Saved labels to: results6\\labels\\MIT_299.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_3.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_3.jpg: 640x480 21 handwrittens, 122.3ms\n",
      "Speed: 3.8ms preprocess, 122.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_3.jpg\n",
      "Saved labels to: results6\\labels\\MIT_3.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_30.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_30.jpg: 640x480 22 handwrittens, 103.3ms\n",
      "Speed: 2.1ms preprocess, 103.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_30.jpg\n",
      "Saved labels to: results6\\labels\\MIT_30.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_300.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_300.jpg: 640x480 21 handwrittens, 105.7ms\n",
      "Speed: 3.0ms preprocess, 105.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_300.jpg\n",
      "Saved labels to: results6\\labels\\MIT_300.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_301.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_301.jpg: 640x480 22 handwrittens, 90.8ms\n",
      "Speed: 2.9ms preprocess, 90.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_301.jpg\n",
      "Saved labels to: results6\\labels\\MIT_301.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_302.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_302.jpg: 640x480 21 handwrittens, 139.1ms\n",
      "Speed: 1.9ms preprocess, 139.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_302.jpg\n",
      "Saved labels to: results6\\labels\\MIT_302.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_303.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_303.jpg: 640x480 21 handwrittens, 104.8ms\n",
      "Speed: 3.2ms preprocess, 104.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_303.jpg\n",
      "Saved labels to: results6\\labels\\MIT_303.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_304.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_304.jpg: 640x480 23 handwrittens, 122.4ms\n",
      "Speed: 3.0ms preprocess, 122.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_304.jpg\n",
      "Saved labels to: results6\\labels\\MIT_304.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_305.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_305.jpg: 640x480 24 handwrittens, 106.9ms\n",
      "Speed: 3.9ms preprocess, 106.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_305.jpg\n",
      "Saved labels to: results6\\labels\\MIT_305.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_306.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_306.jpg: 640x480 23 handwrittens, 105.4ms\n",
      "Speed: 2.6ms preprocess, 105.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_306.jpg\n",
      "Saved labels to: results6\\labels\\MIT_306.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_307.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_307.jpg: 640x480 22 handwrittens, 111.4ms\n",
      "Speed: 3.5ms preprocess, 111.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_307.jpg\n",
      "Saved labels to: results6\\labels\\MIT_307.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_308.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_308.jpg: 640x480 23 handwrittens, 113.0ms\n",
      "Speed: 3.1ms preprocess, 113.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_308.jpg\n",
      "Saved labels to: results6\\labels\\MIT_308.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_309.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_309.jpg: 640x480 24 handwrittens, 103.0ms\n",
      "Speed: 2.6ms preprocess, 103.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_309.jpg\n",
      "Saved labels to: results6\\labels\\MIT_309.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_31.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_31.jpg: 640x480 26 handwrittens, 87.9ms\n",
      "Speed: 3.1ms preprocess, 87.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_31.jpg\n",
      "Saved labels to: results6\\labels\\MIT_31.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_310.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_310.jpg: 640x480 22 handwrittens, 97.3ms\n",
      "Speed: 2.2ms preprocess, 97.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_310.jpg\n",
      "Saved labels to: results6\\labels\\MIT_310.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_311.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_311.jpg: 640x480 21 handwrittens, 114.9ms\n",
      "Speed: 3.4ms preprocess, 114.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_311.jpg\n",
      "Saved labels to: results6\\labels\\MIT_311.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_312.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_312.jpg: 640x480 20 handwrittens, 116.4ms\n",
      "Speed: 3.1ms preprocess, 116.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_312.jpg\n",
      "Saved labels to: results6\\labels\\MIT_312.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_313.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_313.jpg: 640x480 21 handwrittens, 112.1ms\n",
      "Speed: 3.0ms preprocess, 112.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_313.jpg\n",
      "Saved labels to: results6\\labels\\MIT_313.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_314.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_314.jpg: 640x480 21 handwrittens, 99.5ms\n",
      "Speed: 3.0ms preprocess, 99.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_314.jpg\n",
      "Saved labels to: results6\\labels\\MIT_314.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_315.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_315.jpg: 640x480 24 handwrittens, 123.0ms\n",
      "Speed: 7.9ms preprocess, 123.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_315.jpg\n",
      "Saved labels to: results6\\labels\\MIT_315.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_316.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_316.jpg: 640x480 22 handwrittens, 117.3ms\n",
      "Speed: 2.6ms preprocess, 117.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_316.jpg\n",
      "Saved labels to: results6\\labels\\MIT_316.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_317.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_317.jpg: 640x480 27 handwrittens, 120.5ms\n",
      "Speed: 4.0ms preprocess, 120.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_317.jpg\n",
      "Saved labels to: results6\\labels\\MIT_317.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_318.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_318.jpg: 640x480 27 handwrittens, 110.1ms\n",
      "Speed: 3.4ms preprocess, 110.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_318.jpg\n",
      "Saved labels to: results6\\labels\\MIT_318.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_319.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_319.jpg: 640x480 20 handwrittens, 111.3ms\n",
      "Speed: 3.0ms preprocess, 111.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_319.jpg\n",
      "Saved labels to: results6\\labels\\MIT_319.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_32.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_32.jpg: 640x480 22 handwrittens, 155.4ms\n",
      "Speed: 4.3ms preprocess, 155.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_32.jpg\n",
      "Saved labels to: results6\\labels\\MIT_32.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_320.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_320.jpg: 640x480 21 handwrittens, 109.6ms\n",
      "Speed: 3.3ms preprocess, 109.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_320.jpg\n",
      "Saved labels to: results6\\labels\\MIT_320.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_321.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_321.jpg: 640x480 20 handwrittens, 117.3ms\n",
      "Speed: 2.7ms preprocess, 117.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_321.jpg\n",
      "Saved labels to: results6\\labels\\MIT_321.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_322.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_322.jpg: 640x480 21 handwrittens, 106.5ms\n",
      "Speed: 2.7ms preprocess, 106.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_322.jpg\n",
      "Saved labels to: results6\\labels\\MIT_322.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_323.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_323.jpg: 640x480 22 handwrittens, 124.3ms\n",
      "Speed: 3.6ms preprocess, 124.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_323.jpg\n",
      "Saved labels to: results6\\labels\\MIT_323.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_324.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_324.jpg: 640x480 22 handwrittens, 151.7ms\n",
      "Speed: 3.1ms preprocess, 151.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_324.jpg\n",
      "Saved labels to: results6\\labels\\MIT_324.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_325.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_325.jpg: 640x480 20 handwrittens, 116.5ms\n",
      "Speed: 4.1ms preprocess, 116.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_325.jpg\n",
      "Saved labels to: results6\\labels\\MIT_325.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_326.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_326.jpg: 640x480 21 handwrittens, 99.1ms\n",
      "Speed: 2.2ms preprocess, 99.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_326.jpg\n",
      "Saved labels to: results6\\labels\\MIT_326.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_327.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_327.jpg: 640x480 25 handwrittens, 267.2ms\n",
      "Speed: 6.2ms preprocess, 267.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_327.jpg\n",
      "Saved labels to: results6\\labels\\MIT_327.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_328.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_328.jpg: 640x480 21 handwrittens, 179.5ms\n",
      "Speed: 4.0ms preprocess, 179.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_328.jpg\n",
      "Saved labels to: results6\\labels\\MIT_328.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_329.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_329.jpg: 640x480 21 handwrittens, 172.4ms\n",
      "Speed: 4.1ms preprocess, 172.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_329.jpg\n",
      "Saved labels to: results6\\labels\\MIT_329.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_33.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_33.jpg: 640x480 23 handwrittens, 121.5ms\n",
      "Speed: 3.6ms preprocess, 121.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_33.jpg\n",
      "Saved labels to: results6\\labels\\MIT_33.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_330.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_330.jpg: 640x480 21 handwrittens, 105.8ms\n",
      "Speed: 3.4ms preprocess, 105.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_330.jpg\n",
      "Saved labels to: results6\\labels\\MIT_330.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_331.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_331.jpg: 640x480 21 handwrittens, 137.2ms\n",
      "Speed: 3.3ms preprocess, 137.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_331.jpg\n",
      "Saved labels to: results6\\labels\\MIT_331.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_332.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_332.jpg: 640x480 22 handwrittens, 169.8ms\n",
      "Speed: 30.9ms preprocess, 169.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_332.jpg\n",
      "Saved labels to: results6\\labels\\MIT_332.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_333.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_333.jpg: 640x480 21 handwrittens, 160.2ms\n",
      "Speed: 3.4ms preprocess, 160.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_333.jpg\n",
      "Saved labels to: results6\\labels\\MIT_333.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_334.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_334.jpg: 640x480 22 handwrittens, 114.6ms\n",
      "Speed: 3.3ms preprocess, 114.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_334.jpg\n",
      "Saved labels to: results6\\labels\\MIT_334.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_335.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_335.jpg: 640x480 20 handwrittens, 140.0ms\n",
      "Speed: 4.0ms preprocess, 140.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_335.jpg\n",
      "Saved labels to: results6\\labels\\MIT_335.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_336.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_336.jpg: 640x480 21 handwrittens, 124.5ms\n",
      "Speed: 3.1ms preprocess, 124.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_336.jpg\n",
      "Saved labels to: results6\\labels\\MIT_336.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_337.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_337.jpg: 640x480 23 handwrittens, 106.5ms\n",
      "Speed: 3.5ms preprocess, 106.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_337.jpg\n",
      "Saved labels to: results6\\labels\\MIT_337.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_338.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_338.jpg: 640x480 21 handwrittens, 155.1ms\n",
      "Speed: 2.5ms preprocess, 155.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_338.jpg\n",
      "Saved labels to: results6\\labels\\MIT_338.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_339.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_339.jpg: 640x480 19 handwrittens, 104.9ms\n",
      "Speed: 2.9ms preprocess, 104.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_339.jpg\n",
      "Saved labels to: results6\\labels\\MIT_339.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_34.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_34.jpg: 640x480 26 handwrittens, 111.9ms\n",
      "Speed: 3.0ms preprocess, 111.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_34.jpg\n",
      "Saved labels to: results6\\labels\\MIT_34.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_340.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_340.jpg: 640x480 26 handwrittens, 108.4ms\n",
      "Speed: 3.0ms preprocess, 108.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_340.jpg\n",
      "Saved labels to: results6\\labels\\MIT_340.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_341.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_341.jpg: 640x480 21 handwrittens, 117.6ms\n",
      "Speed: 3.5ms preprocess, 117.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_341.jpg\n",
      "Saved labels to: results6\\labels\\MIT_341.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_342.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_342.jpg: 640x480 20 handwrittens, 169.5ms\n",
      "Speed: 3.4ms preprocess, 169.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_342.jpg\n",
      "Saved labels to: results6\\labels\\MIT_342.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_343.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_343.jpg: 640x480 22 handwrittens, 207.3ms\n",
      "Speed: 3.4ms preprocess, 207.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_343.jpg\n",
      "Saved labels to: results6\\labels\\MIT_343.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_344.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_344.jpg: 640x480 23 handwrittens, 113.8ms\n",
      "Speed: 3.4ms preprocess, 113.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_344.jpg\n",
      "Saved labels to: results6\\labels\\MIT_344.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_345.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_345.jpg: 640x480 22 handwrittens, 110.9ms\n",
      "Speed: 2.8ms preprocess, 110.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_345.jpg\n",
      "Saved labels to: results6\\labels\\MIT_345.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_346.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_346.jpg: 640x480 23 handwrittens, 107.4ms\n",
      "Speed: 2.7ms preprocess, 107.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_346.jpg\n",
      "Saved labels to: results6\\labels\\MIT_346.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_347.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_347.jpg: 640x480 20 handwrittens, 103.3ms\n",
      "Speed: 2.8ms preprocess, 103.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_347.jpg\n",
      "Saved labels to: results6\\labels\\MIT_347.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_348.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_348.jpg: 640x480 22 handwrittens, 102.6ms\n",
      "Speed: 3.4ms preprocess, 102.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_348.jpg\n",
      "Saved labels to: results6\\labels\\MIT_348.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_349.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_349.jpg: 640x480 23 handwrittens, 131.6ms\n",
      "Speed: 37.5ms preprocess, 131.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_349.jpg\n",
      "Saved labels to: results6\\labels\\MIT_349.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_35.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_35.jpg: 640x480 21 handwrittens, 158.8ms\n",
      "Speed: 3.8ms preprocess, 158.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_35.jpg\n",
      "Saved labels to: results6\\labels\\MIT_35.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_350.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_350.jpg: 640x480 21 handwrittens, 127.1ms\n",
      "Speed: 3.0ms preprocess, 127.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_350.jpg\n",
      "Saved labels to: results6\\labels\\MIT_350.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_351.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_351.jpg: 640x480 21 handwrittens, 122.7ms\n",
      "Speed: 3.8ms preprocess, 122.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_351.jpg\n",
      "Saved labels to: results6\\labels\\MIT_351.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_352.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_352.jpg: 640x480 23 handwrittens, 109.2ms\n",
      "Speed: 3.0ms preprocess, 109.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_352.jpg\n",
      "Saved labels to: results6\\labels\\MIT_352.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_353.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_353.jpg: 640x480 25 handwrittens, 109.3ms\n",
      "Speed: 3.0ms preprocess, 109.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_353.jpg\n",
      "Saved labels to: results6\\labels\\MIT_353.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_354.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_354.jpg: 640x480 22 handwrittens, 163.0ms\n",
      "Speed: 2.8ms preprocess, 163.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_354.jpg\n",
      "Saved labels to: results6\\labels\\MIT_354.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_355.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_355.jpg: 640x480 21 handwrittens, 96.9ms\n",
      "Speed: 3.1ms preprocess, 96.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_355.jpg\n",
      "Saved labels to: results6\\labels\\MIT_355.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_356.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_356.jpg: 640x480 22 handwrittens, 159.4ms\n",
      "Speed: 4.7ms preprocess, 159.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_356.jpg\n",
      "Saved labels to: results6\\labels\\MIT_356.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_357.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_357.jpg: 640x480 24 handwrittens, 133.3ms\n",
      "Speed: 3.1ms preprocess, 133.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_357.jpg\n",
      "Saved labels to: results6\\labels\\MIT_357.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_358.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_358.jpg: 640x480 23 handwrittens, 111.5ms\n",
      "Speed: 3.0ms preprocess, 111.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_358.jpg\n",
      "Saved labels to: results6\\labels\\MIT_358.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_359.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_359.jpg: 640x480 23 handwrittens, 117.2ms\n",
      "Speed: 2.7ms preprocess, 117.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_359.jpg\n",
      "Saved labels to: results6\\labels\\MIT_359.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_36.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_36.jpg: 640x480 24 handwrittens, 137.4ms\n",
      "Speed: 15.8ms preprocess, 137.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_36.jpg\n",
      "Saved labels to: results6\\labels\\MIT_36.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_360.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_360.jpg: 640x480 21 handwrittens, 122.6ms\n",
      "Speed: 2.7ms preprocess, 122.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_360.jpg\n",
      "Saved labels to: results6\\labels\\MIT_360.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_361.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_361.jpg: 640x480 23 handwrittens, 99.4ms\n",
      "Speed: 2.9ms preprocess, 99.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_361.jpg\n",
      "Saved labels to: results6\\labels\\MIT_361.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_362.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_362.jpg: 640x480 20 handwrittens, 97.7ms\n",
      "Speed: 3.2ms preprocess, 97.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_362.jpg\n",
      "Saved labels to: results6\\labels\\MIT_362.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_363.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_363.jpg: 640x480 21 handwrittens, 112.9ms\n",
      "Speed: 3.0ms preprocess, 112.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_363.jpg\n",
      "Saved labels to: results6\\labels\\MIT_363.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_364.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_364.jpg: 640x480 21 handwrittens, 197.2ms\n",
      "Speed: 6.0ms preprocess, 197.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_364.jpg\n",
      "Saved labels to: results6\\labels\\MIT_364.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_365.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_365.jpg: 640x480 21 handwrittens, 132.2ms\n",
      "Speed: 3.3ms preprocess, 132.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_365.jpg\n",
      "Saved labels to: results6\\labels\\MIT_365.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_366.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_366.jpg: 640x480 21 handwrittens, 107.5ms\n",
      "Speed: 2.7ms preprocess, 107.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_366.jpg\n",
      "Saved labels to: results6\\labels\\MIT_366.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_367.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_367.jpg: 640x480 20 handwrittens, 113.8ms\n",
      "Speed: 3.5ms preprocess, 113.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_367.jpg\n",
      "Saved labels to: results6\\labels\\MIT_367.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_368.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_368.jpg: 640x480 23 handwrittens, 114.6ms\n",
      "Speed: 4.5ms preprocess, 114.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_368.jpg\n",
      "Saved labels to: results6\\labels\\MIT_368.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_369.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_369.jpg: 640x480 21 handwrittens, 94.9ms\n",
      "Speed: 2.9ms preprocess, 94.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_369.jpg\n",
      "Saved labels to: results6\\labels\\MIT_369.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_37.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_37.jpg: 640x480 22 handwrittens, 127.6ms\n",
      "Speed: 1.9ms preprocess, 127.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_37.jpg\n",
      "Saved labels to: results6\\labels\\MIT_37.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_370.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_370.jpg: 640x480 23 handwrittens, 135.7ms\n",
      "Speed: 5.6ms preprocess, 135.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_370.jpg\n",
      "Saved labels to: results6\\labels\\MIT_370.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_371.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_371.jpg: 640x480 20 handwrittens, 162.0ms\n",
      "Speed: 3.1ms preprocess, 162.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_371.jpg\n",
      "Saved labels to: results6\\labels\\MIT_371.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_372.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_372.jpg: 640x480 20 handwrittens, 114.7ms\n",
      "Speed: 2.8ms preprocess, 114.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_372.jpg\n",
      "Saved labels to: results6\\labels\\MIT_372.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_373.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_373.jpg: 640x480 22 handwrittens, 110.6ms\n",
      "Speed: 3.3ms preprocess, 110.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_373.jpg\n",
      "Saved labels to: results6\\labels\\MIT_373.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_374.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_374.jpg: 640x480 20 handwrittens, 103.5ms\n",
      "Speed: 2.4ms preprocess, 103.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_374.jpg\n",
      "Saved labels to: results6\\labels\\MIT_374.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_375.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_375.jpg: 640x480 21 handwrittens, 117.2ms\n",
      "Speed: 3.5ms preprocess, 117.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_375.jpg\n",
      "Saved labels to: results6\\labels\\MIT_375.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_376.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_376.jpg: 640x480 23 handwrittens, 130.8ms\n",
      "Speed: 2.9ms preprocess, 130.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_376.jpg\n",
      "Saved labels to: results6\\labels\\MIT_376.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_377.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_377.jpg: 640x480 23 handwrittens, 156.0ms\n",
      "Speed: 3.3ms preprocess, 156.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_377.jpg\n",
      "Saved labels to: results6\\labels\\MIT_377.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_378.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_378.jpg: 640x480 21 handwrittens, 132.9ms\n",
      "Speed: 3.5ms preprocess, 132.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_378.jpg\n",
      "Saved labels to: results6\\labels\\MIT_378.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_379.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_379.jpg: 640x480 22 handwrittens, 141.7ms\n",
      "Speed: 2.9ms preprocess, 141.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_379.jpg\n",
      "Saved labels to: results6\\labels\\MIT_379.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_38.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_38.jpg: 640x480 23 handwrittens, 145.9ms\n",
      "Speed: 3.7ms preprocess, 145.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_38.jpg\n",
      "Saved labels to: results6\\labels\\MIT_38.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_380.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_380.jpg: 640x480 23 handwrittens, 111.5ms\n",
      "Speed: 2.5ms preprocess, 111.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_380.jpg\n",
      "Saved labels to: results6\\labels\\MIT_380.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_381.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_381.jpg: 640x480 22 handwrittens, 118.5ms\n",
      "Speed: 3.6ms preprocess, 118.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_381.jpg\n",
      "Saved labels to: results6\\labels\\MIT_381.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_382.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_382.jpg: 640x480 21 handwrittens, 106.8ms\n",
      "Speed: 3.0ms preprocess, 106.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_382.jpg\n",
      "Saved labels to: results6\\labels\\MIT_382.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_383.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_383.jpg: 640x480 22 handwrittens, 98.4ms\n",
      "Speed: 2.2ms preprocess, 98.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_383.jpg\n",
      "Saved labels to: results6\\labels\\MIT_383.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_384.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_384.jpg: 640x480 23 handwrittens, 148.4ms\n",
      "Speed: 3.0ms preprocess, 148.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_384.jpg\n",
      "Saved labels to: results6\\labels\\MIT_384.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_385.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_385.jpg: 640x480 20 handwrittens, 134.0ms\n",
      "Speed: 3.5ms preprocess, 134.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_385.jpg\n",
      "Saved labels to: results6\\labels\\MIT_385.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_386.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_386.jpg: 640x480 20 handwrittens, 152.7ms\n",
      "Speed: 3.1ms preprocess, 152.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_386.jpg\n",
      "Saved labels to: results6\\labels\\MIT_386.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_387.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_387.jpg: 640x480 21 handwrittens, 271.6ms\n",
      "Speed: 3.7ms preprocess, 271.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_387.jpg\n",
      "Saved labels to: results6\\labels\\MIT_387.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_388.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_388.jpg: 640x480 21 handwrittens, 120.6ms\n",
      "Speed: 3.3ms preprocess, 120.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_388.jpg\n",
      "Saved labels to: results6\\labels\\MIT_388.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_389.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_389.jpg: 640x480 21 handwrittens, 112.7ms\n",
      "Speed: 3.0ms preprocess, 112.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_389.jpg\n",
      "Saved labels to: results6\\labels\\MIT_389.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_39.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_39.jpg: 640x480 21 handwrittens, 111.7ms\n",
      "Speed: 3.0ms preprocess, 111.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_39.jpg\n",
      "Saved labels to: results6\\labels\\MIT_39.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_390.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_390.jpg: 640x480 20 handwrittens, 170.6ms\n",
      "Speed: 4.6ms preprocess, 170.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_390.jpg\n",
      "Saved labels to: results6\\labels\\MIT_390.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_391.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_391.jpg: 640x480 20 handwrittens, 170.2ms\n",
      "Speed: 3.6ms preprocess, 170.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_391.jpg\n",
      "Saved labels to: results6\\labels\\MIT_391.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_392.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_392.jpg: 640x480 27 handwrittens, 141.2ms\n",
      "Speed: 30.7ms preprocess, 141.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_392.jpg\n",
      "Saved labels to: results6\\labels\\MIT_392.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_393.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_393.jpg: 640x480 27 handwrittens, 108.1ms\n",
      "Speed: 3.0ms preprocess, 108.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_393.jpg\n",
      "Saved labels to: results6\\labels\\MIT_393.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_394.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_394.jpg: 640x480 20 handwrittens, 163.9ms\n",
      "Speed: 3.1ms preprocess, 163.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_394.jpg\n",
      "Saved labels to: results6\\labels\\MIT_394.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_395.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_395.jpg: 640x480 24 handwrittens, 152.9ms\n",
      "Speed: 3.1ms preprocess, 152.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_395.jpg\n",
      "Saved labels to: results6\\labels\\MIT_395.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_396.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_396.jpg: 640x480 21 handwrittens, 98.5ms\n",
      "Speed: 3.2ms preprocess, 98.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_396.jpg\n",
      "Saved labels to: results6\\labels\\MIT_396.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_397.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_397.jpg: 640x480 21 handwrittens, 101.0ms\n",
      "Speed: 3.1ms preprocess, 101.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_397.jpg\n",
      "Saved labels to: results6\\labels\\MIT_397.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_398.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_398.jpg: 640x480 21 handwrittens, 154.6ms\n",
      "Speed: 2.9ms preprocess, 154.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_398.jpg\n",
      "Saved labels to: results6\\labels\\MIT_398.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_399.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_399.jpg: 640x480 21 handwrittens, 95.8ms\n",
      "Speed: 3.8ms preprocess, 95.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_399.jpg\n",
      "Saved labels to: results6\\labels\\MIT_399.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_4.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_4.jpg: 640x480 22 handwrittens, 97.5ms\n",
      "Speed: 3.0ms preprocess, 97.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_4.jpg\n",
      "Saved labels to: results6\\labels\\MIT_4.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_40.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_40.jpg: 640x480 23 handwrittens, 87.4ms\n",
      "Speed: 3.6ms preprocess, 87.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_40.jpg\n",
      "Saved labels to: results6\\labels\\MIT_40.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_400.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_400.jpg: 640x480 23 handwrittens, 102.1ms\n",
      "Speed: 3.2ms preprocess, 102.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_400.jpg\n",
      "Saved labels to: results6\\labels\\MIT_400.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_401.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_401.jpg: 640x480 24 handwrittens, 115.1ms\n",
      "Speed: 3.7ms preprocess, 115.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_401.jpg\n",
      "Saved labels to: results6\\labels\\MIT_401.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_402.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_402.jpg: 640x480 21 handwrittens, 259.1ms\n",
      "Speed: 16.4ms preprocess, 259.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_402.jpg\n",
      "Saved labels to: results6\\labels\\MIT_402.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_403.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_403.jpg: 640x480 21 handwrittens, 121.3ms\n",
      "Speed: 3.0ms preprocess, 121.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_403.jpg\n",
      "Saved labels to: results6\\labels\\MIT_403.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_404.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_404.jpg: 640x480 22 handwrittens, 116.5ms\n",
      "Speed: 3.2ms preprocess, 116.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_404.jpg\n",
      "Saved labels to: results6\\labels\\MIT_404.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_405.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_405.jpg: 640x480 21 handwrittens, 130.1ms\n",
      "Speed: 2.8ms preprocess, 130.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_405.jpg\n",
      "Saved labels to: results6\\labels\\MIT_405.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_406.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_406.jpg: 640x480 21 handwrittens, 112.7ms\n",
      "Speed: 3.1ms preprocess, 112.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_406.jpg\n",
      "Saved labels to: results6\\labels\\MIT_406.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_407.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_407.jpg: 640x480 21 handwrittens, 100.8ms\n",
      "Speed: 3.2ms preprocess, 100.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_407.jpg\n",
      "Saved labels to: results6\\labels\\MIT_407.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_408.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_408.jpg: 640x480 24 handwrittens, 138.3ms\n",
      "Speed: 81.6ms preprocess, 138.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_408.jpg\n",
      "Saved labels to: results6\\labels\\MIT_408.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_409.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_409.jpg: 640x480 22 handwrittens, 139.5ms\n",
      "Speed: 3.7ms preprocess, 139.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_409.jpg\n",
      "Saved labels to: results6\\labels\\MIT_409.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_41.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_41.jpg: 640x480 21 handwrittens, 167.1ms\n",
      "Speed: 3.7ms preprocess, 167.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_41.jpg\n",
      "Saved labels to: results6\\labels\\MIT_41.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_410.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_410.jpg: 640x480 22 handwrittens, 122.5ms\n",
      "Speed: 3.1ms preprocess, 122.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_410.jpg\n",
      "Saved labels to: results6\\labels\\MIT_410.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_411.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_411.jpg: 640x480 20 handwrittens, 125.9ms\n",
      "Speed: 2.7ms preprocess, 125.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_411.jpg\n",
      "Saved labels to: results6\\labels\\MIT_411.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_412.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_412.jpg: 640x480 24 handwrittens, 145.5ms\n",
      "Speed: 3.3ms preprocess, 145.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_412.jpg\n",
      "Saved labels to: results6\\labels\\MIT_412.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_413.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_413.jpg: 640x480 20 handwrittens, 171.2ms\n",
      "Speed: 3.1ms preprocess, 171.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_413.jpg\n",
      "Saved labels to: results6\\labels\\MIT_413.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_414.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_414.jpg: 640x480 21 handwrittens, 164.3ms\n",
      "Speed: 2.8ms preprocess, 164.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_414.jpg\n",
      "Saved labels to: results6\\labels\\MIT_414.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_415.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_415.jpg: 640x480 22 handwrittens, 149.4ms\n",
      "Speed: 3.5ms preprocess, 149.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_415.jpg\n",
      "Saved labels to: results6\\labels\\MIT_415.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_416.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_416.jpg: 640x480 22 handwrittens, 132.3ms\n",
      "Speed: 4.4ms preprocess, 132.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_416.jpg\n",
      "Saved labels to: results6\\labels\\MIT_416.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_417.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_417.jpg: 640x480 22 handwrittens, 219.7ms\n",
      "Speed: 4.6ms preprocess, 219.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_417.jpg\n",
      "Saved labels to: results6\\labels\\MIT_417.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_418.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_418.jpg: 640x480 20 handwrittens, 127.3ms\n",
      "Speed: 3.3ms preprocess, 127.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_418.jpg\n",
      "Saved labels to: results6\\labels\\MIT_418.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_419.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_419.jpg: 640x480 20 handwrittens, 214.0ms\n",
      "Speed: 4.0ms preprocess, 214.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_419.jpg\n",
      "Saved labels to: results6\\labels\\MIT_419.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_42.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_42.jpg: 640x480 23 handwrittens, 105.7ms\n",
      "Speed: 9.2ms preprocess, 105.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_42.jpg\n",
      "Saved labels to: results6\\labels\\MIT_42.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_420.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_420.jpg: 640x480 21 handwrittens, 122.5ms\n",
      "Speed: 3.1ms preprocess, 122.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_420.jpg\n",
      "Saved labels to: results6\\labels\\MIT_420.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_421.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_421.jpg: 640x480 20 handwrittens, 160.2ms\n",
      "Speed: 3.8ms preprocess, 160.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_421.jpg\n",
      "Saved labels to: results6\\labels\\MIT_421.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_422.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_422.jpg: 640x480 22 handwrittens, 141.4ms\n",
      "Speed: 3.0ms preprocess, 141.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_422.jpg\n",
      "Saved labels to: results6\\labels\\MIT_422.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_423.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_423.jpg: 640x480 20 handwrittens, 114.7ms\n",
      "Speed: 2.6ms preprocess, 114.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_423.jpg\n",
      "Saved labels to: results6\\labels\\MIT_423.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_424.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_424.jpg: 640x480 23 handwrittens, 222.8ms\n",
      "Speed: 4.3ms preprocess, 222.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_424.jpg\n",
      "Saved labels to: results6\\labels\\MIT_424.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_425.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_425.jpg: 640x480 25 handwrittens, 133.2ms\n",
      "Speed: 6.0ms preprocess, 133.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_425.jpg\n",
      "Saved labels to: results6\\labels\\MIT_425.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_426.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_426.jpg: 640x480 27 handwrittens, 105.1ms\n",
      "Speed: 4.0ms preprocess, 105.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_426.jpg\n",
      "Saved labels to: results6\\labels\\MIT_426.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_427.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_427.jpg: 640x480 27 handwrittens, 111.6ms\n",
      "Speed: 3.0ms preprocess, 111.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_427.jpg\n",
      "Saved labels to: results6\\labels\\MIT_427.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_428.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_428.jpg: 640x480 23 handwrittens, 166.8ms\n",
      "Speed: 12.4ms preprocess, 166.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_428.jpg\n",
      "Saved labels to: results6\\labels\\MIT_428.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_429.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_429.jpg: 640x480 21 handwrittens, 150.0ms\n",
      "Speed: 3.5ms preprocess, 150.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_429.jpg\n",
      "Saved labels to: results6\\labels\\MIT_429.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_43.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_43.jpg: 640x480 25 handwrittens, 143.3ms\n",
      "Speed: 31.9ms preprocess, 143.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_43.jpg\n",
      "Saved labels to: results6\\labels\\MIT_43.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_430.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_430.jpg: 640x480 20 handwrittens, 117.9ms\n",
      "Speed: 3.8ms preprocess, 117.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_430.jpg\n",
      "Saved labels to: results6\\labels\\MIT_430.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_431.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_431.jpg: 640x480 21 handwrittens, 121.3ms\n",
      "Speed: 2.2ms preprocess, 121.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_431.jpg\n",
      "Saved labels to: results6\\labels\\MIT_431.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_432.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_432.jpg: 640x480 20 handwrittens, 155.9ms\n",
      "Speed: 4.2ms preprocess, 155.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_432.jpg\n",
      "Saved labels to: results6\\labels\\MIT_432.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_433.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_433.jpg: 640x480 21 handwrittens, 116.1ms\n",
      "Speed: 3.4ms preprocess, 116.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_433.jpg\n",
      "Saved labels to: results6\\labels\\MIT_433.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_434.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_434.jpg: 640x480 37 handwrittens, 100.8ms\n",
      "Speed: 3.7ms preprocess, 100.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_434.jpg\n",
      "Saved labels to: results6\\labels\\MIT_434.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_435.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_435.jpg: 640x480 21 handwrittens, 159.9ms\n",
      "Speed: 4.5ms preprocess, 159.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_435.jpg\n",
      "Saved labels to: results6\\labels\\MIT_435.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_436.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_436.jpg: 640x480 21 handwrittens, 143.4ms\n",
      "Speed: 5.6ms preprocess, 143.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_436.jpg\n",
      "Saved labels to: results6\\labels\\MIT_436.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_437.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_437.jpg: 640x480 19 handwrittens, 112.9ms\n",
      "Speed: 3.8ms preprocess, 112.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_437.jpg\n",
      "Saved labels to: results6\\labels\\MIT_437.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_438.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_438.jpg: 640x480 22 handwrittens, 113.5ms\n",
      "Speed: 3.4ms preprocess, 113.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_438.jpg\n",
      "Saved labels to: results6\\labels\\MIT_438.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_439.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_439.jpg: 640x480 21 handwrittens, 111.7ms\n",
      "Speed: 3.7ms preprocess, 111.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_439.jpg\n",
      "Saved labels to: results6\\labels\\MIT_439.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_44.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_44.jpg: 640x480 22 handwrittens, 103.6ms\n",
      "Speed: 3.7ms preprocess, 103.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_44.jpg\n",
      "Saved labels to: results6\\labels\\MIT_44.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_440.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_440.jpg: 640x480 21 handwrittens, 142.4ms\n",
      "Speed: 7.3ms preprocess, 142.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_440.jpg\n",
      "Saved labels to: results6\\labels\\MIT_440.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_441.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_441.jpg: 640x480 20 handwrittens, 98.7ms\n",
      "Speed: 5.3ms preprocess, 98.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_441.jpg\n",
      "Saved labels to: results6\\labels\\MIT_441.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_442.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_442.jpg: 640x480 22 handwrittens, 162.9ms\n",
      "Speed: 3.4ms preprocess, 162.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_442.jpg\n",
      "Saved labels to: results6\\labels\\MIT_442.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_443.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_443.jpg: 640x480 21 handwrittens, 133.7ms\n",
      "Speed: 3.2ms preprocess, 133.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_443.jpg\n",
      "Saved labels to: results6\\labels\\MIT_443.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_444.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_444.jpg: 640x480 21 handwrittens, 124.3ms\n",
      "Speed: 4.4ms preprocess, 124.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_444.jpg\n",
      "Saved labels to: results6\\labels\\MIT_444.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_445.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_445.jpg: 640x480 23 handwrittens, 100.9ms\n",
      "Speed: 3.3ms preprocess, 100.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_445.jpg\n",
      "Saved labels to: results6\\labels\\MIT_445.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_446.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_446.jpg: 640x480 22 handwrittens, 141.7ms\n",
      "Speed: 31.8ms preprocess, 141.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_446.jpg\n",
      "Saved labels to: results6\\labels\\MIT_446.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_447.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_447.jpg: 640x480 21 handwrittens, 114.6ms\n",
      "Speed: 8.9ms preprocess, 114.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_447.jpg\n",
      "Saved labels to: results6\\labels\\MIT_447.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_448.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_448.jpg: 640x480 24 handwrittens, 102.2ms\n",
      "Speed: 3.7ms preprocess, 102.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_448.jpg\n",
      "Saved labels to: results6\\labels\\MIT_448.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_449.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_449.jpg: 640x480 21 handwrittens, 116.5ms\n",
      "Speed: 3.4ms preprocess, 116.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_449.jpg\n",
      "Saved labels to: results6\\labels\\MIT_449.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_45.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_45.jpg: 640x480 22 handwrittens, 206.2ms\n",
      "Speed: 3.5ms preprocess, 206.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_45.jpg\n",
      "Saved labels to: results6\\labels\\MIT_45.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_450.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_450.jpg: 640x480 21 handwrittens, 207.1ms\n",
      "Speed: 3.4ms preprocess, 207.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_450.jpg\n",
      "Saved labels to: results6\\labels\\MIT_450.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_451.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_451.jpg: 640x480 21 handwrittens, 175.4ms\n",
      "Speed: 3.2ms preprocess, 175.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_451.jpg\n",
      "Saved labels to: results6\\labels\\MIT_451.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_452.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_452.jpg: 640x480 24 handwrittens, 111.9ms\n",
      "Speed: 3.4ms preprocess, 111.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_452.jpg\n",
      "Saved labels to: results6\\labels\\MIT_452.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_453.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_453.jpg: 640x480 24 handwrittens, 105.9ms\n",
      "Speed: 3.4ms preprocess, 105.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_453.jpg\n",
      "Saved labels to: results6\\labels\\MIT_453.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_454.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_454.jpg: 640x480 22 handwrittens, 110.9ms\n",
      "Speed: 3.6ms preprocess, 110.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_454.jpg\n",
      "Saved labels to: results6\\labels\\MIT_454.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_455.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_455.jpg: 640x480 24 handwrittens, 112.3ms\n",
      "Speed: 4.0ms preprocess, 112.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_455.jpg\n",
      "Saved labels to: results6\\labels\\MIT_455.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_456.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_456.jpg: 640x480 28 handwrittens, 101.1ms\n",
      "Speed: 2.4ms preprocess, 101.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_456.jpg\n",
      "Saved labels to: results6\\labels\\MIT_456.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_457.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_457.jpg: 640x480 21 handwrittens, 207.1ms\n",
      "Speed: 3.3ms preprocess, 207.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_457.jpg\n",
      "Saved labels to: results6\\labels\\MIT_457.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_458.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_458.jpg: 640x480 23 handwrittens, 107.1ms\n",
      "Speed: 3.0ms preprocess, 107.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_458.jpg\n",
      "Saved labels to: results6\\labels\\MIT_458.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_459.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_459.jpg: 640x480 21 handwrittens, 128.5ms\n",
      "Speed: 5.4ms preprocess, 128.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_459.jpg\n",
      "Saved labels to: results6\\labels\\MIT_459.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_46.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_46.jpg: 640x480 28 handwrittens, 123.4ms\n",
      "Speed: 3.3ms preprocess, 123.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_46.jpg\n",
      "Saved labels to: results6\\labels\\MIT_46.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_460.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_460.jpg: 640x480 24 handwrittens, 111.2ms\n",
      "Speed: 2.8ms preprocess, 111.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_460.jpg\n",
      "Saved labels to: results6\\labels\\MIT_460.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_461.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_461.jpg: 640x480 20 handwrittens, 107.7ms\n",
      "Speed: 3.1ms preprocess, 107.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_461.jpg\n",
      "Saved labels to: results6\\labels\\MIT_461.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_462.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_462.jpg: 640x480 22 handwrittens, 145.2ms\n",
      "Speed: 4.4ms preprocess, 145.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_462.jpg\n",
      "Saved labels to: results6\\labels\\MIT_462.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_463.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_463.jpg: 640x480 22 handwrittens, 115.4ms\n",
      "Speed: 3.2ms preprocess, 115.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_463.jpg\n",
      "Saved labels to: results6\\labels\\MIT_463.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_464.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_464.jpg: 640x480 21 handwrittens, 100.5ms\n",
      "Speed: 3.7ms preprocess, 100.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_464.jpg\n",
      "Saved labels to: results6\\labels\\MIT_464.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_465.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_465.jpg: 640x480 20 handwrittens, 150.3ms\n",
      "Speed: 3.3ms preprocess, 150.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_465.jpg\n",
      "Saved labels to: results6\\labels\\MIT_465.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_466.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_466.jpg: 640x480 22 handwrittens, 220.5ms\n",
      "Speed: 4.2ms preprocess, 220.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_466.jpg\n",
      "Saved labels to: results6\\labels\\MIT_466.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_467.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_467.jpg: 640x480 21 handwrittens, 115.0ms\n",
      "Speed: 3.3ms preprocess, 115.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_467.jpg\n",
      "Saved labels to: results6\\labels\\MIT_467.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_468.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_468.jpg: 640x480 21 handwrittens, 154.0ms\n",
      "Speed: 2.2ms preprocess, 154.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_468.jpg\n",
      "Saved labels to: results6\\labels\\MIT_468.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_469.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_469.jpg: 640x480 21 handwrittens, 107.7ms\n",
      "Speed: 3.4ms preprocess, 107.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_469.jpg\n",
      "Saved labels to: results6\\labels\\MIT_469.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_47.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_47.jpg: 640x480 20 handwrittens, 104.4ms\n",
      "Speed: 3.2ms preprocess, 104.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_47.jpg\n",
      "Saved labels to: results6\\labels\\MIT_47.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_470.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_470.jpg: 640x480 19 handwrittens, 100.1ms\n",
      "Speed: 3.2ms preprocess, 100.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_470.jpg\n",
      "Saved labels to: results6\\labels\\MIT_470.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_471.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_471.jpg: 640x480 24 handwrittens, 92.5ms\n",
      "Speed: 2.5ms preprocess, 92.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_471.jpg\n",
      "Saved labels to: results6\\labels\\MIT_471.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_472.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_472.jpg: 640x480 22 handwrittens, 131.2ms\n",
      "Speed: 3.5ms preprocess, 131.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_472.jpg\n",
      "Saved labels to: results6\\labels\\MIT_472.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_473.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_473.jpg: 640x480 22 handwrittens, 115.1ms\n",
      "Speed: 3.7ms preprocess, 115.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_473.jpg\n",
      "Saved labels to: results6\\labels\\MIT_473.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_474.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_474.jpg: 640x480 21 handwrittens, 178.1ms\n",
      "Speed: 3.1ms preprocess, 178.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_474.jpg\n",
      "Saved labels to: results6\\labels\\MIT_474.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_475.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_475.jpg: 640x480 22 handwrittens, 111.2ms\n",
      "Speed: 3.3ms preprocess, 111.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_475.jpg\n",
      "Saved labels to: results6\\labels\\MIT_475.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_476.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_476.jpg: 640x480 21 handwrittens, 113.9ms\n",
      "Speed: 2.9ms preprocess, 113.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_476.jpg\n",
      "Saved labels to: results6\\labels\\MIT_476.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_477.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_477.jpg: 640x480 22 handwrittens, 106.5ms\n",
      "Speed: 3.6ms preprocess, 106.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_477.jpg\n",
      "Saved labels to: results6\\labels\\MIT_477.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_478.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_478.jpg: 640x480 21 handwrittens, 125.3ms\n",
      "Speed: 4.4ms preprocess, 125.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_478.jpg\n",
      "Saved labels to: results6\\labels\\MIT_478.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_479.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_479.jpg: 640x480 21 handwrittens, 114.3ms\n",
      "Speed: 8.8ms preprocess, 114.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_479.jpg\n",
      "Saved labels to: results6\\labels\\MIT_479.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_48.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_48.jpg: 640x480 22 handwrittens, 111.1ms\n",
      "Speed: 3.0ms preprocess, 111.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_48.jpg\n",
      "Saved labels to: results6\\labels\\MIT_48.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_480.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_480.jpg: 640x480 21 handwrittens, 103.8ms\n",
      "Speed: 2.7ms preprocess, 103.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_480.jpg\n",
      "Saved labels to: results6\\labels\\MIT_480.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_481.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_481.jpg: 640x480 23 handwrittens, 141.3ms\n",
      "Speed: 2.8ms preprocess, 141.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_481.jpg\n",
      "Saved labels to: results6\\labels\\MIT_481.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_482.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_482.jpg: 640x480 21 handwrittens, 128.5ms\n",
      "Speed: 2.6ms preprocess, 128.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_482.jpg\n",
      "Saved labels to: results6\\labels\\MIT_482.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_483.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_483.jpg: 640x480 20 handwrittens, 135.6ms\n",
      "Speed: 3.8ms preprocess, 135.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_483.jpg\n",
      "Saved labels to: results6\\labels\\MIT_483.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_484.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_484.jpg: 640x480 25 handwrittens, 192.2ms\n",
      "Speed: 3.1ms preprocess, 192.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_484.jpg\n",
      "Saved labels to: results6\\labels\\MIT_484.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_485.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_485.jpg: 640x480 22 handwrittens, 134.5ms\n",
      "Speed: 3.4ms preprocess, 134.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_485.jpg\n",
      "Saved labels to: results6\\labels\\MIT_485.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_486.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_486.jpg: 640x480 25 handwrittens, 92.9ms\n",
      "Speed: 2.6ms preprocess, 92.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_486.jpg\n",
      "Saved labels to: results6\\labels\\MIT_486.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_487.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_487.jpg: 640x480 24 handwrittens, 89.7ms\n",
      "Speed: 2.7ms preprocess, 89.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_487.jpg\n",
      "Saved labels to: results6\\labels\\MIT_487.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_488.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_488.jpg: 640x480 23 handwrittens, 115.1ms\n",
      "Speed: 3.3ms preprocess, 115.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_488.jpg\n",
      "Saved labels to: results6\\labels\\MIT_488.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_489.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_489.jpg: 640x480 22 handwrittens, 191.2ms\n",
      "Speed: 3.0ms preprocess, 191.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_489.jpg\n",
      "Saved labels to: results6\\labels\\MIT_489.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_49.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_49.jpg: 640x480 20 handwrittens, 112.5ms\n",
      "Speed: 3.8ms preprocess, 112.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_49.jpg\n",
      "Saved labels to: results6\\labels\\MIT_49.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_490.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_490.jpg: 640x480 22 handwrittens, 130.6ms\n",
      "Speed: 3.2ms preprocess, 130.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_490.jpg\n",
      "Saved labels to: results6\\labels\\MIT_490.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_491.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_491.jpg: 640x480 23 handwrittens, 113.9ms\n",
      "Speed: 3.3ms preprocess, 113.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_491.jpg\n",
      "Saved labels to: results6\\labels\\MIT_491.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_492.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_492.jpg: 640x480 21 handwrittens, 134.6ms\n",
      "Speed: 2.9ms preprocess, 134.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_492.jpg\n",
      "Saved labels to: results6\\labels\\MIT_492.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_493.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_493.jpg: 640x480 22 handwrittens, 123.0ms\n",
      "Speed: 3.9ms preprocess, 123.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_493.jpg\n",
      "Saved labels to: results6\\labels\\MIT_493.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_494.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_494.jpg: 640x480 20 handwrittens, 163.4ms\n",
      "Speed: 2.7ms preprocess, 163.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_494.jpg\n",
      "Saved labels to: results6\\labels\\MIT_494.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_495.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_495.jpg: 640x480 20 handwrittens, 142.4ms\n",
      "Speed: 3.4ms preprocess, 142.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_495.jpg\n",
      "Saved labels to: results6\\labels\\MIT_495.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_496.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_496.jpg: 640x480 23 handwrittens, 128.0ms\n",
      "Speed: 4.2ms preprocess, 128.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_496.jpg\n",
      "Saved labels to: results6\\labels\\MIT_496.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_497.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_497.jpg: 640x480 20 handwrittens, 116.2ms\n",
      "Speed: 3.1ms preprocess, 116.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_497.jpg\n",
      "Saved labels to: results6\\labels\\MIT_497.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_498.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_498.jpg: 640x480 21 handwrittens, 114.3ms\n",
      "Speed: 3.1ms preprocess, 114.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_498.jpg\n",
      "Saved labels to: results6\\labels\\MIT_498.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_499.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_499.jpg: 640x480 29 handwrittens, 135.2ms\n",
      "Speed: 3.1ms preprocess, 135.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_499.jpg\n",
      "Saved labels to: results6\\labels\\MIT_499.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_5.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_5.jpg: 640x480 22 handwrittens, 124.2ms\n",
      "Speed: 4.4ms preprocess, 124.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_5.jpg\n",
      "Saved labels to: results6\\labels\\MIT_5.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_50.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_50.jpg: 640x480 21 handwrittens, 137.3ms\n",
      "Speed: 3.5ms preprocess, 137.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_50.jpg\n",
      "Saved labels to: results6\\labels\\MIT_50.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_500.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_500.jpg: 640x480 22 handwrittens, 91.8ms\n",
      "Speed: 3.1ms preprocess, 91.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_500.jpg\n",
      "Saved labels to: results6\\labels\\MIT_500.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_501.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_501.jpg: 640x480 24 handwrittens, 154.8ms\n",
      "Speed: 3.9ms preprocess, 154.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_501.jpg\n",
      "Saved labels to: results6\\labels\\MIT_501.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_502.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_502.jpg: 640x480 27 handwrittens, 124.8ms\n",
      "Speed: 3.6ms preprocess, 124.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_502.jpg\n",
      "Saved labels to: results6\\labels\\MIT_502.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_503.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_503.jpg: 640x480 27 handwrittens, 106.9ms\n",
      "Speed: 3.3ms preprocess, 106.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_503.jpg\n",
      "Saved labels to: results6\\labels\\MIT_503.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_504.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_504.jpg: 640x480 21 handwrittens, 118.4ms\n",
      "Speed: 7.9ms preprocess, 118.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_504.jpg\n",
      "Saved labels to: results6\\labels\\MIT_504.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_505.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_505.jpg: 640x480 20 handwrittens, 114.0ms\n",
      "Speed: 5.0ms preprocess, 114.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_505.jpg\n",
      "Saved labels to: results6\\labels\\MIT_505.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_506.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_506.jpg: 640x480 26 handwrittens, 113.3ms\n",
      "Speed: 3.4ms preprocess, 113.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_506.jpg\n",
      "Saved labels to: results6\\labels\\MIT_506.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_507.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_507.jpg: 640x480 21 handwrittens, 129.0ms\n",
      "Speed: 3.3ms preprocess, 129.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_507.jpg\n",
      "Saved labels to: results6\\labels\\MIT_507.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_508.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_508.jpg: 640x480 23 handwrittens, 106.8ms\n",
      "Speed: 3.0ms preprocess, 106.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_508.jpg\n",
      "Saved labels to: results6\\labels\\MIT_508.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_509.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_509.jpg: 640x480 22 handwrittens, 106.1ms\n",
      "Speed: 3.1ms preprocess, 106.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_509.jpg\n",
      "Saved labels to: results6\\labels\\MIT_509.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_51.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_51.jpg: 640x480 20 handwrittens, 125.7ms\n",
      "Speed: 6.0ms preprocess, 125.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_51.jpg\n",
      "Saved labels to: results6\\labels\\MIT_51.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_510.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_510.jpg: 640x480 24 handwrittens, 183.4ms\n",
      "Speed: 8.8ms preprocess, 183.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_510.jpg\n",
      "Saved labels to: results6\\labels\\MIT_510.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_511.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_511.jpg: 640x480 21 handwrittens, 133.0ms\n",
      "Speed: 3.5ms preprocess, 133.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_511.jpg\n",
      "Saved labels to: results6\\labels\\MIT_511.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_512.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_512.jpg: 640x480 23 handwrittens, 101.2ms\n",
      "Speed: 2.8ms preprocess, 101.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_512.jpg\n",
      "Saved labels to: results6\\labels\\MIT_512.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_513.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_513.jpg: 640x480 21 handwrittens, 109.2ms\n",
      "Speed: 2.8ms preprocess, 109.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_513.jpg\n",
      "Saved labels to: results6\\labels\\MIT_513.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_514.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_514.jpg: 640x480 24 handwrittens, 105.0ms\n",
      "Speed: 2.8ms preprocess, 105.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_514.jpg\n",
      "Saved labels to: results6\\labels\\MIT_514.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_515.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_515.jpg: 640x480 20 handwrittens, 123.9ms\n",
      "Speed: 3.3ms preprocess, 123.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_515.jpg\n",
      "Saved labels to: results6\\labels\\MIT_515.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_516.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_516.jpg: 640x480 21 handwrittens, 115.5ms\n",
      "Speed: 2.9ms preprocess, 115.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_516.jpg\n",
      "Saved labels to: results6\\labels\\MIT_516.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_517.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_517.jpg: 640x480 23 handwrittens, 131.1ms\n",
      "Speed: 3.2ms preprocess, 131.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_517.jpg\n",
      "Saved labels to: results6\\labels\\MIT_517.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_518.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_518.jpg: 640x480 20 handwrittens, 114.0ms\n",
      "Speed: 3.5ms preprocess, 114.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_518.jpg\n",
      "Saved labels to: results6\\labels\\MIT_518.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_519.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_519.jpg: 640x480 25 handwrittens, 107.2ms\n",
      "Speed: 3.0ms preprocess, 107.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_519.jpg\n",
      "Saved labels to: results6\\labels\\MIT_519.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_52.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_52.jpg: 640x480 22 handwrittens, 178.9ms\n",
      "Speed: 3.1ms preprocess, 178.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_52.jpg\n",
      "Saved labels to: results6\\labels\\MIT_52.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_520.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_520.jpg: 640x480 23 handwrittens, 110.3ms\n",
      "Speed: 3.3ms preprocess, 110.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_520.jpg\n",
      "Saved labels to: results6\\labels\\MIT_520.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_521.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_521.jpg: 640x480 21 handwrittens, 107.3ms\n",
      "Speed: 3.4ms preprocess, 107.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_521.jpg\n",
      "Saved labels to: results6\\labels\\MIT_521.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_522.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_522.jpg: 640x480 24 handwrittens, 107.4ms\n",
      "Speed: 2.9ms preprocess, 107.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_522.jpg\n",
      "Saved labels to: results6\\labels\\MIT_522.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_523.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_523.jpg: 640x480 25 handwrittens, 130.0ms\n",
      "Speed: 3.7ms preprocess, 130.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_523.jpg\n",
      "Saved labels to: results6\\labels\\MIT_523.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_524.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_524.jpg: 640x480 21 handwrittens, 142.1ms\n",
      "Speed: 3.0ms preprocess, 142.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_524.jpg\n",
      "Saved labels to: results6\\labels\\MIT_524.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_525.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_525.jpg: 640x480 28 handwrittens, 149.7ms\n",
      "Speed: 14.9ms preprocess, 149.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_525.jpg\n",
      "Saved labels to: results6\\labels\\MIT_525.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_526.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_526.jpg: 640x480 23 handwrittens, 125.5ms\n",
      "Speed: 3.4ms preprocess, 125.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_526.jpg\n",
      "Saved labels to: results6\\labels\\MIT_526.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_527.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_527.jpg: 640x480 26 handwrittens, 143.6ms\n",
      "Speed: 3.9ms preprocess, 143.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_527.jpg\n",
      "Saved labels to: results6\\labels\\MIT_527.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_528.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_528.jpg: 640x480 24 handwrittens, 114.0ms\n",
      "Speed: 3.2ms preprocess, 114.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_528.jpg\n",
      "Saved labels to: results6\\labels\\MIT_528.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_529.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_529.jpg: 640x480 21 handwrittens, 105.9ms\n",
      "Speed: 4.2ms preprocess, 105.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_529.jpg\n",
      "Saved labels to: results6\\labels\\MIT_529.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_53.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_53.jpg: 640x480 20 handwrittens, 111.0ms\n",
      "Speed: 2.6ms preprocess, 111.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_53.jpg\n",
      "Saved labels to: results6\\labels\\MIT_53.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_530.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_530.jpg: 640x480 28 handwrittens, 147.9ms\n",
      "Speed: 3.1ms preprocess, 147.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_530.jpg\n",
      "Saved labels to: results6\\labels\\MIT_530.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_531.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_531.jpg: 640x480 23 handwrittens, 158.1ms\n",
      "Speed: 3.4ms preprocess, 158.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_531.jpg\n",
      "Saved labels to: results6\\labels\\MIT_531.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_532.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_532.jpg: 640x480 22 handwrittens, 114.7ms\n",
      "Speed: 2.7ms preprocess, 114.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_532.jpg\n",
      "Saved labels to: results6\\labels\\MIT_532.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_533.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_533.jpg: 640x480 25 handwrittens, 167.7ms\n",
      "Speed: 3.6ms preprocess, 167.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_533.jpg\n",
      "Saved labels to: results6\\labels\\MIT_533.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_534.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_534.jpg: 640x480 20 handwrittens, 122.0ms\n",
      "Speed: 3.0ms preprocess, 122.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_534.jpg\n",
      "Saved labels to: results6\\labels\\MIT_534.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_535.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_535.jpg: 640x480 21 handwrittens, 110.0ms\n",
      "Speed: 8.1ms preprocess, 110.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_535.jpg\n",
      "Saved labels to: results6\\labels\\MIT_535.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_536.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_536.jpg: 640x480 21 handwrittens, 115.5ms\n",
      "Speed: 3.4ms preprocess, 115.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_536.jpg\n",
      "Saved labels to: results6\\labels\\MIT_536.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_537.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_537.jpg: 640x480 20 handwrittens, 103.3ms\n",
      "Speed: 1.9ms preprocess, 103.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_537.jpg\n",
      "Saved labels to: results6\\labels\\MIT_537.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_538.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_538.jpg: 640x480 22 handwrittens, 102.3ms\n",
      "Speed: 2.1ms preprocess, 102.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_538.jpg\n",
      "Saved labels to: results6\\labels\\MIT_538.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_539.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_539.jpg: 640x480 23 handwrittens, 101.1ms\n",
      "Speed: 2.9ms preprocess, 101.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_539.jpg\n",
      "Saved labels to: results6\\labels\\MIT_539.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_54.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_54.jpg: 640x480 21 handwrittens, 181.5ms\n",
      "Speed: 3.3ms preprocess, 181.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_54.jpg\n",
      "Saved labels to: results6\\labels\\MIT_54.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_540.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_540.jpg: 640x480 22 handwrittens, 251.7ms\n",
      "Speed: 5.7ms preprocess, 251.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_540.jpg\n",
      "Saved labels to: results6\\labels\\MIT_540.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_541.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_541.jpg: 640x480 23 handwrittens, 123.5ms\n",
      "Speed: 3.3ms preprocess, 123.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_541.jpg\n",
      "Saved labels to: results6\\labels\\MIT_541.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_542.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_542.jpg: 640x480 22 handwrittens, 104.8ms\n",
      "Speed: 3.1ms preprocess, 104.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_542.jpg\n",
      "Saved labels to: results6\\labels\\MIT_542.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_543.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_543.jpg: 640x480 22 handwrittens, 105.6ms\n",
      "Speed: 4.3ms preprocess, 105.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_543.jpg\n",
      "Saved labels to: results6\\labels\\MIT_543.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_544.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_544.jpg: 640x480 22 handwrittens, 104.4ms\n",
      "Speed: 2.9ms preprocess, 104.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_544.jpg\n",
      "Saved labels to: results6\\labels\\MIT_544.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_545.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_545.jpg: 640x480 21 handwrittens, 112.9ms\n",
      "Speed: 2.8ms preprocess, 112.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_545.jpg\n",
      "Saved labels to: results6\\labels\\MIT_545.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_546.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_546.jpg: 640x480 21 handwrittens, 97.7ms\n",
      "Speed: 2.3ms preprocess, 97.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_546.jpg\n",
      "Saved labels to: results6\\labels\\MIT_546.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_547.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_547.jpg: 640x480 21 handwrittens, 130.4ms\n",
      "Speed: 3.2ms preprocess, 130.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_547.jpg\n",
      "Saved labels to: results6\\labels\\MIT_547.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_548.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_548.jpg: 640x480 22 handwrittens, 120.8ms\n",
      "Speed: 3.2ms preprocess, 120.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_548.jpg\n",
      "Saved labels to: results6\\labels\\MIT_548.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_549.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_549.jpg: 640x480 21 handwrittens, 189.2ms\n",
      "Speed: 4.3ms preprocess, 189.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_549.jpg\n",
      "Saved labels to: results6\\labels\\MIT_549.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_55.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_55.jpg: 640x480 21 handwrittens, 137.4ms\n",
      "Speed: 3.2ms preprocess, 137.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_55.jpg\n",
      "Saved labels to: results6\\labels\\MIT_55.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_550.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_550.jpg: 640x480 23 handwrittens, 161.6ms\n",
      "Speed: 3.2ms preprocess, 161.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_550.jpg\n",
      "Saved labels to: results6\\labels\\MIT_550.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_551.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_551.jpg: 640x480 22 handwrittens, 111.4ms\n",
      "Speed: 4.9ms preprocess, 111.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_551.jpg\n",
      "Saved labels to: results6\\labels\\MIT_551.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_552.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_552.jpg: 640x480 24 handwrittens, 106.5ms\n",
      "Speed: 3.0ms preprocess, 106.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_552.jpg\n",
      "Saved labels to: results6\\labels\\MIT_552.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_553.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_553.jpg: 640x480 22 handwrittens, 85.7ms\n",
      "Speed: 2.9ms preprocess, 85.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_553.jpg\n",
      "Saved labels to: results6\\labels\\MIT_553.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_554.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_554.jpg: 640x480 22 handwrittens, 124.3ms\n",
      "Speed: 3.0ms preprocess, 124.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_554.jpg\n",
      "Saved labels to: results6\\labels\\MIT_554.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_555.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_555.jpg: 640x480 21 handwrittens, 105.8ms\n",
      "Speed: 3.2ms preprocess, 105.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_555.jpg\n",
      "Saved labels to: results6\\labels\\MIT_555.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_556.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_556.jpg: 640x480 22 handwrittens, 155.3ms\n",
      "Speed: 12.7ms preprocess, 155.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_556.jpg\n",
      "Saved labels to: results6\\labels\\MIT_556.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_557.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_557.jpg: 640x480 22 handwrittens, 146.1ms\n",
      "Speed: 3.2ms preprocess, 146.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_557.jpg\n",
      "Saved labels to: results6\\labels\\MIT_557.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_558.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_558.jpg: 640x480 20 handwrittens, 121.8ms\n",
      "Speed: 3.7ms preprocess, 121.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_558.jpg\n",
      "Saved labels to: results6\\labels\\MIT_558.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_559.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_559.jpg: 640x480 22 handwrittens, 116.7ms\n",
      "Speed: 3.9ms preprocess, 116.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_559.jpg\n",
      "Saved labels to: results6\\labels\\MIT_559.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_56.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_56.jpg: 640x480 21 handwrittens, 108.8ms\n",
      "Speed: 7.4ms preprocess, 108.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_56.jpg\n",
      "Saved labels to: results6\\labels\\MIT_56.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_560.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_560.jpg: 640x480 22 handwrittens, 90.8ms\n",
      "Speed: 3.1ms preprocess, 90.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_560.jpg\n",
      "Saved labels to: results6\\labels\\MIT_560.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_561.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_561.jpg: 640x480 26 handwrittens, 102.7ms\n",
      "Speed: 2.7ms preprocess, 102.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_561.jpg\n",
      "Saved labels to: results6\\labels\\MIT_561.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_562.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_562.jpg: 640x480 21 handwrittens, 110.5ms\n",
      "Speed: 2.9ms preprocess, 110.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_562.jpg\n",
      "Saved labels to: results6\\labels\\MIT_562.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_563.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_563.jpg: 640x480 22 handwrittens, 154.7ms\n",
      "Speed: 3.2ms preprocess, 154.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_563.jpg\n",
      "Saved labels to: results6\\labels\\MIT_563.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_564.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_564.jpg: 640x480 22 handwrittens, 99.9ms\n",
      "Speed: 3.4ms preprocess, 99.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_564.jpg\n",
      "Saved labels to: results6\\labels\\MIT_564.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_565.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_565.jpg: 640x480 23 handwrittens, 134.4ms\n",
      "Speed: 3.2ms preprocess, 134.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_565.jpg\n",
      "Saved labels to: results6\\labels\\MIT_565.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_566.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_566.jpg: 640x480 31 handwrittens, 205.6ms\n",
      "Speed: 4.0ms preprocess, 205.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_566.jpg\n",
      "Saved labels to: results6\\labels\\MIT_566.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_567.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_567.jpg: 640x480 25 handwrittens, 113.7ms\n",
      "Speed: 3.4ms preprocess, 113.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_567.jpg\n",
      "Saved labels to: results6\\labels\\MIT_567.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_568.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_568.jpg: 640x480 21 handwrittens, 108.1ms\n",
      "Speed: 3.3ms preprocess, 108.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_568.jpg\n",
      "Saved labels to: results6\\labels\\MIT_568.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_569.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_569.jpg: 640x480 22 handwrittens, 115.0ms\n",
      "Speed: 2.4ms preprocess, 115.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_569.jpg\n",
      "Saved labels to: results6\\labels\\MIT_569.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_57.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_57.jpg: 640x480 23 handwrittens, 109.6ms\n",
      "Speed: 2.8ms preprocess, 109.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_57.jpg\n",
      "Saved labels to: results6\\labels\\MIT_57.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_570.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_570.jpg: 640x480 21 handwrittens, 132.4ms\n",
      "Speed: 3.2ms preprocess, 132.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_570.jpg\n",
      "Saved labels to: results6\\labels\\MIT_570.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_571.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_571.jpg: 640x480 24 handwrittens, 101.6ms\n",
      "Speed: 3.2ms preprocess, 101.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_571.jpg\n",
      "Saved labels to: results6\\labels\\MIT_571.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_572.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_572.jpg: 640x480 23 handwrittens, 120.4ms\n",
      "Speed: 2.7ms preprocess, 120.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_572.jpg\n",
      "Saved labels to: results6\\labels\\MIT_572.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_573.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_573.jpg: 640x480 20 handwrittens, 160.5ms\n",
      "Speed: 3.4ms preprocess, 160.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_573.jpg\n",
      "Saved labels to: results6\\labels\\MIT_573.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_574.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_574.jpg: 640x480 20 handwrittens, 137.6ms\n",
      "Speed: 4.1ms preprocess, 137.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_574.jpg\n",
      "Saved labels to: results6\\labels\\MIT_574.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_575.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_575.jpg: 640x480 22 handwrittens, 108.0ms\n",
      "Speed: 2.3ms preprocess, 108.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_575.jpg\n",
      "Saved labels to: results6\\labels\\MIT_575.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_576.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_576.jpg: 640x480 23 handwrittens, 117.0ms\n",
      "Speed: 24.1ms preprocess, 117.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_576.jpg\n",
      "Saved labels to: results6\\labels\\MIT_576.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_577.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_577.jpg: 640x480 21 handwrittens, 128.9ms\n",
      "Speed: 2.7ms preprocess, 128.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_577.jpg\n",
      "Saved labels to: results6\\labels\\MIT_577.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_578.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_578.jpg: 640x480 23 handwrittens, 139.6ms\n",
      "Speed: 2.6ms preprocess, 139.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_578.jpg\n",
      "Saved labels to: results6\\labels\\MIT_578.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_579.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_579.jpg: 640x480 20 handwrittens, 103.3ms\n",
      "Speed: 2.9ms preprocess, 103.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_579.jpg\n",
      "Saved labels to: results6\\labels\\MIT_579.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_58.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_58.jpg: 640x480 25 handwrittens, 118.6ms\n",
      "Speed: 3.5ms preprocess, 118.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_58.jpg\n",
      "Saved labels to: results6\\labels\\MIT_58.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_580.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_580.jpg: 640x480 22 handwrittens, 111.6ms\n",
      "Speed: 3.0ms preprocess, 111.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_580.jpg\n",
      "Saved labels to: results6\\labels\\MIT_580.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_581.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_581.jpg: 640x480 22 handwrittens, 127.1ms\n",
      "Speed: 3.5ms preprocess, 127.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_581.jpg\n",
      "Saved labels to: results6\\labels\\MIT_581.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_582.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_582.jpg: 640x480 22 handwrittens, 114.7ms\n",
      "Speed: 3.1ms preprocess, 114.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_582.jpg\n",
      "Saved labels to: results6\\labels\\MIT_582.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_583.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_583.jpg: 640x480 21 handwrittens, 95.5ms\n",
      "Speed: 2.6ms preprocess, 95.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_583.jpg\n",
      "Saved labels to: results6\\labels\\MIT_583.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_584.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_584.jpg: 640x480 20 handwrittens, 165.8ms\n",
      "Speed: 4.8ms preprocess, 165.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_584.jpg\n",
      "Saved labels to: results6\\labels\\MIT_584.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_585.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_585.jpg: 640x480 20 handwrittens, 116.1ms\n",
      "Speed: 2.9ms preprocess, 116.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_585.jpg\n",
      "Saved labels to: results6\\labels\\MIT_585.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_586.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_586.jpg: 640x480 22 handwrittens, 136.4ms\n",
      "Speed: 3.1ms preprocess, 136.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_586.jpg\n",
      "Saved labels to: results6\\labels\\MIT_586.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_587.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_587.jpg: 640x480 23 handwrittens, 107.6ms\n",
      "Speed: 3.3ms preprocess, 107.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_587.jpg\n",
      "Saved labels to: results6\\labels\\MIT_587.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_588.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_588.jpg: 640x480 23 handwrittens, 109.0ms\n",
      "Speed: 3.0ms preprocess, 109.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_588.jpg\n",
      "Saved labels to: results6\\labels\\MIT_588.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_589.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_589.jpg: 640x480 22 handwrittens, 105.6ms\n",
      "Speed: 2.5ms preprocess, 105.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_589.jpg\n",
      "Saved labels to: results6\\labels\\MIT_589.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_59.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_59.jpg: 640x480 24 handwrittens, 120.1ms\n",
      "Speed: 3.0ms preprocess, 120.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_59.jpg\n",
      "Saved labels to: results6\\labels\\MIT_59.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_590.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_590.jpg: 640x480 21 handwrittens, 111.7ms\n",
      "Speed: 2.9ms preprocess, 111.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_590.jpg\n",
      "Saved labels to: results6\\labels\\MIT_590.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_591.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_591.jpg: 640x480 21 handwrittens, 180.5ms\n",
      "Speed: 3.4ms preprocess, 180.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_591.jpg\n",
      "Saved labels to: results6\\labels\\MIT_591.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_592.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_592.jpg: 640x480 20 handwrittens, 138.9ms\n",
      "Speed: 3.4ms preprocess, 138.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_592.jpg\n",
      "Saved labels to: results6\\labels\\MIT_592.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_593.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_593.jpg: 640x480 24 handwrittens, 115.8ms\n",
      "Speed: 3.5ms preprocess, 115.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_593.jpg\n",
      "Saved labels to: results6\\labels\\MIT_593.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_594.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_594.jpg: 640x480 21 handwrittens, 130.0ms\n",
      "Speed: 3.5ms preprocess, 130.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_594.jpg\n",
      "Saved labels to: results6\\labels\\MIT_594.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_595.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_595.jpg: 640x480 22 handwrittens, 138.5ms\n",
      "Speed: 3.0ms preprocess, 138.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_595.jpg\n",
      "Saved labels to: results6\\labels\\MIT_595.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_596.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_596.jpg: 640x480 22 handwrittens, 121.9ms\n",
      "Speed: 3.1ms preprocess, 121.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_596.jpg\n",
      "Saved labels to: results6\\labels\\MIT_596.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_597.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_597.jpg: 640x480 22 handwrittens, 129.4ms\n",
      "Speed: 3.3ms preprocess, 129.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_597.jpg\n",
      "Saved labels to: results6\\labels\\MIT_597.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_598.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_598.jpg: 640x480 20 handwrittens, 166.9ms\n",
      "Speed: 3.3ms preprocess, 166.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_598.jpg\n",
      "Saved labels to: results6\\labels\\MIT_598.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_599.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_599.jpg: 640x480 21 handwrittens, 121.8ms\n",
      "Speed: 3.4ms preprocess, 121.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_599.jpg\n",
      "Saved labels to: results6\\labels\\MIT_599.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_6.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_6.jpg: 640x480 22 handwrittens, 140.6ms\n",
      "Speed: 3.2ms preprocess, 140.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_6.jpg\n",
      "Saved labels to: results6\\labels\\MIT_6.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_60.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_60.jpg: 640x480 23 handwrittens, 115.4ms\n",
      "Speed: 3.2ms preprocess, 115.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_60.jpg\n",
      "Saved labels to: results6\\labels\\MIT_60.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_600.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_600.jpg: 640x480 25 handwrittens, 158.2ms\n",
      "Speed: 28.5ms preprocess, 158.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_600.jpg\n",
      "Saved labels to: results6\\labels\\MIT_600.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_601.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_601.jpg: 640x480 22 handwrittens, 116.9ms\n",
      "Speed: 3.1ms preprocess, 116.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_601.jpg\n",
      "Saved labels to: results6\\labels\\MIT_601.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_602.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_602.jpg: 640x480 23 handwrittens, 121.7ms\n",
      "Speed: 3.1ms preprocess, 121.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_602.jpg\n",
      "Saved labels to: results6\\labels\\MIT_602.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_603.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_603.jpg: 640x480 22 handwrittens, 124.4ms\n",
      "Speed: 4.4ms preprocess, 124.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_603.jpg\n",
      "Saved labels to: results6\\labels\\MIT_603.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_604.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_604.jpg: 640x480 21 handwrittens, 124.8ms\n",
      "Speed: 3.1ms preprocess, 124.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_604.jpg\n",
      "Saved labels to: results6\\labels\\MIT_604.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_605.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_605.jpg: 640x480 24 handwrittens, 105.3ms\n",
      "Speed: 3.4ms preprocess, 105.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_605.jpg\n",
      "Saved labels to: results6\\labels\\MIT_605.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_606.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_606.jpg: 640x480 23 handwrittens, 99.4ms\n",
      "Speed: 3.0ms preprocess, 99.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_606.jpg\n",
      "Saved labels to: results6\\labels\\MIT_606.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_607.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_607.jpg: 640x480 22 handwrittens, 99.9ms\n",
      "Speed: 3.2ms preprocess, 99.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_607.jpg\n",
      "Saved labels to: results6\\labels\\MIT_607.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_608.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_608.jpg: 640x480 22 handwrittens, 127.7ms\n",
      "Speed: 4.3ms preprocess, 127.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_608.jpg\n",
      "Saved labels to: results6\\labels\\MIT_608.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_609.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_609.jpg: 640x480 22 handwrittens, 136.7ms\n",
      "Speed: 3.0ms preprocess, 136.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_609.jpg\n",
      "Saved labels to: results6\\labels\\MIT_609.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_61.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_61.jpg: 640x480 21 handwrittens, 152.7ms\n",
      "Speed: 4.3ms preprocess, 152.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_61.jpg\n",
      "Saved labels to: results6\\labels\\MIT_61.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_610.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_610.jpg: 640x480 22 handwrittens, 151.7ms\n",
      "Speed: 4.0ms preprocess, 151.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_610.jpg\n",
      "Saved labels to: results6\\labels\\MIT_610.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_611.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_611.jpg: 640x480 20 handwrittens, 161.1ms\n",
      "Speed: 3.7ms preprocess, 161.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_611.jpg\n",
      "Saved labels to: results6\\labels\\MIT_611.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_612.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_612.jpg: 640x480 19 handwrittens, 160.2ms\n",
      "Speed: 3.2ms preprocess, 160.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_612.jpg\n",
      "Saved labels to: results6\\labels\\MIT_612.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_613.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_613.jpg: 640x480 21 handwrittens, 124.1ms\n",
      "Speed: 3.3ms preprocess, 124.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_613.jpg\n",
      "Saved labels to: results6\\labels\\MIT_613.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_614.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_614.jpg: 640x480 20 handwrittens, 102.2ms\n",
      "Speed: 3.1ms preprocess, 102.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_614.jpg\n",
      "Saved labels to: results6\\labels\\MIT_614.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_615.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_615.jpg: 640x480 22 handwrittens, 107.8ms\n",
      "Speed: 4.3ms preprocess, 107.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_615.jpg\n",
      "Saved labels to: results6\\labels\\MIT_615.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_616.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_616.jpg: 640x480 23 handwrittens, 240.3ms\n",
      "Speed: 2.8ms preprocess, 240.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_616.jpg\n",
      "Saved labels to: results6\\labels\\MIT_616.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_617.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_617.jpg: 640x480 22 handwrittens, 133.5ms\n",
      "Speed: 3.6ms preprocess, 133.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_617.jpg\n",
      "Saved labels to: results6\\labels\\MIT_617.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_618.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_618.jpg: 640x480 21 handwrittens, 108.3ms\n",
      "Speed: 3.3ms preprocess, 108.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_618.jpg\n",
      "Saved labels to: results6\\labels\\MIT_618.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_619.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_619.jpg: 640x480 27 handwrittens, 121.6ms\n",
      "Speed: 3.2ms preprocess, 121.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_619.jpg\n",
      "Saved labels to: results6\\labels\\MIT_619.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_62.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_62.jpg: 640x480 22 handwrittens, 139.3ms\n",
      "Speed: 2.8ms preprocess, 139.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_62.jpg\n",
      "Saved labels to: results6\\labels\\MIT_62.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_620.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_620.jpg: 640x480 24 handwrittens, 185.9ms\n",
      "Speed: 25.0ms preprocess, 185.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_620.jpg\n",
      "Saved labels to: results6\\labels\\MIT_620.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_621.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_621.jpg: 640x480 23 handwrittens, 143.2ms\n",
      "Speed: 5.0ms preprocess, 143.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_621.jpg\n",
      "Saved labels to: results6\\labels\\MIT_621.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_622.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_622.jpg: 640x480 23 handwrittens, 159.1ms\n",
      "Speed: 3.1ms preprocess, 159.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_622.jpg\n",
      "Saved labels to: results6\\labels\\MIT_622.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_623.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_623.jpg: 640x480 24 handwrittens, 119.7ms\n",
      "Speed: 3.6ms preprocess, 119.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_623.jpg\n",
      "Saved labels to: results6\\labels\\MIT_623.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_624.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_624.jpg: 640x480 25 handwrittens, 110.9ms\n",
      "Speed: 3.1ms preprocess, 110.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_624.jpg\n",
      "Saved labels to: results6\\labels\\MIT_624.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_625.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_625.jpg: 640x480 23 handwrittens, 169.3ms\n",
      "Speed: 3.3ms preprocess, 169.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_625.jpg\n",
      "Saved labels to: results6\\labels\\MIT_625.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_626.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_626.jpg: 640x480 20 handwrittens, 116.8ms\n",
      "Speed: 3.3ms preprocess, 116.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_626.jpg\n",
      "Saved labels to: results6\\labels\\MIT_626.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_627.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_627.jpg: 640x480 20 handwrittens, 122.2ms\n",
      "Speed: 3.4ms preprocess, 122.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_627.jpg\n",
      "Saved labels to: results6\\labels\\MIT_627.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_628.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_628.jpg: 640x480 22 handwrittens, 116.6ms\n",
      "Speed: 3.1ms preprocess, 116.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_628.jpg\n",
      "Saved labels to: results6\\labels\\MIT_628.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_629.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_629.jpg: 640x480 24 handwrittens, 124.2ms\n",
      "Speed: 6.2ms preprocess, 124.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_629.jpg\n",
      "Saved labels to: results6\\labels\\MIT_629.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_63.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_63.jpg: 640x480 27 handwrittens, 205.0ms\n",
      "Speed: 3.1ms preprocess, 205.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_63.jpg\n",
      "Saved labels to: results6\\labels\\MIT_63.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_630.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_630.jpg: 640x480 22 handwrittens, 134.6ms\n",
      "Speed: 3.4ms preprocess, 134.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_630.jpg\n",
      "Saved labels to: results6\\labels\\MIT_630.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_631.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_631.jpg: 640x480 22 handwrittens, 119.9ms\n",
      "Speed: 3.3ms preprocess, 119.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_631.jpg\n",
      "Saved labels to: results6\\labels\\MIT_631.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_632.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_632.jpg: 640x480 20 handwrittens, 111.0ms\n",
      "Speed: 3.1ms preprocess, 111.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_632.jpg\n",
      "Saved labels to: results6\\labels\\MIT_632.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_633.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_633.jpg: 640x480 20 handwrittens, 113.6ms\n",
      "Speed: 3.0ms preprocess, 113.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_633.jpg\n",
      "Saved labels to: results6\\labels\\MIT_633.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_634.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_634.jpg: 640x480 21 handwrittens, 96.3ms\n",
      "Speed: 2.9ms preprocess, 96.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_634.jpg\n",
      "Saved labels to: results6\\labels\\MIT_634.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_635.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_635.jpg: 640x480 22 handwrittens, 111.7ms\n",
      "Speed: 4.0ms preprocess, 111.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_635.jpg\n",
      "Saved labels to: results6\\labels\\MIT_635.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_636.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_636.jpg: 640x480 21 handwrittens, 148.3ms\n",
      "Speed: 3.3ms preprocess, 148.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_636.jpg\n",
      "Saved labels to: results6\\labels\\MIT_636.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_637.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_637.jpg: 640x480 21 handwrittens, 216.0ms\n",
      "Speed: 3.9ms preprocess, 216.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_637.jpg\n",
      "Saved labels to: results6\\labels\\MIT_637.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_638.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_638.jpg: 640x480 20 handwrittens, 143.0ms\n",
      "Speed: 3.1ms preprocess, 143.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_638.jpg\n",
      "Saved labels to: results6\\labels\\MIT_638.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_639.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_639.jpg: 640x480 20 handwrittens, 136.6ms\n",
      "Speed: 5.6ms preprocess, 136.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_639.jpg\n",
      "Saved labels to: results6\\labels\\MIT_639.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_64.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_64.jpg: 640x480 21 handwrittens, 189.0ms\n",
      "Speed: 4.6ms preprocess, 189.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_64.jpg\n",
      "Saved labels to: results6\\labels\\MIT_64.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_640.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_640.jpg: 640x480 21 handwrittens, 153.0ms\n",
      "Speed: 4.0ms preprocess, 153.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_640.jpg\n",
      "Saved labels to: results6\\labels\\MIT_640.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_641.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_641.jpg: 640x480 24 handwrittens, 122.0ms\n",
      "Speed: 3.0ms preprocess, 122.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_641.jpg\n",
      "Saved labels to: results6\\labels\\MIT_641.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_642.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_642.jpg: 640x480 21 handwrittens, 242.0ms\n",
      "Speed: 4.4ms preprocess, 242.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_642.jpg\n",
      "Saved labels to: results6\\labels\\MIT_642.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_643.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_643.jpg: 640x480 22 handwrittens, 155.0ms\n",
      "Speed: 4.1ms preprocess, 155.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_643.jpg\n",
      "Saved labels to: results6\\labels\\MIT_643.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_644.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_644.jpg: 640x480 20 handwrittens, 156.4ms\n",
      "Speed: 2.9ms preprocess, 156.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_644.jpg\n",
      "Saved labels to: results6\\labels\\MIT_644.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_645.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_645.jpg: 640x480 22 handwrittens, 109.0ms\n",
      "Speed: 2.7ms preprocess, 109.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_645.jpg\n",
      "Saved labels to: results6\\labels\\MIT_645.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_646.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_646.jpg: 640x480 21 handwrittens, 110.2ms\n",
      "Speed: 3.6ms preprocess, 110.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_646.jpg\n",
      "Saved labels to: results6\\labels\\MIT_646.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_647.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_647.jpg: 640x480 21 handwrittens, 113.3ms\n",
      "Speed: 3.1ms preprocess, 113.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_647.jpg\n",
      "Saved labels to: results6\\labels\\MIT_647.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_648.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_648.jpg: 640x480 21 handwrittens, 112.7ms\n",
      "Speed: 2.6ms preprocess, 112.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_648.jpg\n",
      "Saved labels to: results6\\labels\\MIT_648.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_649.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_649.jpg: 640x480 24 handwrittens, 144.4ms\n",
      "Speed: 2.5ms preprocess, 144.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_649.jpg\n",
      "Saved labels to: results6\\labels\\MIT_649.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_65.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_65.jpg: 640x480 21 handwrittens, 106.9ms\n",
      "Speed: 11.3ms preprocess, 106.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_65.jpg\n",
      "Saved labels to: results6\\labels\\MIT_65.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_650.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_650.jpg: 640x480 23 handwrittens, 159.9ms\n",
      "Speed: 4.5ms preprocess, 159.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_650.jpg\n",
      "Saved labels to: results6\\labels\\MIT_650.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_651.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_651.jpg: 640x480 20 handwrittens, 111.5ms\n",
      "Speed: 3.1ms preprocess, 111.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_651.jpg\n",
      "Saved labels to: results6\\labels\\MIT_651.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_652.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_652.jpg: 640x480 22 handwrittens, 103.1ms\n",
      "Speed: 3.1ms preprocess, 103.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_652.jpg\n",
      "Saved labels to: results6\\labels\\MIT_652.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_653.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_653.jpg: 640x480 20 handwrittens, 177.8ms\n",
      "Speed: 7.9ms preprocess, 177.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_653.jpg\n",
      "Saved labels to: results6\\labels\\MIT_653.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_654.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_654.jpg: 640x480 22 handwrittens, 110.5ms\n",
      "Speed: 1.9ms preprocess, 110.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_654.jpg\n",
      "Saved labels to: results6\\labels\\MIT_654.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_655.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_655.jpg: 640x480 30 handwrittens, 97.2ms\n",
      "Speed: 3.4ms preprocess, 97.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_655.jpg\n",
      "Saved labels to: results6\\labels\\MIT_655.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_656.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_656.jpg: 640x480 21 handwrittens, 93.2ms\n",
      "Speed: 2.1ms preprocess, 93.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_656.jpg\n",
      "Saved labels to: results6\\labels\\MIT_656.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_657.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_657.jpg: 640x480 22 handwrittens, 150.8ms\n",
      "Speed: 3.2ms preprocess, 150.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_657.jpg\n",
      "Saved labels to: results6\\labels\\MIT_657.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_658.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_658.jpg: 640x480 20 handwrittens, 168.4ms\n",
      "Speed: 3.1ms preprocess, 168.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_658.jpg\n",
      "Saved labels to: results6\\labels\\MIT_658.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_659.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_659.jpg: 640x480 22 handwrittens, 140.1ms\n",
      "Speed: 3.0ms preprocess, 140.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_659.jpg\n",
      "Saved labels to: results6\\labels\\MIT_659.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_66.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_66.jpg: 640x480 27 handwrittens, 146.8ms\n",
      "Speed: 3.6ms preprocess, 146.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_66.jpg\n",
      "Saved labels to: results6\\labels\\MIT_66.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_660.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_660.jpg: 640x480 23 handwrittens, 107.3ms\n",
      "Speed: 3.1ms preprocess, 107.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_660.jpg\n",
      "Saved labels to: results6\\labels\\MIT_660.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_661.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_661.jpg: 640x480 21 handwrittens, 106.6ms\n",
      "Speed: 2.7ms preprocess, 106.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_661.jpg\n",
      "Saved labels to: results6\\labels\\MIT_661.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_662.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_662.jpg: 640x480 23 handwrittens, 162.7ms\n",
      "Speed: 3.8ms preprocess, 162.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_662.jpg\n",
      "Saved labels to: results6\\labels\\MIT_662.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_663.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_663.jpg: 640x480 24 handwrittens, 94.6ms\n",
      "Speed: 7.2ms preprocess, 94.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_663.jpg\n",
      "Saved labels to: results6\\labels\\MIT_663.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_664.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_664.jpg: 640x480 25 handwrittens, 152.2ms\n",
      "Speed: 2.9ms preprocess, 152.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_664.jpg\n",
      "Saved labels to: results6\\labels\\MIT_664.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_665.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_665.jpg: 640x480 22 handwrittens, 142.4ms\n",
      "Speed: 3.3ms preprocess, 142.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_665.jpg\n",
      "Saved labels to: results6\\labels\\MIT_665.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_666.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_666.jpg: 640x480 20 handwrittens, 122.6ms\n",
      "Speed: 3.1ms preprocess, 122.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_666.jpg\n",
      "Saved labels to: results6\\labels\\MIT_666.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_667.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_667.jpg: 640x480 22 handwrittens, 201.8ms\n",
      "Speed: 2.4ms preprocess, 201.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_667.jpg\n",
      "Saved labels to: results6\\labels\\MIT_667.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_668.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_668.jpg: 640x480 24 handwrittens, 132.0ms\n",
      "Speed: 2.9ms preprocess, 132.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_668.jpg\n",
      "Saved labels to: results6\\labels\\MIT_668.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_669.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_669.jpg: 640x480 20 handwrittens, 105.4ms\n",
      "Speed: 3.2ms preprocess, 105.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_669.jpg\n",
      "Saved labels to: results6\\labels\\MIT_669.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_67.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_67.jpg: 640x480 21 handwrittens, 111.9ms\n",
      "Speed: 3.1ms preprocess, 111.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_67.jpg\n",
      "Saved labels to: results6\\labels\\MIT_67.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_670.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_670.jpg: 640x480 21 handwrittens, 99.6ms\n",
      "Speed: 3.3ms preprocess, 99.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_670.jpg\n",
      "Saved labels to: results6\\labels\\MIT_670.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_671.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_671.jpg: 640x480 21 handwrittens, 168.7ms\n",
      "Speed: 3.9ms preprocess, 168.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_671.jpg\n",
      "Saved labels to: results6\\labels\\MIT_671.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_672.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_672.jpg: 640x480 19 handwrittens, 114.3ms\n",
      "Speed: 2.7ms preprocess, 114.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_672.jpg\n",
      "Saved labels to: results6\\labels\\MIT_672.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_673.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_673.jpg: 640x480 22 handwrittens, 110.3ms\n",
      "Speed: 3.2ms preprocess, 110.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_673.jpg\n",
      "Saved labels to: results6\\labels\\MIT_673.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_674.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_674.jpg: 640x480 21 handwrittens, 141.0ms\n",
      "Speed: 3.2ms preprocess, 141.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_674.jpg\n",
      "Saved labels to: results6\\labels\\MIT_674.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_675.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_675.jpg: 640x480 25 handwrittens, 156.6ms\n",
      "Speed: 3.5ms preprocess, 156.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_675.jpg\n",
      "Saved labels to: results6\\labels\\MIT_675.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_676.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_676.jpg: 640x480 21 handwrittens, 275.2ms\n",
      "Speed: 5.8ms preprocess, 275.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_676.jpg\n",
      "Saved labels to: results6\\labels\\MIT_676.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_677.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_677.jpg: 640x480 22 handwrittens, 119.5ms\n",
      "Speed: 2.2ms preprocess, 119.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_677.jpg\n",
      "Saved labels to: results6\\labels\\MIT_677.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_678.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_678.jpg: 640x480 20 handwrittens, 96.2ms\n",
      "Speed: 1.8ms preprocess, 96.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_678.jpg\n",
      "Saved labels to: results6\\labels\\MIT_678.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_679.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_679.jpg: 640x480 24 handwrittens, 120.5ms\n",
      "Speed: 3.4ms preprocess, 120.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_679.jpg\n",
      "Saved labels to: results6\\labels\\MIT_679.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_68.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_68.jpg: 640x480 24 handwrittens, 110.1ms\n",
      "Speed: 2.4ms preprocess, 110.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_68.jpg\n",
      "Saved labels to: results6\\labels\\MIT_68.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_680.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_680.jpg: 640x480 21 handwrittens, 163.4ms\n",
      "Speed: 3.2ms preprocess, 163.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_680.jpg\n",
      "Saved labels to: results6\\labels\\MIT_680.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_681.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_681.jpg: 640x480 21 handwrittens, 119.5ms\n",
      "Speed: 3.1ms preprocess, 119.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_681.jpg\n",
      "Saved labels to: results6\\labels\\MIT_681.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_682.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_682.jpg: 640x480 22 handwrittens, 108.7ms\n",
      "Speed: 3.0ms preprocess, 108.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_682.jpg\n",
      "Saved labels to: results6\\labels\\MIT_682.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_683.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_683.jpg: 640x480 25 handwrittens, 126.8ms\n",
      "Speed: 3.2ms preprocess, 126.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_683.jpg\n",
      "Saved labels to: results6\\labels\\MIT_683.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_684.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_684.jpg: 640x480 20 handwrittens, 173.7ms\n",
      "Speed: 3.4ms preprocess, 173.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_684.jpg\n",
      "Saved labels to: results6\\labels\\MIT_684.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_685.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_685.jpg: 640x480 21 handwrittens, 129.4ms\n",
      "Speed: 19.9ms preprocess, 129.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_685.jpg\n",
      "Saved labels to: results6\\labels\\MIT_685.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_686.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_686.jpg: 640x480 21 handwrittens, 110.5ms\n",
      "Speed: 2.9ms preprocess, 110.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_686.jpg\n",
      "Saved labels to: results6\\labels\\MIT_686.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_687.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_687.jpg: 640x480 22 handwrittens, 113.4ms\n",
      "Speed: 3.2ms preprocess, 113.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_687.jpg\n",
      "Saved labels to: results6\\labels\\MIT_687.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_688.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_688.jpg: 640x480 21 handwrittens, 121.4ms\n",
      "Speed: 2.7ms preprocess, 121.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_688.jpg\n",
      "Saved labels to: results6\\labels\\MIT_688.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_689.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_689.jpg: 640x480 25 handwrittens, 108.9ms\n",
      "Speed: 3.1ms preprocess, 108.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_689.jpg\n",
      "Saved labels to: results6\\labels\\MIT_689.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_69.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_69.jpg: 640x480 23 handwrittens, 155.9ms\n",
      "Speed: 2.9ms preprocess, 155.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_69.jpg\n",
      "Saved labels to: results6\\labels\\MIT_69.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_690.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_690.jpg: 640x480 25 handwrittens, 105.3ms\n",
      "Speed: 2.5ms preprocess, 105.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_690.jpg\n",
      "Saved labels to: results6\\labels\\MIT_690.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_691.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_691.jpg: 640x480 21 handwrittens, 114.2ms\n",
      "Speed: 3.5ms preprocess, 114.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_691.jpg\n",
      "Saved labels to: results6\\labels\\MIT_691.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_692.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_692.jpg: 640x480 22 handwrittens, 122.1ms\n",
      "Speed: 3.7ms preprocess, 122.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_692.jpg\n",
      "Saved labels to: results6\\labels\\MIT_692.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_693.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_693.jpg: 640x480 23 handwrittens, 130.3ms\n",
      "Speed: 4.4ms preprocess, 130.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_693.jpg\n",
      "Saved labels to: results6\\labels\\MIT_693.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_694.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_694.jpg: 640x480 21 handwrittens, 173.5ms\n",
      "Speed: 3.6ms preprocess, 173.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_694.jpg\n",
      "Saved labels to: results6\\labels\\MIT_694.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_695.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_695.jpg: 640x480 22 handwrittens, 148.0ms\n",
      "Speed: 9.7ms preprocess, 148.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_695.jpg\n",
      "Saved labels to: results6\\labels\\MIT_695.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_696.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_696.jpg: 640x480 21 handwrittens, 97.7ms\n",
      "Speed: 3.2ms preprocess, 97.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_696.jpg\n",
      "Saved labels to: results6\\labels\\MIT_696.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_697.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_697.jpg: 640x480 23 handwrittens, 102.9ms\n",
      "Speed: 3.3ms preprocess, 102.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_697.jpg\n",
      "Saved labels to: results6\\labels\\MIT_697.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_698.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_698.jpg: 640x480 23 handwrittens, 109.9ms\n",
      "Speed: 3.8ms preprocess, 109.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_698.jpg\n",
      "Saved labels to: results6\\labels\\MIT_698.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_699.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_699.jpg: 640x480 22 handwrittens, 175.2ms\n",
      "Speed: 3.0ms preprocess, 175.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_699.jpg\n",
      "Saved labels to: results6\\labels\\MIT_699.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_7.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_7.jpg: 640x480 22 handwrittens, 96.7ms\n",
      "Speed: 3.2ms preprocess, 96.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_7.jpg\n",
      "Saved labels to: results6\\labels\\MIT_7.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_70.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_70.jpg: 640x480 21 handwrittens, 112.1ms\n",
      "Speed: 3.1ms preprocess, 112.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_70.jpg\n",
      "Saved labels to: results6\\labels\\MIT_70.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_700.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_700.jpg: 640x480 22 handwrittens, 112.4ms\n",
      "Speed: 4.7ms preprocess, 112.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_700.jpg\n",
      "Saved labels to: results6\\labels\\MIT_700.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_71.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_71.jpg: 640x480 21 handwrittens, 136.9ms\n",
      "Speed: 3.5ms preprocess, 136.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_71.jpg\n",
      "Saved labels to: results6\\labels\\MIT_71.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_72.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_72.jpg: 640x480 24 handwrittens, 192.0ms\n",
      "Speed: 3.0ms preprocess, 192.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_72.jpg\n",
      "Saved labels to: results6\\labels\\MIT_72.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_73.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_73.jpg: 640x480 21 handwrittens, 113.5ms\n",
      "Speed: 3.2ms preprocess, 113.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_73.jpg\n",
      "Saved labels to: results6\\labels\\MIT_73.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_74.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_74.jpg: 640x480 25 handwrittens, 104.2ms\n",
      "Speed: 3.0ms preprocess, 104.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_74.jpg\n",
      "Saved labels to: results6\\labels\\MIT_74.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_75.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_75.jpg: 640x480 25 handwrittens, 113.2ms\n",
      "Speed: 3.2ms preprocess, 113.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_75.jpg\n",
      "Saved labels to: results6\\labels\\MIT_75.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_76.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_76.jpg: 640x480 21 handwrittens, 102.2ms\n",
      "Speed: 2.5ms preprocess, 102.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_76.jpg\n",
      "Saved labels to: results6\\labels\\MIT_76.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_77.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_77.jpg: 640x480 27 handwrittens, 107.5ms\n",
      "Speed: 4.6ms preprocess, 107.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_77.jpg\n",
      "Saved labels to: results6\\labels\\MIT_77.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_78.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_78.jpg: 640x480 20 handwrittens, 158.4ms\n",
      "Speed: 6.3ms preprocess, 158.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_78.jpg\n",
      "Saved labels to: results6\\labels\\MIT_78.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_79.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_79.jpg: 640x480 21 handwrittens, 145.7ms\n",
      "Speed: 3.2ms preprocess, 145.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_79.jpg\n",
      "Saved labels to: results6\\labels\\MIT_79.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_8.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_8.jpg: 640x480 23 handwrittens, 118.9ms\n",
      "Speed: 3.0ms preprocess, 118.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_8.jpg\n",
      "Saved labels to: results6\\labels\\MIT_8.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_80.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_80.jpg: 640x480 23 handwrittens, 111.3ms\n",
      "Speed: 2.8ms preprocess, 111.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_80.jpg\n",
      "Saved labels to: results6\\labels\\MIT_80.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_81.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_81.jpg: 640x480 24 handwrittens, 119.0ms\n",
      "Speed: 3.3ms preprocess, 119.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_81.jpg\n",
      "Saved labels to: results6\\labels\\MIT_81.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_82.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_82.jpg: 640x480 22 handwrittens, 127.1ms\n",
      "Speed: 3.9ms preprocess, 127.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_82.jpg\n",
      "Saved labels to: results6\\labels\\MIT_82.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_83.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_83.jpg: 640x480 20 handwrittens, 117.0ms\n",
      "Speed: 3.3ms preprocess, 117.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_83.jpg\n",
      "Saved labels to: results6\\labels\\MIT_83.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_84.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_84.jpg: 640x480 21 handwrittens, 101.2ms\n",
      "Speed: 3.0ms preprocess, 101.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_84.jpg\n",
      "Saved labels to: results6\\labels\\MIT_84.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_85.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_85.jpg: 640x480 21 handwrittens, 151.3ms\n",
      "Speed: 3.4ms preprocess, 151.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_85.jpg\n",
      "Saved labels to: results6\\labels\\MIT_85.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_86.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_86.jpg: 640x480 24 handwrittens, 233.6ms\n",
      "Speed: 10.9ms preprocess, 233.6ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_86.jpg\n",
      "Saved labels to: results6\\labels\\MIT_86.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_87.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_87.jpg: 640x480 21 handwrittens, 113.8ms\n",
      "Speed: 2.9ms preprocess, 113.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_87.jpg\n",
      "Saved labels to: results6\\labels\\MIT_87.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_88.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_88.jpg: 640x480 20 handwrittens, 103.8ms\n",
      "Speed: 2.9ms preprocess, 103.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_88.jpg\n",
      "Saved labels to: results6\\labels\\MIT_88.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_89.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_89.jpg: 640x480 22 handwrittens, 110.5ms\n",
      "Speed: 3.2ms preprocess, 110.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_89.jpg\n",
      "Saved labels to: results6\\labels\\MIT_89.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_9.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_9.jpg: 640x480 30 handwrittens, 106.0ms\n",
      "Speed: 3.4ms preprocess, 106.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_9.jpg\n",
      "Saved labels to: results6\\labels\\MIT_9.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_90.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_90.jpg: 640x480 21 handwrittens, 132.7ms\n",
      "Speed: 18.3ms preprocess, 132.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_90.jpg\n",
      "Saved labels to: results6\\labels\\MIT_90.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_91.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_91.jpg: 640x480 20 handwrittens, 101.8ms\n",
      "Speed: 3.1ms preprocess, 101.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_91.jpg\n",
      "Saved labels to: results6\\labels\\MIT_91.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_92.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_92.jpg: 640x480 23 handwrittens, 128.2ms\n",
      "Speed: 3.3ms preprocess, 128.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_92.jpg\n",
      "Saved labels to: results6\\labels\\MIT_92.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_93.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_93.jpg: 640x480 21 handwrittens, 105.5ms\n",
      "Speed: 3.6ms preprocess, 105.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_93.jpg\n",
      "Saved labels to: results6\\labels\\MIT_93.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_94.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_94.jpg: 640x480 24 handwrittens, 159.4ms\n",
      "Speed: 3.2ms preprocess, 159.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_94.jpg\n",
      "Saved labels to: results6\\labels\\MIT_94.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_95.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_95.jpg: 640x480 22 handwrittens, 179.7ms\n",
      "Speed: 3.4ms preprocess, 179.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_95.jpg\n",
      "Saved labels to: results6\\labels\\MIT_95.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_96.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_96.jpg: 640x480 24 handwrittens, 121.4ms\n",
      "Speed: 3.2ms preprocess, 121.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_96.jpg\n",
      "Saved labels to: results6\\labels\\MIT_96.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_97.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_97.jpg: 640x480 22 handwrittens, 101.6ms\n",
      "Speed: 2.6ms preprocess, 101.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_97.jpg\n",
      "Saved labels to: results6\\labels\\MIT_97.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_98.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_98.jpg: 640x480 21 handwrittens, 97.6ms\n",
      "Speed: 2.9ms preprocess, 97.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_98.jpg\n",
      "Saved labels to: results6\\labels\\MIT_98.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_99.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\MIT_99.jpg: 640x480 25 handwrittens, 92.2ms\n",
      "Speed: 3.2ms preprocess, 92.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\MIT_99.jpg\n",
      "Saved labels to: results6\\labels\\MIT_99.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1001.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1001.jpg: 640x448 27 handwrittens, 193.3ms\n",
      "Speed: 8.3ms preprocess, 193.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved image to: results6\\TCE_1001.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1001.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1002.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1002.jpg: 640x448 25 handwrittens, 121.1ms\n",
      "Speed: 3.8ms preprocess, 121.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved image to: results6\\TCE_1002.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1002.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1003.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1003.jpg: 640x448 27 handwrittens, 124.2ms\n",
      "Speed: 3.6ms preprocess, 124.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved image to: results6\\TCE_1003.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1003.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1004.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1004.jpg: 640x448 24 handwrittens, 137.1ms\n",
      "Speed: 3.3ms preprocess, 137.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved image to: results6\\TCE_1004.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1004.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1005.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1005.jpg: 640x480 22 handwrittens, 128.9ms\n",
      "Speed: 3.5ms preprocess, 128.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1005.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1005.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1006.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1006.jpg: 640x480 24 handwrittens, 130.6ms\n",
      "Speed: 11.6ms preprocess, 130.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1006.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1006.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1007.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1007.jpg: 640x480 21 handwrittens, 101.7ms\n",
      "Speed: 3.2ms preprocess, 101.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1007.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1007.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1008.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1008.jpg: 640x480 23 handwrittens, 95.9ms\n",
      "Speed: 2.8ms preprocess, 95.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1008.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1008.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1009.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1009.jpg: 640x480 23 handwrittens, 113.5ms\n",
      "Speed: 2.8ms preprocess, 113.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1009.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1009.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1010.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1010.jpg: 640x480 20 handwrittens, 106.2ms\n",
      "Speed: 3.3ms preprocess, 106.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1010.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1010.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1011.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1011.jpg: 640x480 20 handwrittens, 215.6ms\n",
      "Speed: 2.6ms preprocess, 215.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1011.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1011.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1012.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1012.jpg: 640x480 25 handwrittens, 118.0ms\n",
      "Speed: 3.9ms preprocess, 118.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1012.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1012.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1013.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1013.jpg: 640x480 24 handwrittens, 165.7ms\n",
      "Speed: 3.7ms preprocess, 165.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1013.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1013.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1014.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1014.jpg: 640x480 20 handwrittens, 118.8ms\n",
      "Speed: 3.4ms preprocess, 118.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1014.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1014.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1015.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1015.jpg: 640x480 27 handwrittens, 111.9ms\n",
      "Speed: 4.0ms preprocess, 111.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1015.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1015.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1016.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1016.jpg: 640x480 19 handwrittens, 154.4ms\n",
      "Speed: 4.0ms preprocess, 154.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1016.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1016.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1017.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1017.jpg: 640x480 25 handwrittens, 111.4ms\n",
      "Speed: 3.0ms preprocess, 111.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1017.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1017.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1018.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1018.jpg: 640x480 19 handwrittens, 109.2ms\n",
      "Speed: 2.7ms preprocess, 109.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1018.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1018.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1019.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1019.jpg: 640x480 20 handwrittens, 134.1ms\n",
      "Speed: 2.9ms preprocess, 134.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1019.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1019.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1020.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1020.jpg: 640x480 19 handwrittens, 124.0ms\n",
      "Speed: 3.3ms preprocess, 124.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1020.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1020.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1021.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1021.jpg: 640x480 23 handwrittens, 158.0ms\n",
      "Speed: 4.8ms preprocess, 158.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1021.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1021.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1022.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1022.jpg: 640x480 21 handwrittens, 174.7ms\n",
      "Speed: 13.5ms preprocess, 174.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1022.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1022.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1023.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1023.jpg: 640x480 21 handwrittens, 154.2ms\n",
      "Speed: 4.0ms preprocess, 154.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1023.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1023.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1024.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1024.jpg: 640x480 20 handwrittens, 95.7ms\n",
      "Speed: 2.8ms preprocess, 95.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1024.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1024.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1025.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1025.jpg: 640x480 20 handwrittens, 131.2ms\n",
      "Speed: 3.2ms preprocess, 131.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1025.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1025.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1026.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1026.jpg: 640x480 19 handwrittens, 204.7ms\n",
      "Speed: 2.9ms preprocess, 204.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1026.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1026.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1027.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1027.jpg: 640x480 20 handwrittens, 148.0ms\n",
      "Speed: 5.8ms preprocess, 148.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1027.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1027.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1028.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1028.jpg: 640x480 21 handwrittens, 111.2ms\n",
      "Speed: 2.8ms preprocess, 111.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1028.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1028.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1029.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1029.jpg: 640x480 19 handwrittens, 107.7ms\n",
      "Speed: 3.3ms preprocess, 107.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1029.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1029.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1030.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1030.jpg: 640x480 23 handwrittens, 103.7ms\n",
      "Speed: 2.9ms preprocess, 103.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1030.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1030.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1031.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1031.jpg: 640x480 19 handwrittens, 231.5ms\n",
      "Speed: 2.9ms preprocess, 231.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1031.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1031.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1032.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1032.jpg: 640x480 21 handwrittens, 106.0ms\n",
      "Speed: 4.1ms preprocess, 106.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1032.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1032.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1033.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1033.jpg: 640x480 20 handwrittens, 159.2ms\n",
      "Speed: 2.9ms preprocess, 159.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1033.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1033.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1034.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1034.jpg: 640x480 19 handwrittens, 111.6ms\n",
      "Speed: 3.9ms preprocess, 111.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1034.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1034.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1035.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1035.jpg: 640x480 19 handwrittens, 151.7ms\n",
      "Speed: 4.6ms preprocess, 151.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1035.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1035.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1036.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1036.jpg: 640x480 23 handwrittens, 185.3ms\n",
      "Speed: 3.0ms preprocess, 185.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1036.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1036.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1037.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1037.jpg: 640x480 19 handwrittens, 102.9ms\n",
      "Speed: 3.5ms preprocess, 102.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1037.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1037.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1038.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1038.jpg: 640x480 19 handwrittens, 110.1ms\n",
      "Speed: 4.0ms preprocess, 110.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1038.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1038.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1039.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1039.jpg: 640x480 19 handwrittens, 114.9ms\n",
      "Speed: 2.9ms preprocess, 114.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1039.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1039.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1040.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1040.jpg: 640x480 19 handwrittens, 115.4ms\n",
      "Speed: 3.0ms preprocess, 115.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1040.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1040.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1041.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1041.jpg: 640x480 20 handwrittens, 149.2ms\n",
      "Speed: 18.9ms preprocess, 149.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1041.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1041.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1042.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1042.jpg: 640x480 20 handwrittens, 109.2ms\n",
      "Speed: 2.8ms preprocess, 109.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1042.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1042.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1043.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1043.jpg: 640x480 19 handwrittens, 175.3ms\n",
      "Speed: 2.9ms preprocess, 175.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1043.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1043.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1044.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1044.jpg: 640x480 20 handwrittens, 112.5ms\n",
      "Speed: 3.0ms preprocess, 112.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1044.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1044.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1045.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1045.jpg: 640x480 19 handwrittens, 105.7ms\n",
      "Speed: 3.0ms preprocess, 105.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1045.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1045.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1046.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1046.jpg: 640x480 19 handwrittens, 165.3ms\n",
      "Speed: 3.3ms preprocess, 165.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1046.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1046.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1047.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1047.jpg: 640x480 19 handwrittens, 109.1ms\n",
      "Speed: 3.6ms preprocess, 109.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1047.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1047.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1048.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1048.jpg: 640x480 23 handwrittens, 101.0ms\n",
      "Speed: 2.8ms preprocess, 101.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1048.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1048.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1049.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1049.jpg: 640x480 24 handwrittens, 93.8ms\n",
      "Speed: 2.9ms preprocess, 93.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1049.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1049.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1050.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1050.jpg: 640x480 22 handwrittens, 198.7ms\n",
      "Speed: 2.9ms preprocess, 198.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1050.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1050.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1051.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1051.jpg: 640x480 21 handwrittens, 187.6ms\n",
      "Speed: 3.1ms preprocess, 187.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1051.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1051.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1052.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1052.jpg: 640x480 21 handwrittens, 156.8ms\n",
      "Speed: 3.3ms preprocess, 156.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1052.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1052.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1053.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1053.jpg: 640x480 18 handwrittens, 109.5ms\n",
      "Speed: 2.7ms preprocess, 109.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1053.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1053.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1054.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1054.jpg: 640x480 22 handwrittens, 105.1ms\n",
      "Speed: 3.1ms preprocess, 105.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1054.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1054.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1055.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1055.jpg: 640x480 20 handwrittens, 105.4ms\n",
      "Speed: 3.0ms preprocess, 105.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1055.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1055.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1056.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1056.jpg: 640x480 23 handwrittens, 156.1ms\n",
      "Speed: 3.2ms preprocess, 156.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1056.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1056.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1057.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1057.jpg: 640x480 21 handwrittens, 96.8ms\n",
      "Speed: 2.9ms preprocess, 96.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1057.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1057.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1058.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1058.jpg: 640x480 18 handwrittens, 115.7ms\n",
      "Speed: 2.8ms preprocess, 115.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1058.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1058.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1059.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1059.jpg: 640x480 22 handwrittens, 140.8ms\n",
      "Speed: 4.0ms preprocess, 140.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1059.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1059.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1060.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1060.jpg: 640x480 21 handwrittens, 167.2ms\n",
      "Speed: 7.7ms preprocess, 167.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1060.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1060.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1061.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1061.jpg: 640x480 20 handwrittens, 98.3ms\n",
      "Speed: 1.9ms preprocess, 98.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1061.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1061.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1062.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1062.jpg: 640x480 20 handwrittens, 109.2ms\n",
      "Speed: 3.1ms preprocess, 109.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1062.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1062.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1063.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1063.jpg: 640x480 20 handwrittens, 142.4ms\n",
      "Speed: 4.9ms preprocess, 142.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1063.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1063.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1064.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1064.jpg: 640x480 21 handwrittens, 113.9ms\n",
      "Speed: 2.8ms preprocess, 113.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1064.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1064.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1065.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1065.jpg: 640x480 22 handwrittens, 110.2ms\n",
      "Speed: 2.6ms preprocess, 110.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1065.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1065.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1066.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1066.jpg: 640x480 20 handwrittens, 155.3ms\n",
      "Speed: 3.0ms preprocess, 155.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1066.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1066.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1067.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1067.jpg: 640x480 21 handwrittens, 109.9ms\n",
      "Speed: 3.5ms preprocess, 109.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1067.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1067.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1068.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1068.jpg: 640x480 24 handwrittens, 211.5ms\n",
      "Speed: 3.8ms preprocess, 211.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1068.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1068.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1069.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1069.jpg: 640x480 22 handwrittens, 134.2ms\n",
      "Speed: 3.4ms preprocess, 134.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1069.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1069.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1070.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1070.jpg: 640x480 22 handwrittens, 113.0ms\n",
      "Speed: 3.6ms preprocess, 113.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1070.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1070.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1071.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1071.jpg: 640x480 19 handwrittens, 124.5ms\n",
      "Speed: 4.3ms preprocess, 124.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1071.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1071.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1072.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1072.jpg: 640x480 21 handwrittens, 108.0ms\n",
      "Speed: 3.2ms preprocess, 108.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1072.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1072.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1073.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1073.jpg: 640x480 20 handwrittens, 101.5ms\n",
      "Speed: 3.0ms preprocess, 101.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1073.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1073.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1074.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1074.jpg: 640x480 23 handwrittens, 94.6ms\n",
      "Speed: 3.0ms preprocess, 94.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1074.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1074.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1075.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1075.jpg: 640x480 23 handwrittens, 115.9ms\n",
      "Speed: 3.2ms preprocess, 115.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1075.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1075.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1076.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1076.jpg: 640x480 23 handwrittens, 179.5ms\n",
      "Speed: 3.0ms preprocess, 179.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1076.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1076.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1077.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1077.jpg: 640x480 21 handwrittens, 227.7ms\n",
      "Speed: 4.8ms preprocess, 227.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1077.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1077.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1078.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1078.jpg: 640x480 25 handwrittens, 121.9ms\n",
      "Speed: 3.1ms preprocess, 121.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1078.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1078.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1079.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1079.jpg: 640x480 27 handwrittens, 114.6ms\n",
      "Speed: 3.1ms preprocess, 114.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1079.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1079.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1080.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1080.jpg: 640x480 29 handwrittens, 108.2ms\n",
      "Speed: 3.4ms preprocess, 108.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1080.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1080.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1081.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1081.jpg: 640x480 21 handwrittens, 116.9ms\n",
      "Speed: 3.2ms preprocess, 116.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1081.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1081.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1082.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1082.jpg: 640x480 28 handwrittens, 174.0ms\n",
      "Speed: 7.0ms preprocess, 174.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1082.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1082.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1083.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1083.jpg: 640x480 26 handwrittens, 170.9ms\n",
      "Speed: 3.1ms preprocess, 170.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1083.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1083.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1084.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1084.jpg: 640x480 19 handwrittens, 133.3ms\n",
      "Speed: 3.4ms preprocess, 133.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1084.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1084.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1085.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1085.jpg: 640x480 19 handwrittens, 163.1ms\n",
      "Speed: 3.6ms preprocess, 163.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1085.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1085.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1086.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1086.jpg: 640x480 21 handwrittens, 177.7ms\n",
      "Speed: 3.9ms preprocess, 177.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1086.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1086.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1087.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1087.jpg: 640x512 22 handwrittens, 127.9ms\n",
      "Speed: 3.4ms preprocess, 127.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Saved image to: results6\\TCE_1087.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1087.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1088.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1088.jpg: 640x512 26 handwrittens, 122.5ms\n",
      "Speed: 3.2ms preprocess, 122.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Saved image to: results6\\TCE_1088.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1088.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1089.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1089.jpg: 640x480 21 handwrittens, 98.0ms\n",
      "Speed: 2.0ms preprocess, 98.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1089.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1089.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1090.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1090.jpg: 640x480 21 handwrittens, 98.0ms\n",
      "Speed: 2.1ms preprocess, 98.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1090.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1090.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1091.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1091.jpg: 640x480 19 handwrittens, 111.0ms\n",
      "Speed: 3.8ms preprocess, 111.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1091.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1091.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1092.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1092.jpg: 640x480 19 handwrittens, 119.0ms\n",
      "Speed: 3.0ms preprocess, 119.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1092.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1092.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1093.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1093.jpg: 640x480 26 handwrittens, 122.3ms\n",
      "Speed: 3.2ms preprocess, 122.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1093.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1093.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1094.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1094.jpg: 640x480 19 handwrittens, 235.7ms\n",
      "Speed: 4.8ms preprocess, 235.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1094.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1094.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1095.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1095.jpg: 640x480 19 handwrittens, 127.6ms\n",
      "Speed: 4.2ms preprocess, 127.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1095.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1095.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1096.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1096.jpg: 640x480 31 handwrittens, 115.1ms\n",
      "Speed: 3.4ms preprocess, 115.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1096.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1096.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1097.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1097.jpg: 640x480 20 handwrittens, 119.0ms\n",
      "Speed: 3.6ms preprocess, 119.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1097.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1097.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1098.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1098.jpg: 640x480 20 handwrittens, 150.0ms\n",
      "Speed: 3.9ms preprocess, 150.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1098.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1098.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1099.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1099.jpg: 640x480 20 handwrittens, 99.3ms\n",
      "Speed: 2.8ms preprocess, 99.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1099.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1099.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1100.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1100.jpg: 640x480 22 handwrittens, 115.2ms\n",
      "Speed: 2.9ms preprocess, 115.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1100.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1100.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1101.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1101.jpg: 640x480 20 handwrittens, 164.2ms\n",
      "Speed: 8.4ms preprocess, 164.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1101.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1101.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1102.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1102.jpg: 640x480 19 handwrittens, 250.5ms\n",
      "Speed: 4.1ms preprocess, 250.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1102.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1102.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1103.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1103.jpg: 640x480 20 handwrittens, 187.7ms\n",
      "Speed: 3.3ms preprocess, 187.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1103.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1103.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1104.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1104.jpg: 640x480 28 handwrittens, 138.7ms\n",
      "Speed: 5.5ms preprocess, 138.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1104.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1104.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1105.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1105.jpg: 640x480 19 handwrittens, 133.1ms\n",
      "Speed: 3.8ms preprocess, 133.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1105.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1105.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1106.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1106.jpg: 640x480 29 handwrittens, 121.8ms\n",
      "Speed: 3.3ms preprocess, 121.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1106.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1106.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1107.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1107.jpg: 640x480 26 handwrittens, 145.2ms\n",
      "Speed: 3.5ms preprocess, 145.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1107.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1107.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1108.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1108.jpg: 640x480 20 handwrittens, 126.8ms\n",
      "Speed: 3.4ms preprocess, 126.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1108.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1108.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1109.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1109.jpg: 640x480 20 handwrittens, 133.7ms\n",
      "Speed: 3.1ms preprocess, 133.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1109.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1109.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1110.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1110.jpg: 640x480 23 handwrittens, 130.3ms\n",
      "Speed: 3.2ms preprocess, 130.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1110.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1110.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1111.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1111.jpg: 640x480 26 handwrittens, 275.7ms\n",
      "Speed: 6.5ms preprocess, 275.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1111.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1111.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1112.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1112.jpg: 640x480 21 handwrittens, 129.0ms\n",
      "Speed: 3.1ms preprocess, 129.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1112.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1112.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1113.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1113.jpg: 640x480 21 handwrittens, 88.5ms\n",
      "Speed: 3.3ms preprocess, 88.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1113.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1113.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1114.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1114.jpg: 640x480 24 handwrittens, 135.7ms\n",
      "Speed: 3.3ms preprocess, 135.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1114.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1114.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1115.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1115.jpg: 640x480 21 handwrittens, 130.3ms\n",
      "Speed: 9.8ms preprocess, 130.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1115.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1115.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1116.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1116.jpg: 640x480 21 handwrittens, 157.8ms\n",
      "Speed: 3.2ms preprocess, 157.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1116.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1116.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1117.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1117.jpg: 640x480 18 handwrittens, 116.3ms\n",
      "Speed: 3.2ms preprocess, 116.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1117.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1117.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1118.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1118.jpg: 640x480 19 handwrittens, 118.3ms\n",
      "Speed: 7.8ms preprocess, 118.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1118.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1118.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1119.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1119.jpg: 640x480 21 handwrittens, 128.8ms\n",
      "Speed: 3.2ms preprocess, 128.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1119.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1119.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1120.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1120.jpg: 640x480 27 handwrittens, 204.1ms\n",
      "Speed: 3.5ms preprocess, 204.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1120.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1120.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1121.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1121.jpg: 640x480 19 handwrittens, 131.7ms\n",
      "Speed: 11.1ms preprocess, 131.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1121.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1121.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1122.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1122.jpg: 640x480 20 handwrittens, 135.6ms\n",
      "Speed: 3.2ms preprocess, 135.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1122.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1122.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1123.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1123.jpg: 640x480 22 handwrittens, 126.3ms\n",
      "Speed: 4.3ms preprocess, 126.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1123.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1123.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1124.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1124.jpg: 640x480 19 handwrittens, 128.1ms\n",
      "Speed: 10.2ms preprocess, 128.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1124.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1124.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1125.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1125.jpg: 640x480 20 handwrittens, 130.3ms\n",
      "Speed: 3.3ms preprocess, 130.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1125.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1125.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1126.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1126.jpg: 640x480 20 handwrittens, 128.7ms\n",
      "Speed: 4.2ms preprocess, 128.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1126.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1126.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1127.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1127.jpg: 640x480 17 handwrittens, 116.4ms\n",
      "Speed: 3.3ms preprocess, 116.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1127.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1127.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1128.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1128.jpg: 640x480 24 handwrittens, 164.2ms\n",
      "Speed: 4.0ms preprocess, 164.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1128.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1128.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1129.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1129.jpg: 640x480 19 handwrittens, 113.8ms\n",
      "Speed: 4.1ms preprocess, 113.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1129.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1129.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1130.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1130.jpg: 640x480 23 handwrittens, 140.1ms\n",
      "Speed: 18.0ms preprocess, 140.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1130.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1130.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1131.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1131.jpg: 640x480 19 handwrittens, 210.0ms\n",
      "Speed: 23.3ms preprocess, 210.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1131.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1131.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1132.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1132.jpg: 640x480 20 handwrittens, 105.2ms\n",
      "Speed: 3.5ms preprocess, 105.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1132.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1132.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1133.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1133.jpg: 640x480 21 handwrittens, 131.0ms\n",
      "Speed: 9.2ms preprocess, 131.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1133.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1133.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1134.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1134.jpg: 640x480 19 handwrittens, 125.1ms\n",
      "Speed: 3.2ms preprocess, 125.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1134.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1134.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1135.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1135.jpg: 640x480 19 handwrittens, 134.2ms\n",
      "Speed: 3.5ms preprocess, 134.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1135.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1135.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1136.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1136.jpg: 640x480 20 handwrittens, 134.3ms\n",
      "Speed: 4.9ms preprocess, 134.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1136.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1136.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1137.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1137.jpg: 640x480 20 handwrittens, 157.3ms\n",
      "Speed: 3.4ms preprocess, 157.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1137.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1137.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1138.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1138.jpg: 640x480 19 handwrittens, 104.9ms\n",
      "Speed: 2.5ms preprocess, 104.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1138.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1138.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1139.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1139.jpg: 640x480 21 handwrittens, 173.2ms\n",
      "Speed: 10.4ms preprocess, 173.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1139.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1139.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1140.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1140.jpg: 640x480 21 handwrittens, 118.9ms\n",
      "Speed: 3.4ms preprocess, 118.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1140.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1140.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1141.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1141.jpg: 640x480 22 handwrittens, 123.0ms\n",
      "Speed: 3.2ms preprocess, 123.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1141.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1141.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1142.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1142.jpg: 640x480 21 handwrittens, 111.9ms\n",
      "Speed: 7.6ms preprocess, 111.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1142.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1142.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1143.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1143.jpg: 640x480 23 handwrittens, 115.0ms\n",
      "Speed: 3.4ms preprocess, 115.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1143.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1143.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1144.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1144.jpg: 640x480 20 handwrittens, 104.4ms\n",
      "Speed: 2.2ms preprocess, 104.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1144.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1144.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1145.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1145.jpg: 640x480 20 handwrittens, 107.6ms\n",
      "Speed: 2.3ms preprocess, 107.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1145.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1145.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1146.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1146.jpg: 640x480 24 handwrittens, 192.2ms\n",
      "Speed: 24.2ms preprocess, 192.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1146.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1146.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1147.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1147.jpg: 640x480 21 handwrittens, 135.8ms\n",
      "Speed: 3.1ms preprocess, 135.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1147.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1147.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1148.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1148.jpg: 640x480 21 handwrittens, 113.3ms\n",
      "Speed: 4.4ms preprocess, 113.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1148.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1148.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1149.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1149.jpg: 640x480 20 handwrittens, 111.3ms\n",
      "Speed: 3.2ms preprocess, 111.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1149.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1149.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1150.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1150.jpg: 640x480 20 handwrittens, 113.5ms\n",
      "Speed: 3.7ms preprocess, 113.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1150.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1150.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1151.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1151.jpg: 640x480 20 handwrittens, 119.5ms\n",
      "Speed: 5.6ms preprocess, 119.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1151.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1151.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1152.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1152.jpg: 640x480 21 handwrittens, 104.9ms\n",
      "Speed: 3.1ms preprocess, 104.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1152.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1152.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1153.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1153.jpg: 640x480 20 handwrittens, 96.8ms\n",
      "Speed: 3.0ms preprocess, 96.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1153.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1153.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1154.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1154.jpg: 640x480 21 handwrittens, 97.6ms\n",
      "Speed: 6.3ms preprocess, 97.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1154.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1154.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1155.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1155.jpg: 640x480 22 handwrittens, 87.8ms\n",
      "Speed: 3.2ms preprocess, 87.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1155.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1155.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1156.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1156.jpg: 640x480 21 handwrittens, 161.8ms\n",
      "Speed: 3.1ms preprocess, 161.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1156.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1156.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1157.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1157.jpg: 640x480 21 handwrittens, 86.6ms\n",
      "Speed: 3.2ms preprocess, 86.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1157.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1157.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1158.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1158.jpg: 640x480 22 handwrittens, 90.2ms\n",
      "Speed: 2.8ms preprocess, 90.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1158.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1158.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1159.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1159.jpg: 640x480 26 handwrittens, 93.3ms\n",
      "Speed: 2.9ms preprocess, 93.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1159.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1159.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1160.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1160.jpg: 640x480 27 handwrittens, 91.9ms\n",
      "Speed: 2.8ms preprocess, 91.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1160.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1160.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1161.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1161.jpg: 640x448 25 handwrittens, 92.5ms\n",
      "Speed: 2.9ms preprocess, 92.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved image to: results6\\TCE_1161.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1161.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1162.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1162.jpg: 640x448 22 handwrittens, 93.3ms\n",
      "Speed: 1.8ms preprocess, 93.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved image to: results6\\TCE_1162.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1162.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1163.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1163.jpg: 640x448 27 handwrittens, 104.8ms\n",
      "Speed: 6.8ms preprocess, 104.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved image to: results6\\TCE_1163.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1163.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1164.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1164.jpg: 640x448 22 handwrittens, 116.6ms\n",
      "Speed: 3.7ms preprocess, 116.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved image to: results6\\TCE_1164.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1164.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1165.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1165.jpg: 640x448 20 handwrittens, 104.9ms\n",
      "Speed: 2.8ms preprocess, 104.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved image to: results6\\TCE_1165.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1165.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1166.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1166.jpg: 640x448 20 handwrittens, 150.1ms\n",
      "Speed: 3.1ms preprocess, 150.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved image to: results6\\TCE_1166.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1166.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1167.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1167.jpg: 640x480 19 handwrittens, 120.3ms\n",
      "Speed: 2.8ms preprocess, 120.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1167.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1167.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1168.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1168.jpg: 640x480 19 handwrittens, 105.8ms\n",
      "Speed: 2.6ms preprocess, 105.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1168.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1168.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1169.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1169.jpg: 640x480 19 handwrittens, 106.1ms\n",
      "Speed: 3.8ms preprocess, 106.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1169.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1169.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1170.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1170.jpg: 640x480 23 handwrittens, 147.3ms\n",
      "Speed: 2.9ms preprocess, 147.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1170.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1170.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1171.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1171.jpg: 640x480 21 handwrittens, 130.4ms\n",
      "Speed: 6.3ms preprocess, 130.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1171.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1171.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1172.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1172.jpg: 640x480 22 handwrittens, 125.4ms\n",
      "Speed: 3.4ms preprocess, 125.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1172.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1172.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1173.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1173.jpg: 640x480 26 handwrittens, 151.5ms\n",
      "Speed: 3.5ms preprocess, 151.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1173.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1173.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1174.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1174.jpg: 640x480 23 handwrittens, 115.9ms\n",
      "Speed: 7.4ms preprocess, 115.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1174.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1174.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1175.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1175.jpg: 640x480 23 handwrittens, 166.6ms\n",
      "Speed: 6.1ms preprocess, 166.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1175.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1175.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1176.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1176.jpg: 640x480 28 handwrittens, 135.7ms\n",
      "Speed: 4.4ms preprocess, 135.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1176.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1176.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1177.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1177.jpg: 640x480 27 handwrittens, 111.7ms\n",
      "Speed: 4.9ms preprocess, 111.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1177.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1177.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1178.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1178.jpg: 640x480 22 handwrittens, 94.4ms\n",
      "Speed: 2.6ms preprocess, 94.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1178.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1178.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1179.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1179.jpg: 640x480 22 handwrittens, 180.7ms\n",
      "Speed: 2.8ms preprocess, 180.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1179.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1179.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1180.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1180.jpg: 640x480 22 handwrittens, 191.8ms\n",
      "Speed: 3.4ms preprocess, 191.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1180.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1180.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1181.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1181.jpg: 640x480 22 handwrittens, 111.6ms\n",
      "Speed: 2.8ms preprocess, 111.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1181.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1181.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1182.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1182.jpg: 640x480 21 handwrittens, 114.4ms\n",
      "Speed: 2.8ms preprocess, 114.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1182.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1182.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1183.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1183.jpg: 640x480 21 handwrittens, 108.8ms\n",
      "Speed: 3.4ms preprocess, 108.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1183.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1183.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1184.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1184.jpg: 640x480 22 handwrittens, 182.2ms\n",
      "Speed: 3.7ms preprocess, 182.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1184.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1184.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1185.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1185.jpg: 640x480 25 handwrittens, 117.3ms\n",
      "Speed: 3.0ms preprocess, 117.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1185.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1185.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1186.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1186.jpg: 640x480 23 handwrittens, 92.6ms\n",
      "Speed: 3.4ms preprocess, 92.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1186.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1186.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1187.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1187.jpg: 640x480 23 handwrittens, 146.7ms\n",
      "Speed: 6.6ms preprocess, 146.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1187.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1187.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1188.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1188.jpg: 640x480 24 handwrittens, 121.9ms\n",
      "Speed: 5.8ms preprocess, 121.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1188.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1188.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1189.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1189.jpg: 640x480 20 handwrittens, 185.4ms\n",
      "Speed: 3.3ms preprocess, 185.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1189.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1189.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1190.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1190.jpg: 640x480 20 handwrittens, 104.6ms\n",
      "Speed: 3.0ms preprocess, 104.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1190.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1190.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1191.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1191.jpg: 640x480 20 handwrittens, 104.4ms\n",
      "Speed: 2.1ms preprocess, 104.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1191.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1191.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1192.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1192.jpg: 640x480 19 handwrittens, 103.0ms\n",
      "Speed: 3.8ms preprocess, 103.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1192.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1192.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1193.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1193.jpg: 640x480 20 handwrittens, 113.1ms\n",
      "Speed: 6.4ms preprocess, 113.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1193.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1193.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1194.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1194.jpg: 640x480 22 handwrittens, 125.0ms\n",
      "Speed: 14.0ms preprocess, 125.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1194.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1194.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1195.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1195.jpg: 640x480 23 handwrittens, 101.5ms\n",
      "Speed: 3.0ms preprocess, 101.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1195.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1195.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1196.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1196.jpg: 640x480 21 handwrittens, 106.5ms\n",
      "Speed: 3.2ms preprocess, 106.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1196.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1196.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1197.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1197.jpg: 640x480 20 handwrittens, 136.9ms\n",
      "Speed: 3.5ms preprocess, 136.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1197.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1197.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1198.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1198.jpg: 640x480 21 handwrittens, 99.5ms\n",
      "Speed: 3.3ms preprocess, 99.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1198.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1198.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1199.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1199.jpg: 640x480 22 handwrittens, 106.8ms\n",
      "Speed: 3.3ms preprocess, 106.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1199.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1199.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1200.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1200.jpg: 640x480 20 handwrittens, 102.7ms\n",
      "Speed: 2.5ms preprocess, 102.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1200.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1200.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1201.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1201.jpg: 640x480 21 handwrittens, 100.7ms\n",
      "Speed: 3.3ms preprocess, 100.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1201.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1201.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1202.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1202.jpg: 640x480 21 handwrittens, 101.0ms\n",
      "Speed: 3.1ms preprocess, 101.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1202.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1202.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1203.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1203.jpg: 640x480 20 handwrittens, 157.5ms\n",
      "Speed: 2.0ms preprocess, 157.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1203.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1203.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1204.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1204.jpg: 640x480 19 handwrittens, 169.7ms\n",
      "Speed: 3.8ms preprocess, 169.7ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1204.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1204.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1205.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1205.jpg: 640x480 21 handwrittens, 115.5ms\n",
      "Speed: 3.3ms preprocess, 115.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1205.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1205.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1206.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1206.jpg: 640x480 25 handwrittens, 119.0ms\n",
      "Speed: 4.0ms preprocess, 119.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1206.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1206.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1207.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1207.jpg: 640x480 19 handwrittens, 100.6ms\n",
      "Speed: 3.7ms preprocess, 100.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1207.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1207.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1208.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1208.jpg: 640x480 19 handwrittens, 110.9ms\n",
      "Speed: 3.2ms preprocess, 110.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1208.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1208.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1209.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1209.jpg: 640x480 19 handwrittens, 103.5ms\n",
      "Speed: 2.9ms preprocess, 103.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1209.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1209.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1210.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1210.jpg: 640x480 19 handwrittens, 104.6ms\n",
      "Speed: 3.2ms preprocess, 104.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1210.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1210.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1211.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1211.jpg: 640x480 19 handwrittens, 106.7ms\n",
      "Speed: 3.0ms preprocess, 106.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1211.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1211.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1212.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1212.jpg: 640x480 20 handwrittens, 111.7ms\n",
      "Speed: 1.9ms preprocess, 111.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1212.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1212.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1213.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1213.jpg: 640x480 19 handwrittens, 115.3ms\n",
      "Speed: 3.1ms preprocess, 115.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1213.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1213.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1214.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1214.jpg: 640x480 19 handwrittens, 137.3ms\n",
      "Speed: 3.1ms preprocess, 137.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1214.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1214.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1215.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1215.jpg: 640x480 19 handwrittens, 115.2ms\n",
      "Speed: 3.2ms preprocess, 115.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1215.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1215.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1216.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1216.jpg: 640x480 19 handwrittens, 107.0ms\n",
      "Speed: 3.4ms preprocess, 107.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1216.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1216.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1217.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1217.jpg: 640x480 19 handwrittens, 118.6ms\n",
      "Speed: 4.0ms preprocess, 118.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1217.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1217.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1218.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1218.jpg: 640x480 19 handwrittens, 109.5ms\n",
      "Speed: 2.8ms preprocess, 109.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1218.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1218.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1219.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1219.jpg: 640x480 23 handwrittens, 102.4ms\n",
      "Speed: 2.4ms preprocess, 102.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1219.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1219.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1220.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1220.jpg: 640x480 23 handwrittens, 111.7ms\n",
      "Speed: 2.1ms preprocess, 111.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1220.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1220.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1221.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1221.jpg: 640x480 22 handwrittens, 99.8ms\n",
      "Speed: 3.1ms preprocess, 99.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1221.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1221.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1222.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1222.jpg: 640x480 22 handwrittens, 116.7ms\n",
      "Speed: 3.7ms preprocess, 116.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1222.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1222.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1223.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1223.jpg: 640x480 22 handwrittens, 187.1ms\n",
      "Speed: 3.0ms preprocess, 187.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1223.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1223.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1224.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1224.jpg: 640x480 26 handwrittens, 159.6ms\n",
      "Speed: 4.4ms preprocess, 159.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1224.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1224.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1225.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1225.jpg: 640x480 21 handwrittens, 100.1ms\n",
      "Speed: 2.1ms preprocess, 100.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1225.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1225.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1226.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1226.jpg: 640x480 21 handwrittens, 110.4ms\n",
      "Speed: 2.3ms preprocess, 110.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1226.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1226.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1227.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1227.jpg: 640x480 19 handwrittens, 118.6ms\n",
      "Speed: 8.0ms preprocess, 118.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1227.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1227.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1228.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1228.jpg: 640x480 24 handwrittens, 107.1ms\n",
      "Speed: 3.0ms preprocess, 107.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1228.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1228.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1229.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1229.jpg: 640x480 25 handwrittens, 101.1ms\n",
      "Speed: 2.9ms preprocess, 101.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1229.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1229.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1230.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1230.jpg: 640x480 22 handwrittens, 113.4ms\n",
      "Speed: 11.9ms preprocess, 113.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1230.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1230.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1231.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1231.jpg: 640x480 20 handwrittens, 105.1ms\n",
      "Speed: 3.3ms preprocess, 105.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1231.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1231.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1232.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1232.jpg: 640x480 20 handwrittens, 155.0ms\n",
      "Speed: 4.9ms preprocess, 155.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1232.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1232.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1233.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1233.jpg: 640x480 21 handwrittens, 149.3ms\n",
      "Speed: 3.1ms preprocess, 149.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1233.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1233.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1234.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1234.jpg: 640x448 19 handwrittens, 108.8ms\n",
      "Speed: 4.1ms preprocess, 108.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved image to: results6\\TCE_1234.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1234.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1235.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1235.jpg: 640x448 22 handwrittens, 105.1ms\n",
      "Speed: 5.3ms preprocess, 105.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved image to: results6\\TCE_1235.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1235.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1236.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1236.jpg: 640x480 20 handwrittens, 126.9ms\n",
      "Speed: 3.0ms preprocess, 126.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1236.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1236.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1237.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1237.jpg: 640x448 20 handwrittens, 114.6ms\n",
      "Speed: 3.4ms preprocess, 114.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved image to: results6\\TCE_1237.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1237.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1238.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1238.jpg: 640x480 20 handwrittens, 106.3ms\n",
      "Speed: 2.2ms preprocess, 106.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1238.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1238.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1239.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1239.jpg: 640x480 21 handwrittens, 126.6ms\n",
      "Speed: 3.9ms preprocess, 126.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1239.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1239.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1240.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1240.jpg: 640x448 22 handwrittens, 105.8ms\n",
      "Speed: 9.3ms preprocess, 105.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved image to: results6\\TCE_1240.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1240.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1241.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1241.jpg: 640x480 20 handwrittens, 112.1ms\n",
      "Speed: 3.8ms preprocess, 112.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1241.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1241.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1242.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1242.jpg: 640x448 21 handwrittens, 175.1ms\n",
      "Speed: 11.1ms preprocess, 175.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved image to: results6\\TCE_1242.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1242.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1243.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1243.jpg: 640x448 19 handwrittens, 143.9ms\n",
      "Speed: 3.0ms preprocess, 143.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved image to: results6\\TCE_1243.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1243.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1244.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1244.jpg: 640x480 21 handwrittens, 112.8ms\n",
      "Speed: 3.6ms preprocess, 112.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1244.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1244.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1245.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1245.jpg: 640x480 22 handwrittens, 112.0ms\n",
      "Speed: 3.3ms preprocess, 112.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1245.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1245.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1246.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1246.jpg: 640x480 21 handwrittens, 91.5ms\n",
      "Speed: 3.0ms preprocess, 91.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1246.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1246.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1247.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1247.jpg: 640x480 24 handwrittens, 89.2ms\n",
      "Speed: 1.9ms preprocess, 89.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1247.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1247.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1248.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1248.jpg: 640x480 23 handwrittens, 110.3ms\n",
      "Speed: 3.3ms preprocess, 110.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1248.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1248.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1249.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1249.jpg: 640x480 22 handwrittens, 109.4ms\n",
      "Speed: 3.7ms preprocess, 109.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1249.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1249.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1250.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1250.jpg: 640x448 21 handwrittens, 113.7ms\n",
      "Speed: 5.6ms preprocess, 113.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Saved image to: results6\\TCE_1250.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1250.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1251.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1251.jpg: 640x480 21 handwrittens, 95.4ms\n",
      "Speed: 3.3ms preprocess, 95.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1251.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1251.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1252.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1252.jpg: 640x480 23 handwrittens, 103.6ms\n",
      "Speed: 2.4ms preprocess, 103.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1252.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1252.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1253.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1253.jpg: 640x480 22 handwrittens, 145.3ms\n",
      "Speed: 3.6ms preprocess, 145.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1253.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1253.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1254.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1254.jpg: 640x480 20 handwrittens, 98.7ms\n",
      "Speed: 2.5ms preprocess, 98.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1254.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1254.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1255.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1255.jpg: 640x480 24 handwrittens, 110.4ms\n",
      "Speed: 4.3ms preprocess, 110.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1255.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1255.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1256.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1256.jpg: 640x480 21 handwrittens, 95.1ms\n",
      "Speed: 4.6ms preprocess, 95.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1256.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1256.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1257.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1257.jpg: 640x480 21 handwrittens, 140.9ms\n",
      "Speed: 7.7ms preprocess, 140.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1257.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1257.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1258.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1258.jpg: 640x480 21 handwrittens, 109.7ms\n",
      "Speed: 2.7ms preprocess, 109.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1258.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1258.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1259.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1259.jpg: 640x480 21 handwrittens, 126.2ms\n",
      "Speed: 3.2ms preprocess, 126.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1259.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1259.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1260.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1260.jpg: 640x480 21 handwrittens, 112.8ms\n",
      "Speed: 7.6ms preprocess, 112.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1260.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1260.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1261.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1261.jpg: 640x480 21 handwrittens, 108.7ms\n",
      "Speed: 3.2ms preprocess, 108.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1261.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1261.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1262.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1262.jpg: 640x480 22 handwrittens, 145.1ms\n",
      "Speed: 3.4ms preprocess, 145.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1262.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1262.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1263.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1263.jpg: 640x480 21 handwrittens, 160.3ms\n",
      "Speed: 3.7ms preprocess, 160.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1263.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1263.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1264.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1264.jpg: 640x480 21 handwrittens, 93.3ms\n",
      "Speed: 3.0ms preprocess, 93.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1264.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1264.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1265.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1265.jpg: 640x480 27 handwrittens, 134.8ms\n",
      "Speed: 2.0ms preprocess, 134.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1265.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1265.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1266.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1266.jpg: 640x512 30 handwrittens, 162.0ms\n",
      "Speed: 3.4ms preprocess, 162.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Saved image to: results6\\TCE_1266.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1266.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1267.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1267.jpg: 640x480 25 handwrittens, 117.3ms\n",
      "Speed: 3.4ms preprocess, 117.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1267.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1267.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1268.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1268.jpg: 640x480 22 handwrittens, 115.1ms\n",
      "Speed: 4.9ms preprocess, 115.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1268.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1268.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1269.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1269.jpg: 640x480 23 handwrittens, 120.9ms\n",
      "Speed: 3.9ms preprocess, 120.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1269.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1269.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1270.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1270.jpg: 640x480 28 handwrittens, 109.4ms\n",
      "Speed: 3.0ms preprocess, 109.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1270.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1270.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1271.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1271.jpg: 640x480 24 handwrittens, 133.9ms\n",
      "Speed: 3.3ms preprocess, 133.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1271.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1271.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1272.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1272.jpg: 640x480 27 handwrittens, 113.5ms\n",
      "Speed: 3.5ms preprocess, 113.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1272.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1272.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1273.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1273.jpg: 640x480 20 handwrittens, 106.6ms\n",
      "Speed: 2.9ms preprocess, 106.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1273.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1273.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1274.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1274.jpg: 640x480 19 handwrittens, 95.4ms\n",
      "Speed: 3.0ms preprocess, 95.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1274.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1274.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1275.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1275.jpg: 640x480 21 handwrittens, 204.6ms\n",
      "Speed: 3.3ms preprocess, 204.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1275.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1275.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1276.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1276.jpg: 640x480 22 handwrittens, 112.3ms\n",
      "Speed: 3.8ms preprocess, 112.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1276.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1276.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1277.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1277.jpg: 640x480 22 handwrittens, 107.6ms\n",
      "Speed: 3.4ms preprocess, 107.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1277.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1277.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1278.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1278.jpg: 640x480 19 handwrittens, 102.8ms\n",
      "Speed: 3.4ms preprocess, 102.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1278.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1278.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1279.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1279.jpg: 640x480 20 handwrittens, 97.7ms\n",
      "Speed: 2.6ms preprocess, 97.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1279.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1279.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1280.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1280.jpg: 640x480 20 handwrittens, 99.5ms\n",
      "Speed: 2.7ms preprocess, 99.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1280.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1280.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1281.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1281.jpg: 640x480 25 handwrittens, 125.9ms\n",
      "Speed: 13.2ms preprocess, 125.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1281.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1281.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1282.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1282.jpg: 640x480 21 handwrittens, 133.8ms\n",
      "Speed: 3.7ms preprocess, 133.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1282.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1282.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1283.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1283.jpg: 640x480 22 handwrittens, 127.9ms\n",
      "Speed: 3.0ms preprocess, 127.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1283.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1283.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1284.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1284.jpg: 640x480 24 handwrittens, 122.5ms\n",
      "Speed: 4.2ms preprocess, 122.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1284.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1284.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1285.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1285.jpg: 640x480 21 handwrittens, 110.1ms\n",
      "Speed: 3.5ms preprocess, 110.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1285.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1285.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1286.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1286.jpg: 640x480 21 handwrittens, 102.2ms\n",
      "Speed: 2.7ms preprocess, 102.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1286.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1286.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1287.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1287.jpg: 640x480 24 handwrittens, 104.9ms\n",
      "Speed: 3.3ms preprocess, 104.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1287.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1287.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1288.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1288.jpg: 640x480 22 handwrittens, 102.3ms\n",
      "Speed: 3.1ms preprocess, 102.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1288.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1288.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1289.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1289.jpg: 640x480 21 handwrittens, 141.3ms\n",
      "Speed: 17.0ms preprocess, 141.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1289.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1289.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1290.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1290.jpg: 640x480 23 handwrittens, 121.1ms\n",
      "Speed: 3.4ms preprocess, 121.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1290.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1290.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1291.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1291.jpg: 640x480 21 handwrittens, 159.2ms\n",
      "Speed: 3.7ms preprocess, 159.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1291.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1291.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1292.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1292.jpg: 640x480 25 handwrittens, 110.1ms\n",
      "Speed: 3.7ms preprocess, 110.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1292.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1292.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1293.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1293.jpg: 640x480 20 handwrittens, 101.2ms\n",
      "Speed: 3.1ms preprocess, 101.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1293.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1293.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1294.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1294.jpg: 640x480 21 handwrittens, 129.9ms\n",
      "Speed: 3.2ms preprocess, 129.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1294.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1294.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1295.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1295.jpg: 640x480 21 handwrittens, 108.1ms\n",
      "Speed: 3.1ms preprocess, 108.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1295.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1295.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1296.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1296.jpg: 640x480 20 handwrittens, 99.9ms\n",
      "Speed: 2.9ms preprocess, 99.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1296.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1296.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1297.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1297.jpg: 640x480 28 handwrittens, 101.0ms\n",
      "Speed: 3.2ms preprocess, 101.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1297.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1297.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1298.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1298.jpg: 640x480 20 handwrittens, 93.8ms\n",
      "Speed: 2.0ms preprocess, 93.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1298.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1298.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1299.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1299.jpg: 640x480 27 handwrittens, 110.5ms\n",
      "Speed: 7.0ms preprocess, 110.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1299.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1299.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1300.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1300.jpg: 640x480 24 handwrittens, 164.4ms\n",
      "Speed: 3.2ms preprocess, 164.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1300.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1300.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1301.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1301.jpg: 640x480 21 handwrittens, 239.2ms\n",
      "Speed: 5.4ms preprocess, 239.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1301.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1301.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1302.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1302.jpg: 640x480 22 handwrittens, 116.3ms\n",
      "Speed: 3.1ms preprocess, 116.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1302.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1302.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1303.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1303.jpg: 640x480 21 handwrittens, 111.8ms\n",
      "Speed: 2.9ms preprocess, 111.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1303.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1303.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1304.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1304.jpg: 640x480 20 handwrittens, 96.6ms\n",
      "Speed: 5.0ms preprocess, 96.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1304.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1304.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1305.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1305.jpg: 640x480 24 handwrittens, 104.8ms\n",
      "Speed: 2.9ms preprocess, 104.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1305.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1305.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1306.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1306.jpg: 640x480 19 handwrittens, 96.8ms\n",
      "Speed: 3.0ms preprocess, 96.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1306.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1306.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1307.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1307.jpg: 640x480 20 handwrittens, 95.9ms\n",
      "Speed: 2.8ms preprocess, 95.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1307.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1307.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1308.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1308.jpg: 640x480 22 handwrittens, 140.4ms\n",
      "Speed: 9.1ms preprocess, 140.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1308.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1308.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1309.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1309.jpg: 640x480 23 handwrittens, 214.1ms\n",
      "Speed: 6.7ms preprocess, 214.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1309.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1309.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1310.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1310.jpg: 640x480 22 handwrittens, 107.6ms\n",
      "Speed: 3.3ms preprocess, 107.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1310.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1310.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1311.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1311.jpg: 640x480 21 handwrittens, 131.9ms\n",
      "Speed: 3.0ms preprocess, 131.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1311.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1311.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1312.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1312.jpg: 640x480 20 handwrittens, 116.6ms\n",
      "Speed: 3.1ms preprocess, 116.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1312.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1312.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1313.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1313.jpg: 640x480 21 handwrittens, 112.9ms\n",
      "Speed: 3.5ms preprocess, 112.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1313.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1313.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1314.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1314.jpg: 640x480 21 handwrittens, 111.4ms\n",
      "Speed: 4.2ms preprocess, 111.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1314.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1314.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1315.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1315.jpg: 640x480 20 handwrittens, 156.8ms\n",
      "Speed: 2.9ms preprocess, 156.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1315.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1315.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1316.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1316.jpg: 640x480 22 handwrittens, 119.9ms\n",
      "Speed: 3.3ms preprocess, 119.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1316.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1316.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1317.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1317.jpg: 640x480 24 handwrittens, 194.1ms\n",
      "Speed: 3.4ms preprocess, 194.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1317.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1317.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1318.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1318.jpg: 640x480 21 handwrittens, 203.5ms\n",
      "Speed: 6.2ms preprocess, 203.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1318.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1318.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1319.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1319.jpg: 640x480 25 handwrittens, 149.5ms\n",
      "Speed: 9.1ms preprocess, 149.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1319.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1319.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1320.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1320.jpg: 640x480 22 handwrittens, 142.3ms\n",
      "Speed: 3.4ms preprocess, 142.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1320.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1320.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1321.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1321.jpg: 640x480 21 handwrittens, 131.9ms\n",
      "Speed: 4.2ms preprocess, 131.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1321.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1321.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1322.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1322.jpg: 640x480 23 handwrittens, 103.1ms\n",
      "Speed: 3.5ms preprocess, 103.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1322.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1322.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1323.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1323.jpg: 640x480 20 handwrittens, 139.7ms\n",
      "Speed: 6.7ms preprocess, 139.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1323.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1323.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1324.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1324.jpg: 640x480 18 handwrittens, 104.6ms\n",
      "Speed: 8.3ms preprocess, 104.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1324.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1324.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1325.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1325.jpg: 640x480 21 handwrittens, 104.9ms\n",
      "Speed: 2.8ms preprocess, 104.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1325.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1325.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1326.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1326.jpg: 640x480 19 handwrittens, 111.2ms\n",
      "Speed: 2.2ms preprocess, 111.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1326.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1326.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1327.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1327.jpg: 640x480 23 handwrittens, 115.1ms\n",
      "Speed: 3.6ms preprocess, 115.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1327.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1327.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1328.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1328.jpg: 640x480 22 handwrittens, 130.2ms\n",
      "Speed: 4.3ms preprocess, 130.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1328.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1328.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1329.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1329.jpg: 640x480 20 handwrittens, 115.2ms\n",
      "Speed: 3.9ms preprocess, 115.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1329.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1329.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1330.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1330.jpg: 640x480 20 handwrittens, 167.7ms\n",
      "Speed: 3.4ms preprocess, 167.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1330.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1330.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1331.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1331.jpg: 640x480 22 handwrittens, 145.8ms\n",
      "Speed: 3.3ms preprocess, 145.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1331.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1331.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1332.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1332.jpg: 640x480 20 handwrittens, 127.0ms\n",
      "Speed: 3.3ms preprocess, 127.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1332.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1332.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1333.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1333.jpg: 640x480 19 handwrittens, 123.5ms\n",
      "Speed: 4.2ms preprocess, 123.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1333.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1333.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1334.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1334.jpg: 640x480 24 handwrittens, 114.5ms\n",
      "Speed: 3.8ms preprocess, 114.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1334.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1334.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1335.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1335.jpg: 640x480 23 handwrittens, 98.6ms\n",
      "Speed: 3.3ms preprocess, 98.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1335.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1335.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1336.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1336.jpg: 640x480 18 handwrittens, 125.0ms\n",
      "Speed: 3.5ms preprocess, 125.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1336.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1336.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1337.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1337.jpg: 640x480 19 handwrittens, 124.3ms\n",
      "Speed: 3.1ms preprocess, 124.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1337.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1337.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1338.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1338.jpg: 640x480 23 handwrittens, 115.0ms\n",
      "Speed: 3.9ms preprocess, 115.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1338.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1338.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1339.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1339.jpg: 640x480 22 handwrittens, 120.2ms\n",
      "Speed: 3.4ms preprocess, 120.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1339.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1339.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1340.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1340.jpg: 640x480 24 handwrittens, 129.4ms\n",
      "Speed: 3.6ms preprocess, 129.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1340.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1340.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1341.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1341.jpg: 640x480 20 handwrittens, 129.5ms\n",
      "Speed: 3.2ms preprocess, 129.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1341.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1341.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1342.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1342.jpg: 640x480 23 handwrittens, 184.9ms\n",
      "Speed: 3.7ms preprocess, 184.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1342.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1342.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1343.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1343.jpg: 640x480 21 handwrittens, 119.2ms\n",
      "Speed: 3.5ms preprocess, 119.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1343.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1343.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1344.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1344.jpg: 640x512 24 handwrittens, 120.3ms\n",
      "Speed: 3.3ms preprocess, 120.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Saved image to: results6\\TCE_1344.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1344.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1345.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1345.jpg: 640x480 19 handwrittens, 114.8ms\n",
      "Speed: 3.2ms preprocess, 114.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1345.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1345.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1346.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1346.jpg: 640x480 20 handwrittens, 184.4ms\n",
      "Speed: 3.9ms preprocess, 184.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1346.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1346.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1347.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1347.jpg: 640x480 25 handwrittens, 156.9ms\n",
      "Speed: 4.1ms preprocess, 156.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1347.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1347.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1348.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1348.jpg: 640x480 19 handwrittens, 127.1ms\n",
      "Speed: 3.3ms preprocess, 127.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1348.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1348.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1349.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1349.jpg: 640x480 20 handwrittens, 137.3ms\n",
      "Speed: 3.4ms preprocess, 137.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1349.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1349.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1350.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1350.jpg: 640x480 20 handwrittens, 129.3ms\n",
      "Speed: 3.3ms preprocess, 129.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1350.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1350.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1351.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1351.jpg: 640x480 23 handwrittens, 129.6ms\n",
      "Speed: 3.6ms preprocess, 129.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1351.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1351.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1352.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1352.jpg: 640x480 26 handwrittens, 123.6ms\n",
      "Speed: 6.9ms preprocess, 123.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1352.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1352.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1353.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1353.jpg: 640x480 23 handwrittens, 137.9ms\n",
      "Speed: 3.2ms preprocess, 137.9ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1353.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1353.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1354.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1354.jpg: 640x480 22 handwrittens, 117.5ms\n",
      "Speed: 3.5ms preprocess, 117.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1354.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1354.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1355.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1355.jpg: 640x480 23 handwrittens, 204.0ms\n",
      "Speed: 3.6ms preprocess, 204.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1355.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1355.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1356.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1356.jpg: 640x480 25 handwrittens, 109.7ms\n",
      "Speed: 3.1ms preprocess, 109.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1356.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1356.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1357.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1357.jpg: 640x480 24 handwrittens, 120.5ms\n",
      "Speed: 3.6ms preprocess, 120.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1357.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1357.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1358.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1358.jpg: 640x480 26 handwrittens, 121.4ms\n",
      "Speed: 3.2ms preprocess, 121.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1358.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1358.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1359.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1359.jpg: 640x480 23 handwrittens, 111.1ms\n",
      "Speed: 2.4ms preprocess, 111.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1359.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1359.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1360.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1360.jpg: 640x480 30 handwrittens, 146.5ms\n",
      "Speed: 3.6ms preprocess, 146.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1360.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1360.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1361.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1361.jpg: 640x480 26 handwrittens, 153.0ms\n",
      "Speed: 3.2ms preprocess, 153.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1361.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1361.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1362.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1362.jpg: 640x480 24 handwrittens, 189.2ms\n",
      "Speed: 11.2ms preprocess, 189.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1362.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1362.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1363.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1363.jpg: 640x480 24 handwrittens, 136.1ms\n",
      "Speed: 4.6ms preprocess, 136.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1363.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1363.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1364.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1364.jpg: 640x480 19 handwrittens, 113.3ms\n",
      "Speed: 2.0ms preprocess, 113.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1364.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1364.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1365.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1365.jpg: 640x480 25 handwrittens, 126.6ms\n",
      "Speed: 3.6ms preprocess, 126.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1365.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1365.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1366.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1366.jpg: 640x480 22 handwrittens, 104.8ms\n",
      "Speed: 4.6ms preprocess, 104.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1366.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1366.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1367.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1367.jpg: 640x480 22 handwrittens, 104.8ms\n",
      "Speed: 3.3ms preprocess, 104.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1367.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1367.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1368.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1368.jpg: 640x480 19 handwrittens, 94.1ms\n",
      "Speed: 3.1ms preprocess, 94.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1368.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1368.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1369.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1369.jpg: 640x480 21 handwrittens, 94.3ms\n",
      "Speed: 2.7ms preprocess, 94.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1369.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1369.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1370.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1370.jpg: 640x480 21 handwrittens, 111.1ms\n",
      "Speed: 4.5ms preprocess, 111.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1370.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1370.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1371.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1371.jpg: 640x480 20 handwrittens, 227.3ms\n",
      "Speed: 4.2ms preprocess, 227.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1371.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1371.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1372.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1372.jpg: 640x480 23 handwrittens, 113.0ms\n",
      "Speed: 3.1ms preprocess, 113.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1372.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1372.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1373.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1373.jpg: 640x480 22 handwrittens, 108.3ms\n",
      "Speed: 3.0ms preprocess, 108.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1373.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1373.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1374.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1374.jpg: 640x480 19 handwrittens, 124.5ms\n",
      "Speed: 9.4ms preprocess, 124.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1374.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1374.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1375.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1375.jpg: 640x480 20 handwrittens, 104.6ms\n",
      "Speed: 5.5ms preprocess, 104.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1375.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1375.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1376.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1376.jpg: 640x480 19 handwrittens, 99.9ms\n",
      "Speed: 1.8ms preprocess, 99.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1376.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1376.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1377.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1377.jpg: 640x480 20 handwrittens, 92.4ms\n",
      "Speed: 2.2ms preprocess, 92.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1377.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1377.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1378.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1378.jpg: 640x480 19 handwrittens, 90.0ms\n",
      "Speed: 1.9ms preprocess, 90.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1378.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1378.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1379.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1379.jpg: 640x480 19 handwrittens, 104.0ms\n",
      "Speed: 9.0ms preprocess, 104.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1379.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1379.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1380.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1380.jpg: 640x480 20 handwrittens, 162.4ms\n",
      "Speed: 4.6ms preprocess, 162.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1380.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1380.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1381.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1381.jpg: 640x480 22 handwrittens, 158.2ms\n",
      "Speed: 4.1ms preprocess, 158.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1381.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1381.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1382.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1382.jpg: 640x480 21 handwrittens, 140.2ms\n",
      "Speed: 3.9ms preprocess, 140.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1382.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1382.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1383.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1383.jpg: 640x480 20 handwrittens, 152.8ms\n",
      "Speed: 2.3ms preprocess, 152.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1383.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1383.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1384.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1384.jpg: 640x512 26 handwrittens, 108.9ms\n",
      "Speed: 3.4ms preprocess, 108.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Saved image to: results6\\TCE_1384.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1384.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1385.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1385.jpg: 640x480 22 handwrittens, 115.2ms\n",
      "Speed: 3.3ms preprocess, 115.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1385.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1385.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1386.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1386.jpg: 640x480 19 handwrittens, 88.7ms\n",
      "Speed: 3.0ms preprocess, 88.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1386.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1386.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1387.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1387.jpg: 640x480 20 handwrittens, 127.9ms\n",
      "Speed: 2.3ms preprocess, 127.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1387.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1387.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1388.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1388.jpg: 640x480 22 handwrittens, 125.7ms\n",
      "Speed: 3.3ms preprocess, 125.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1388.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1388.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1389.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1389.jpg: 640x480 20 handwrittens, 118.6ms\n",
      "Speed: 4.4ms preprocess, 118.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1389.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1389.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1390.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1390.jpg: 640x480 21 handwrittens, 105.4ms\n",
      "Speed: 2.8ms preprocess, 105.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1390.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1390.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1391.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1391.jpg: 640x480 22 handwrittens, 140.8ms\n",
      "Speed: 3.5ms preprocess, 140.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1391.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1391.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1392.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1392.jpg: 640x480 21 handwrittens, 150.9ms\n",
      "Speed: 4.8ms preprocess, 150.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1392.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1392.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1393.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1393.jpg: 640x480 20 handwrittens, 106.4ms\n",
      "Speed: 2.5ms preprocess, 106.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1393.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1393.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1394.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1394.jpg: 640x480 25 handwrittens, 101.3ms\n",
      "Speed: 5.5ms preprocess, 101.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1394.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1394.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1395.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1395.jpg: 640x480 21 handwrittens, 98.3ms\n",
      "Speed: 3.3ms preprocess, 98.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1395.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1395.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1396.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1396.jpg: 640x480 19 handwrittens, 107.0ms\n",
      "Speed: 3.0ms preprocess, 107.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1396.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1396.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1397.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1397.jpg: 640x480 19 handwrittens, 100.5ms\n",
      "Speed: 2.8ms preprocess, 100.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1397.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1397.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1398.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1398.jpg: 640x480 20 handwrittens, 129.2ms\n",
      "Speed: 4.3ms preprocess, 129.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1398.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1398.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1399.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1399.jpg: 640x480 19 handwrittens, 114.6ms\n",
      "Speed: 3.4ms preprocess, 114.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1399.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1399.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1400.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1400.jpg: 640x480 20 handwrittens, 120.0ms\n",
      "Speed: 3.2ms preprocess, 120.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1400.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1400.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1401.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1401.jpg: 640x480 22 handwrittens, 197.6ms\n",
      "Speed: 3.7ms preprocess, 197.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1401.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1401.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1402.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1402.jpg: 640x480 21 handwrittens, 107.6ms\n",
      "Speed: 2.8ms preprocess, 107.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1402.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1402.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1403.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1403.jpg: 640x480 22 handwrittens, 98.4ms\n",
      "Speed: 3.0ms preprocess, 98.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1403.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1403.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1404.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1404.jpg: 640x480 19 handwrittens, 92.4ms\n",
      "Speed: 1.8ms preprocess, 92.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1404.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1404.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1405.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1405.jpg: 640x480 21 handwrittens, 124.4ms\n",
      "Speed: 42.6ms preprocess, 124.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1405.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1405.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1406.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1406.jpg: 640x480 23 handwrittens, 157.3ms\n",
      "Speed: 4.3ms preprocess, 157.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1406.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1406.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1407.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1407.jpg: 640x480 20 handwrittens, 104.5ms\n",
      "Speed: 2.7ms preprocess, 104.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1407.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1407.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1408.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1408.jpg: 640x480 22 handwrittens, 103.7ms\n",
      "Speed: 2.9ms preprocess, 103.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1408.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1408.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1409.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1409.jpg: 640x480 21 handwrittens, 97.1ms\n",
      "Speed: 2.4ms preprocess, 97.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1409.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1409.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1410.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1410.jpg: 640x480 19 handwrittens, 128.6ms\n",
      "Speed: 3.0ms preprocess, 128.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1410.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1410.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1411.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1411.jpg: 640x480 19 handwrittens, 116.7ms\n",
      "Speed: 2.1ms preprocess, 116.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1411.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1411.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1412.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1412.jpg: 640x480 21 handwrittens, 102.1ms\n",
      "Speed: 2.4ms preprocess, 102.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1412.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1412.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1413.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1413.jpg: 640x480 20 handwrittens, 118.6ms\n",
      "Speed: 2.4ms preprocess, 118.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1413.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1413.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1414.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1414.jpg: 640x480 21 handwrittens, 140.6ms\n",
      "Speed: 19.3ms preprocess, 140.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1414.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1414.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1415.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1415.jpg: 640x480 22 handwrittens, 121.9ms\n",
      "Speed: 2.9ms preprocess, 121.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1415.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1415.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1416.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1416.jpg: 640x480 23 handwrittens, 101.3ms\n",
      "Speed: 4.5ms preprocess, 101.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1416.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1416.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1417.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1417.jpg: 640x480 19 handwrittens, 100.6ms\n",
      "Speed: 2.9ms preprocess, 100.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1417.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1417.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1418.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1418.jpg: 640x480 19 handwrittens, 147.4ms\n",
      "Speed: 3.9ms preprocess, 147.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1418.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1418.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1419.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1419.jpg: 640x480 21 handwrittens, 107.3ms\n",
      "Speed: 3.3ms preprocess, 107.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1419.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1419.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1420.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1420.jpg: 640x480 22 handwrittens, 140.0ms\n",
      "Speed: 3.7ms preprocess, 140.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1420.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1420.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1421.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1421.jpg: 640x480 19 handwrittens, 94.8ms\n",
      "Speed: 3.0ms preprocess, 94.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1421.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1421.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1422.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1422.jpg: 640x480 22 handwrittens, 173.0ms\n",
      "Speed: 3.5ms preprocess, 173.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1422.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1422.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1423.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1423.jpg: 640x480 24 handwrittens, 100.1ms\n",
      "Speed: 2.1ms preprocess, 100.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1423.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1423.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1424.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1424.jpg: 640x480 20 handwrittens, 133.1ms\n",
      "Speed: 2.2ms preprocess, 133.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1424.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1424.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1425.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1425.jpg: 640x480 20 handwrittens, 104.0ms\n",
      "Speed: 2.9ms preprocess, 104.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1425.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1425.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1426.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1426.jpg: 640x480 19 handwrittens, 154.3ms\n",
      "Speed: 4.7ms preprocess, 154.3ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1426.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1426.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1427.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1427.jpg: 640x480 21 handwrittens, 110.8ms\n",
      "Speed: 2.9ms preprocess, 110.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1427.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1427.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1428.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1428.jpg: 640x480 19 handwrittens, 106.7ms\n",
      "Speed: 7.5ms preprocess, 106.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1428.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1428.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1429.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1429.jpg: 640x480 20 handwrittens, 126.4ms\n",
      "Speed: 3.2ms preprocess, 126.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1429.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1429.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1430.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1430.jpg: 640x480 24 handwrittens, 131.2ms\n",
      "Speed: 3.5ms preprocess, 131.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1430.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1430.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1431.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1431.jpg: 640x480 20 handwrittens, 111.0ms\n",
      "Speed: 2.9ms preprocess, 111.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1431.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1431.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1432.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1432.jpg: 640x480 21 handwrittens, 124.9ms\n",
      "Speed: 13.1ms preprocess, 124.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1432.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1432.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1433.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1433.jpg: 640x480 21 handwrittens, 117.7ms\n",
      "Speed: 4.1ms preprocess, 117.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1433.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1433.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1434.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1434.jpg: 640x480 19 handwrittens, 156.2ms\n",
      "Speed: 5.2ms preprocess, 156.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1434.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1434.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1435.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1435.jpg: 640x480 23 handwrittens, 137.3ms\n",
      "Speed: 4.7ms preprocess, 137.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1435.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1435.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1436.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1436.jpg: 640x480 23 handwrittens, 112.6ms\n",
      "Speed: 6.5ms preprocess, 112.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1436.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1436.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1437.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1437.jpg: 640x480 21 handwrittens, 174.4ms\n",
      "Speed: 4.4ms preprocess, 174.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1437.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1437.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1438.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1438.jpg: 640x480 23 handwrittens, 240.9ms\n",
      "Speed: 5.5ms preprocess, 240.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1438.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1438.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1439.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1439.jpg: 640x480 19 handwrittens, 169.7ms\n",
      "Speed: 3.2ms preprocess, 169.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1439.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1439.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1440.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1440.jpg: 640x480 20 handwrittens, 115.4ms\n",
      "Speed: 3.2ms preprocess, 115.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1440.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1440.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1441.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1441.jpg: 640x480 20 handwrittens, 133.3ms\n",
      "Speed: 3.5ms preprocess, 133.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1441.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1441.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1442.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1442.jpg: 640x480 21 handwrittens, 132.0ms\n",
      "Speed: 3.4ms preprocess, 132.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1442.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1442.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1443.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1443.jpg: 640x480 20 handwrittens, 234.1ms\n",
      "Speed: 3.5ms preprocess, 234.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1443.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1443.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1444.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1444.jpg: 640x480 20 handwrittens, 130.9ms\n",
      "Speed: 4.0ms preprocess, 130.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1444.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1444.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1445.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1445.jpg: 640x480 23 handwrittens, 142.6ms\n",
      "Speed: 3.7ms preprocess, 142.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1445.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1445.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1446.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1446.jpg: 640x480 19 handwrittens, 233.2ms\n",
      "Speed: 5.7ms preprocess, 233.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1446.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1446.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1447.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1447.jpg: 640x480 23 handwrittens, 183.8ms\n",
      "Speed: 51.7ms preprocess, 183.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1447.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1447.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1448.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1448.jpg: 640x480 21 handwrittens, 106.9ms\n",
      "Speed: 3.4ms preprocess, 106.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1448.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1448.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1449.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1449.jpg: 640x480 23 handwrittens, 112.1ms\n",
      "Speed: 7.8ms preprocess, 112.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1449.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1449.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1450.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1450.jpg: 640x480 25 handwrittens, 109.7ms\n",
      "Speed: 3.4ms preprocess, 109.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1450.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1450.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1451.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1451.jpg: 640x480 23 handwrittens, 153.4ms\n",
      "Speed: 7.2ms preprocess, 153.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1451.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1451.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1452.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1452.jpg: 640x480 20 handwrittens, 98.6ms\n",
      "Speed: 3.0ms preprocess, 98.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1452.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1452.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1453.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1453.jpg: 640x480 19 handwrittens, 100.2ms\n",
      "Speed: 3.5ms preprocess, 100.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1453.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1453.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1454.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1454.jpg: 640x480 21 handwrittens, 90.8ms\n",
      "Speed: 2.8ms preprocess, 90.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1454.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1454.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1455.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1455.jpg: 640x480 21 handwrittens, 179.9ms\n",
      "Speed: 3.0ms preprocess, 179.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1455.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1455.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1456.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1456.jpg: 640x480 21 handwrittens, 112.0ms\n",
      "Speed: 2.8ms preprocess, 112.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1456.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1456.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1457.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1457.jpg: 640x480 20 handwrittens, 101.0ms\n",
      "Speed: 8.0ms preprocess, 101.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1457.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1457.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1458.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1458.jpg: 640x480 22 handwrittens, 93.5ms\n",
      "Speed: 1.8ms preprocess, 93.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1458.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1458.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1459.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1459.jpg: 640x480 19 handwrittens, 121.2ms\n",
      "Speed: 24.3ms preprocess, 121.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1459.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1459.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1460.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1460.jpg: 640x480 21 handwrittens, 99.7ms\n",
      "Speed: 2.1ms preprocess, 99.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1460.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1460.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1461.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1461.jpg: 640x480 21 handwrittens, 102.2ms\n",
      "Speed: 9.5ms preprocess, 102.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1461.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1461.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1462.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1462.jpg: 640x480 23 handwrittens, 101.1ms\n",
      "Speed: 2.8ms preprocess, 101.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1462.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1462.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1463.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1463.jpg: 640x480 20 handwrittens, 161.5ms\n",
      "Speed: 4.1ms preprocess, 161.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1463.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1463.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1464.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1464.jpg: 640x480 20 handwrittens, 109.0ms\n",
      "Speed: 3.0ms preprocess, 109.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1464.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1464.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1465.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1465.jpg: 640x480 23 handwrittens, 211.7ms\n",
      "Speed: 6.3ms preprocess, 211.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1465.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1465.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1466.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1466.jpg: 640x480 19 handwrittens, 177.9ms\n",
      "Speed: 6.5ms preprocess, 177.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1466.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1466.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1467.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1467.jpg: 640x480 19 handwrittens, 153.3ms\n",
      "Speed: 3.3ms preprocess, 153.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1467.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1467.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1468.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1468.jpg: 640x480 19 handwrittens, 130.7ms\n",
      "Speed: 4.1ms preprocess, 130.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1468.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1468.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1469.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1469.jpg: 640x480 21 handwrittens, 127.0ms\n",
      "Speed: 3.8ms preprocess, 127.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1469.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1469.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1470.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1470.jpg: 640x480 19 handwrittens, 108.1ms\n",
      "Speed: 3.3ms preprocess, 108.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1470.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1470.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1471.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1471.jpg: 640x480 22 handwrittens, 135.3ms\n",
      "Speed: 6.2ms preprocess, 135.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1471.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1471.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1472.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1472.jpg: 640x480 25 handwrittens, 93.2ms\n",
      "Speed: 2.0ms preprocess, 93.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1472.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1472.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1473.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1473.jpg: 640x480 22 handwrittens, 93.2ms\n",
      "Speed: 1.9ms preprocess, 93.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1473.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1473.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1474.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1474.jpg: 640x480 18 handwrittens, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1474.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1474.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1475.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1475.jpg: 640x480 21 handwrittens, 201.6ms\n",
      "Speed: 8.1ms preprocess, 201.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1475.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1475.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1476.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1476.jpg: 640x480 22 handwrittens, 111.2ms\n",
      "Speed: 3.8ms preprocess, 111.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1476.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1476.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1477.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1477.jpg: 640x480 22 handwrittens, 147.4ms\n",
      "Speed: 3.2ms preprocess, 147.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1477.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1477.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1478.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1478.jpg: 640x480 22 handwrittens, 110.6ms\n",
      "Speed: 3.0ms preprocess, 110.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1478.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1478.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1479.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1479.jpg: 640x480 19 handwrittens, 155.6ms\n",
      "Speed: 3.1ms preprocess, 155.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1479.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1479.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1480.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1480.jpg: 640x480 20 handwrittens, 104.8ms\n",
      "Speed: 3.2ms preprocess, 104.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1480.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1480.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1481.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1481.jpg: 640x480 19 handwrittens, 111.5ms\n",
      "Speed: 3.0ms preprocess, 111.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1481.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1481.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1482.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1482.jpg: 640x480 20 handwrittens, 99.9ms\n",
      "Speed: 2.0ms preprocess, 99.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1482.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1482.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1483.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1483.jpg: 640x480 20 handwrittens, 112.1ms\n",
      "Speed: 3.7ms preprocess, 112.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1483.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1483.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1484.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1484.jpg: 640x480 21 handwrittens, 114.3ms\n",
      "Speed: 3.4ms preprocess, 114.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1484.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1484.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1485.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1485.jpg: 640x480 20 handwrittens, 93.5ms\n",
      "Speed: 1.9ms preprocess, 93.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1485.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1485.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1486.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1486.jpg: 640x480 19 handwrittens, 93.0ms\n",
      "Speed: 1.9ms preprocess, 93.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1486.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1486.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1487.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1487.jpg: 640x480 20 handwrittens, 91.8ms\n",
      "Speed: 2.9ms preprocess, 91.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1487.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1487.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1488.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1488.jpg: 640x480 19 handwrittens, 92.8ms\n",
      "Speed: 2.9ms preprocess, 92.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1488.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1488.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1489.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1489.jpg: 640x480 20 handwrittens, 98.3ms\n",
      "Speed: 1.9ms preprocess, 98.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1489.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1489.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1490.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1490.jpg: 640x480 21 handwrittens, 95.2ms\n",
      "Speed: 2.2ms preprocess, 95.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1490.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1490.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1491.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1491.jpg: 640x480 23 handwrittens, 92.0ms\n",
      "Speed: 2.3ms preprocess, 92.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1491.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1491.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1492.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1492.jpg: 640x480 20 handwrittens, 103.7ms\n",
      "Speed: 3.0ms preprocess, 103.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1492.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1492.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1493.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1493.jpg: 640x480 21 handwrittens, 108.9ms\n",
      "Speed: 3.0ms preprocess, 108.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1493.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1493.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1494.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1494.jpg: 640x480 22 handwrittens, 196.5ms\n",
      "Speed: 4.3ms preprocess, 196.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1494.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1494.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1495.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1495.jpg: 640x480 24 handwrittens, 192.7ms\n",
      "Speed: 5.4ms preprocess, 192.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1495.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1495.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1496.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1496.jpg: 640x480 24 handwrittens, 156.9ms\n",
      "Speed: 11.1ms preprocess, 156.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1496.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1496.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1497.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1497.jpg: 640x480 19 handwrittens, 135.8ms\n",
      "Speed: 3.2ms preprocess, 135.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1497.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1497.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1498.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1498.jpg: 640x480 19 handwrittens, 106.6ms\n",
      "Speed: 3.5ms preprocess, 106.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1498.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1498.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1499.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1499.jpg: 640x480 21 handwrittens, 111.0ms\n",
      "Speed: 3.0ms preprocess, 111.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1499.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1499.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1500.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\TCE_1500.jpg: 640x480 24 handwrittens, 172.4ms\n",
      "Speed: 3.8ms preprocess, 172.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\TCE_1500.jpg\n",
      "Saved labels to: results6\\labels\\TCE_1500.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_1000.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_1000.jpg: 640x480 22 handwrittens, 106.8ms\n",
      "Speed: 3.2ms preprocess, 106.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_1000.jpg\n",
      "Saved labels to: results6\\labels\\VIT_1000.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_701.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_701.jpg: 640x480 25 handwrittens, 100.8ms\n",
      "Speed: 2.3ms preprocess, 100.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_701.jpg\n",
      "Saved labels to: results6\\labels\\VIT_701.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_702.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_702.jpg: 640x480 21 handwrittens, 133.2ms\n",
      "Speed: 3.4ms preprocess, 133.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_702.jpg\n",
      "Saved labels to: results6\\labels\\VIT_702.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_703.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_703.jpg: 640x480 23 handwrittens, 133.6ms\n",
      "Speed: 12.6ms preprocess, 133.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_703.jpg\n",
      "Saved labels to: results6\\labels\\VIT_703.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_704.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_704.jpg: 640x480 25 handwrittens, 112.4ms\n",
      "Speed: 2.2ms preprocess, 112.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_704.jpg\n",
      "Saved labels to: results6\\labels\\VIT_704.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_705.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_705.jpg: 640x480 21 handwrittens, 87.9ms\n",
      "Speed: 2.8ms preprocess, 87.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_705.jpg\n",
      "Saved labels to: results6\\labels\\VIT_705.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_706.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_706.jpg: 640x480 28 handwrittens, 99.0ms\n",
      "Speed: 2.9ms preprocess, 99.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_706.jpg\n",
      "Saved labels to: results6\\labels\\VIT_706.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_707.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_707.jpg: 640x480 25 handwrittens, 126.3ms\n",
      "Speed: 2.4ms preprocess, 126.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_707.jpg\n",
      "Saved labels to: results6\\labels\\VIT_707.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_708.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_708.jpg: 640x480 27 handwrittens, 92.8ms\n",
      "Speed: 2.6ms preprocess, 92.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_708.jpg\n",
      "Saved labels to: results6\\labels\\VIT_708.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_709.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_709.jpg: 640x480 22 handwrittens, 93.6ms\n",
      "Speed: 3.0ms preprocess, 93.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_709.jpg\n",
      "Saved labels to: results6\\labels\\VIT_709.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_710.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_710.jpg: 640x480 25 handwrittens, 89.8ms\n",
      "Speed: 2.3ms preprocess, 89.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_710.jpg\n",
      "Saved labels to: results6\\labels\\VIT_710.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_711.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_711.jpg: 640x480 21 handwrittens, 123.9ms\n",
      "Speed: 10.2ms preprocess, 123.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_711.jpg\n",
      "Saved labels to: results6\\labels\\VIT_711.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_712.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_712.jpg: 640x480 26 handwrittens, 139.3ms\n",
      "Speed: 2.6ms preprocess, 139.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_712.jpg\n",
      "Saved labels to: results6\\labels\\VIT_712.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_713.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_713.jpg: 640x480 23 handwrittens, 161.6ms\n",
      "Speed: 3.5ms preprocess, 161.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_713.jpg\n",
      "Saved labels to: results6\\labels\\VIT_713.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_714.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_714.jpg: 640x480 22 handwrittens, 99.0ms\n",
      "Speed: 3.0ms preprocess, 99.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_714.jpg\n",
      "Saved labels to: results6\\labels\\VIT_714.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_715.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_715.jpg: 640x480 24 handwrittens, 146.0ms\n",
      "Speed: 2.7ms preprocess, 146.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_715.jpg\n",
      "Saved labels to: results6\\labels\\VIT_715.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_716.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_716.jpg: 640x480 24 handwrittens, 95.8ms\n",
      "Speed: 2.7ms preprocess, 95.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_716.jpg\n",
      "Saved labels to: results6\\labels\\VIT_716.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_717.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_717.jpg: 640x480 22 handwrittens, 105.0ms\n",
      "Speed: 3.2ms preprocess, 105.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_717.jpg\n",
      "Saved labels to: results6\\labels\\VIT_717.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_718.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_718.jpg: 640x480 26 handwrittens, 96.3ms\n",
      "Speed: 3.1ms preprocess, 96.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_718.jpg\n",
      "Saved labels to: results6\\labels\\VIT_718.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_719.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_719.jpg: 640x480 20 handwrittens, 128.9ms\n",
      "Speed: 2.0ms preprocess, 128.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_719.jpg\n",
      "Saved labels to: results6\\labels\\VIT_719.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_720.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_720.jpg: 640x480 26 handwrittens, 95.2ms\n",
      "Speed: 2.4ms preprocess, 95.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_720.jpg\n",
      "Saved labels to: results6\\labels\\VIT_720.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_721.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_721.jpg: 640x480 22 handwrittens, 98.2ms\n",
      "Speed: 3.0ms preprocess, 98.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_721.jpg\n",
      "Saved labels to: results6\\labels\\VIT_721.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_722.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_722.jpg: 640x480 24 handwrittens, 118.3ms\n",
      "Speed: 2.7ms preprocess, 118.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_722.jpg\n",
      "Saved labels to: results6\\labels\\VIT_722.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_723.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_723.jpg: 640x480 22 handwrittens, 127.8ms\n",
      "Speed: 9.2ms preprocess, 127.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_723.jpg\n",
      "Saved labels to: results6\\labels\\VIT_723.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_724.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_724.jpg: 640x480 27 handwrittens, 98.7ms\n",
      "Speed: 2.4ms preprocess, 98.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_724.jpg\n",
      "Saved labels to: results6\\labels\\VIT_724.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_725.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_725.jpg: 640x480 28 handwrittens, 93.8ms\n",
      "Speed: 2.7ms preprocess, 93.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_725.jpg\n",
      "Saved labels to: results6\\labels\\VIT_725.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_726.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_726.jpg: 640x480 24 handwrittens, 89.2ms\n",
      "Speed: 2.0ms preprocess, 89.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_726.jpg\n",
      "Saved labels to: results6\\labels\\VIT_726.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_727.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_727.jpg: 640x480 25 handwrittens, 133.1ms\n",
      "Speed: 4.9ms preprocess, 133.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_727.jpg\n",
      "Saved labels to: results6\\labels\\VIT_727.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_728.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_728.jpg: 640x480 25 handwrittens, 87.3ms\n",
      "Speed: 2.1ms preprocess, 87.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_728.jpg\n",
      "Saved labels to: results6\\labels\\VIT_728.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_729.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_729.jpg: 640x480 28 handwrittens, 89.3ms\n",
      "Speed: 2.8ms preprocess, 89.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_729.jpg\n",
      "Saved labels to: results6\\labels\\VIT_729.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_730.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_730.jpg: 640x480 24 handwrittens, 116.5ms\n",
      "Speed: 3.5ms preprocess, 116.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_730.jpg\n",
      "Saved labels to: results6\\labels\\VIT_730.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_731.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_731.jpg: 640x480 27 handwrittens, 209.4ms\n",
      "Speed: 5.6ms preprocess, 209.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_731.jpg\n",
      "Saved labels to: results6\\labels\\VIT_731.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_732.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_732.jpg: 640x480 27 handwrittens, 140.4ms\n",
      "Speed: 4.9ms preprocess, 140.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_732.jpg\n",
      "Saved labels to: results6\\labels\\VIT_732.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_733.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_733.jpg: 640x480 24 handwrittens, 122.1ms\n",
      "Speed: 3.1ms preprocess, 122.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_733.jpg\n",
      "Saved labels to: results6\\labels\\VIT_733.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_734.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_734.jpg: 640x480 25 handwrittens, 108.1ms\n",
      "Speed: 2.8ms preprocess, 108.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_734.jpg\n",
      "Saved labels to: results6\\labels\\VIT_734.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_735.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_735.jpg: 640x480 21 handwrittens, 150.1ms\n",
      "Speed: 2.0ms preprocess, 150.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_735.jpg\n",
      "Saved labels to: results6\\labels\\VIT_735.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_736.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_736.jpg: 640x480 29 handwrittens, 96.3ms\n",
      "Speed: 2.6ms preprocess, 96.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_736.jpg\n",
      "Saved labels to: results6\\labels\\VIT_736.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_737.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_737.jpg: 640x480 25 handwrittens, 98.7ms\n",
      "Speed: 2.1ms preprocess, 98.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_737.jpg\n",
      "Saved labels to: results6\\labels\\VIT_737.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_738.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_738.jpg: 640x480 23 handwrittens, 87.7ms\n",
      "Speed: 2.6ms preprocess, 87.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_738.jpg\n",
      "Saved labels to: results6\\labels\\VIT_738.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_739.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_739.jpg: 640x480 22 handwrittens, 112.6ms\n",
      "Speed: 3.0ms preprocess, 112.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_739.jpg\n",
      "Saved labels to: results6\\labels\\VIT_739.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_740.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_740.jpg: 640x480 28 handwrittens, 95.5ms\n",
      "Speed: 3.1ms preprocess, 95.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_740.jpg\n",
      "Saved labels to: results6\\labels\\VIT_740.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_741.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_741.jpg: 640x480 28 handwrittens, 102.6ms\n",
      "Speed: 1.9ms preprocess, 102.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_741.jpg\n",
      "Saved labels to: results6\\labels\\VIT_741.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_742.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_742.jpg: 640x480 22 handwrittens, 112.1ms\n",
      "Speed: 2.7ms preprocess, 112.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_742.jpg\n",
      "Saved labels to: results6\\labels\\VIT_742.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_743.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_743.jpg: 640x480 25 handwrittens, 119.5ms\n",
      "Speed: 2.9ms preprocess, 119.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_743.jpg\n",
      "Saved labels to: results6\\labels\\VIT_743.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_744.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_744.jpg: 640x480 22 handwrittens, 110.9ms\n",
      "Speed: 2.3ms preprocess, 110.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_744.jpg\n",
      "Saved labels to: results6\\labels\\VIT_744.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_745.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_745.jpg: 640x480 24 handwrittens, 86.7ms\n",
      "Speed: 3.0ms preprocess, 86.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_745.jpg\n",
      "Saved labels to: results6\\labels\\VIT_745.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_746.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_746.jpg: 640x480 24 handwrittens, 90.7ms\n",
      "Speed: 2.9ms preprocess, 90.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_746.jpg\n",
      "Saved labels to: results6\\labels\\VIT_746.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_747.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_747.jpg: 640x480 21 handwrittens, 111.3ms\n",
      "Speed: 3.1ms preprocess, 111.3ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_747.jpg\n",
      "Saved labels to: results6\\labels\\VIT_747.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_748.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_748.jpg: 640x480 23 handwrittens, 98.3ms\n",
      "Speed: 3.2ms preprocess, 98.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_748.jpg\n",
      "Saved labels to: results6\\labels\\VIT_748.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_749.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_749.jpg: 640x480 21 handwrittens, 133.6ms\n",
      "Speed: 3.7ms preprocess, 133.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_749.jpg\n",
      "Saved labels to: results6\\labels\\VIT_749.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_750.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_750.jpg: 640x480 22 handwrittens, 152.9ms\n",
      "Speed: 3.1ms preprocess, 152.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_750.jpg\n",
      "Saved labels to: results6\\labels\\VIT_750.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_751.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_751.jpg: 640x480 29 handwrittens, 198.4ms\n",
      "Speed: 5.1ms preprocess, 198.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_751.jpg\n",
      "Saved labels to: results6\\labels\\VIT_751.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_752.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_752.jpg: 640x480 24 handwrittens, 129.7ms\n",
      "Speed: 3.3ms preprocess, 129.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_752.jpg\n",
      "Saved labels to: results6\\labels\\VIT_752.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_753.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_753.jpg: 640x480 24 handwrittens, 142.6ms\n",
      "Speed: 3.4ms preprocess, 142.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_753.jpg\n",
      "Saved labels to: results6\\labels\\VIT_753.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_754.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_754.jpg: 640x480 21 handwrittens, 104.8ms\n",
      "Speed: 2.2ms preprocess, 104.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_754.jpg\n",
      "Saved labels to: results6\\labels\\VIT_754.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_755.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_755.jpg: 640x480 23 handwrittens, 97.0ms\n",
      "Speed: 2.3ms preprocess, 97.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_755.jpg\n",
      "Saved labels to: results6\\labels\\VIT_755.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_756.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_756.jpg: 640x480 24 handwrittens, 104.6ms\n",
      "Speed: 8.4ms preprocess, 104.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_756.jpg\n",
      "Saved labels to: results6\\labels\\VIT_756.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_757.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_757.jpg: 640x480 22 handwrittens, 103.2ms\n",
      "Speed: 2.6ms preprocess, 103.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_757.jpg\n",
      "Saved labels to: results6\\labels\\VIT_757.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_758.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_758.jpg: 640x480 24 handwrittens, 96.6ms\n",
      "Speed: 3.2ms preprocess, 96.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_758.jpg\n",
      "Saved labels to: results6\\labels\\VIT_758.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_759.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_759.jpg: 640x480 26 handwrittens, 99.6ms\n",
      "Speed: 1.9ms preprocess, 99.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_759.jpg\n",
      "Saved labels to: results6\\labels\\VIT_759.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_760.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_760.jpg: 640x480 25 handwrittens, 129.5ms\n",
      "Speed: 5.8ms preprocess, 129.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_760.jpg\n",
      "Saved labels to: results6\\labels\\VIT_760.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_761.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_761.jpg: 640x480 23 handwrittens, 119.8ms\n",
      "Speed: 3.2ms preprocess, 119.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_761.jpg\n",
      "Saved labels to: results6\\labels\\VIT_761.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_762.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_762.jpg: 640x480 21 handwrittens, 112.1ms\n",
      "Speed: 3.4ms preprocess, 112.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_762.jpg\n",
      "Saved labels to: results6\\labels\\VIT_762.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_763.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_763.jpg: 640x480 23 handwrittens, 112.6ms\n",
      "Speed: 3.4ms preprocess, 112.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_763.jpg\n",
      "Saved labels to: results6\\labels\\VIT_763.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_764.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_764.jpg: 640x480 21 handwrittens, 148.8ms\n",
      "Speed: 4.6ms preprocess, 148.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_764.jpg\n",
      "Saved labels to: results6\\labels\\VIT_764.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_765.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_765.jpg: 640x480 23 handwrittens, 100.2ms\n",
      "Speed: 2.3ms preprocess, 100.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_765.jpg\n",
      "Saved labels to: results6\\labels\\VIT_765.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_766.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_766.jpg: 640x480 20 handwrittens, 102.4ms\n",
      "Speed: 3.2ms preprocess, 102.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_766.jpg\n",
      "Saved labels to: results6\\labels\\VIT_766.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_767.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_767.jpg: 640x480 21 handwrittens, 109.8ms\n",
      "Speed: 3.0ms preprocess, 109.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_767.jpg\n",
      "Saved labels to: results6\\labels\\VIT_767.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_768.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_768.jpg: 640x480 21 handwrittens, 279.8ms\n",
      "Speed: 2.9ms preprocess, 279.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_768.jpg\n",
      "Saved labels to: results6\\labels\\VIT_768.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_769.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_769.jpg: 640x480 20 handwrittens, 137.1ms\n",
      "Speed: 3.1ms preprocess, 137.1ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_769.jpg\n",
      "Saved labels to: results6\\labels\\VIT_769.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_770.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_770.jpg: 640x480 21 handwrittens, 167.8ms\n",
      "Speed: 2.9ms preprocess, 167.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_770.jpg\n",
      "Saved labels to: results6\\labels\\VIT_770.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_771.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_771.jpg: 640x480 21 handwrittens, 129.7ms\n",
      "Speed: 8.5ms preprocess, 129.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_771.jpg\n",
      "Saved labels to: results6\\labels\\VIT_771.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_772.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_772.jpg: 640x480 23 handwrittens, 133.3ms\n",
      "Speed: 11.2ms preprocess, 133.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_772.jpg\n",
      "Saved labels to: results6\\labels\\VIT_772.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_773.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_773.jpg: 640x480 24 handwrittens, 108.2ms\n",
      "Speed: 3.9ms preprocess, 108.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_773.jpg\n",
      "Saved labels to: results6\\labels\\VIT_773.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_774.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_774.jpg: 640x480 21 handwrittens, 132.7ms\n",
      "Speed: 3.3ms preprocess, 132.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_774.jpg\n",
      "Saved labels to: results6\\labels\\VIT_774.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_775.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_775.jpg: 640x480 21 handwrittens, 193.3ms\n",
      "Speed: 5.7ms preprocess, 193.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_775.jpg\n",
      "Saved labels to: results6\\labels\\VIT_775.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_776.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_776.jpg: 640x480 22 handwrittens, 158.4ms\n",
      "Speed: 9.4ms preprocess, 158.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_776.jpg\n",
      "Saved labels to: results6\\labels\\VIT_776.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_777.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_777.jpg: 640x480 21 handwrittens, 141.2ms\n",
      "Speed: 4.5ms preprocess, 141.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_777.jpg\n",
      "Saved labels to: results6\\labels\\VIT_777.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_778.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_778.jpg: 640x480 23 handwrittens, 118.5ms\n",
      "Speed: 3.7ms preprocess, 118.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_778.jpg\n",
      "Saved labels to: results6\\labels\\VIT_778.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_779.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_779.jpg: 640x480 22 handwrittens, 133.8ms\n",
      "Speed: 4.3ms preprocess, 133.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_779.jpg\n",
      "Saved labels to: results6\\labels\\VIT_779.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_780.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_780.jpg: 640x480 23 handwrittens, 161.2ms\n",
      "Speed: 3.2ms preprocess, 161.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_780.jpg\n",
      "Saved labels to: results6\\labels\\VIT_780.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_781.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_781.jpg: 640x480 22 handwrittens, 103.2ms\n",
      "Speed: 3.8ms preprocess, 103.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_781.jpg\n",
      "Saved labels to: results6\\labels\\VIT_781.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_782.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_782.jpg: 640x480 22 handwrittens, 129.9ms\n",
      "Speed: 3.2ms preprocess, 129.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_782.jpg\n",
      "Saved labels to: results6\\labels\\VIT_782.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_783.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_783.jpg: 640x480 22 handwrittens, 113.8ms\n",
      "Speed: 3.8ms preprocess, 113.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_783.jpg\n",
      "Saved labels to: results6\\labels\\VIT_783.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_784.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_784.jpg: 640x480 22 handwrittens, 139.5ms\n",
      "Speed: 7.6ms preprocess, 139.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_784.jpg\n",
      "Saved labels to: results6\\labels\\VIT_784.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_785.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_785.jpg: 640x480 23 handwrittens, 137.0ms\n",
      "Speed: 3.7ms preprocess, 137.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_785.jpg\n",
      "Saved labels to: results6\\labels\\VIT_785.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_786.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_786.jpg: 640x480 22 handwrittens, 130.0ms\n",
      "Speed: 3.0ms preprocess, 130.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_786.jpg\n",
      "Saved labels to: results6\\labels\\VIT_786.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_787.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_787.jpg: 640x480 22 handwrittens, 112.6ms\n",
      "Speed: 3.7ms preprocess, 112.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_787.jpg\n",
      "Saved labels to: results6\\labels\\VIT_787.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_788.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_788.jpg: 640x480 22 handwrittens, 135.7ms\n",
      "Speed: 7.1ms preprocess, 135.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_788.jpg\n",
      "Saved labels to: results6\\labels\\VIT_788.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_789.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_789.jpg: 640x480 22 handwrittens, 119.1ms\n",
      "Speed: 3.0ms preprocess, 119.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_789.jpg\n",
      "Saved labels to: results6\\labels\\VIT_789.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_790.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_790.jpg: 640x480 23 handwrittens, 188.8ms\n",
      "Speed: 4.9ms preprocess, 188.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_790.jpg\n",
      "Saved labels to: results6\\labels\\VIT_790.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_791.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_791.jpg: 640x480 23 handwrittens, 178.0ms\n",
      "Speed: 3.6ms preprocess, 178.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_791.jpg\n",
      "Saved labels to: results6\\labels\\VIT_791.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_792.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_792.jpg: 640x480 25 handwrittens, 128.3ms\n",
      "Speed: 3.1ms preprocess, 128.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_792.jpg\n",
      "Saved labels to: results6\\labels\\VIT_792.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_793.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_793.jpg: 640x480 23 handwrittens, 194.7ms\n",
      "Speed: 3.2ms preprocess, 194.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_793.jpg\n",
      "Saved labels to: results6\\labels\\VIT_793.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_794.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_794.jpg: 640x480 21 handwrittens, 149.8ms\n",
      "Speed: 3.9ms preprocess, 149.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_794.jpg\n",
      "Saved labels to: results6\\labels\\VIT_794.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_795.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_795.jpg: 640x480 22 handwrittens, 278.2ms\n",
      "Speed: 4.4ms preprocess, 278.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_795.jpg\n",
      "Saved labels to: results6\\labels\\VIT_795.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_796.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_796.jpg: 640x480 22 handwrittens, 136.3ms\n",
      "Speed: 3.3ms preprocess, 136.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_796.jpg\n",
      "Saved labels to: results6\\labels\\VIT_796.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_797.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_797.jpg: 640x480 25 handwrittens, 166.4ms\n",
      "Speed: 3.1ms preprocess, 166.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_797.jpg\n",
      "Saved labels to: results6\\labels\\VIT_797.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_798.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_798.jpg: 640x480 25 handwrittens, 154.0ms\n",
      "Speed: 11.0ms preprocess, 154.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_798.jpg\n",
      "Saved labels to: results6\\labels\\VIT_798.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_799.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_799.jpg: 640x480 22 handwrittens, 111.2ms\n",
      "Speed: 3.4ms preprocess, 111.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_799.jpg\n",
      "Saved labels to: results6\\labels\\VIT_799.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_800.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_800.jpg: 640x480 22 handwrittens, 131.2ms\n",
      "Speed: 2.6ms preprocess, 131.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_800.jpg\n",
      "Saved labels to: results6\\labels\\VIT_800.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_801.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_801.jpg: 640x480 25 handwrittens, 188.3ms\n",
      "Speed: 39.0ms preprocess, 188.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_801.jpg\n",
      "Saved labels to: results6\\labels\\VIT_801.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_802.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_802.jpg: 640x480 22 handwrittens, 179.6ms\n",
      "Speed: 3.2ms preprocess, 179.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_802.jpg\n",
      "Saved labels to: results6\\labels\\VIT_802.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_803.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_803.jpg: 640x480 24 handwrittens, 135.0ms\n",
      "Speed: 2.9ms preprocess, 135.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_803.jpg\n",
      "Saved labels to: results6\\labels\\VIT_803.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_804.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_804.jpg: 640x480 23 handwrittens, 228.3ms\n",
      "Speed: 4.6ms preprocess, 228.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_804.jpg\n",
      "Saved labels to: results6\\labels\\VIT_804.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_805.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_805.jpg: 640x480 23 handwrittens, 135.1ms\n",
      "Speed: 3.7ms preprocess, 135.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_805.jpg\n",
      "Saved labels to: results6\\labels\\VIT_805.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_806.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_806.jpg: 640x480 25 handwrittens, 142.6ms\n",
      "Speed: 3.6ms preprocess, 142.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_806.jpg\n",
      "Saved labels to: results6\\labels\\VIT_806.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_807.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_807.jpg: 640x480 22 handwrittens, 119.7ms\n",
      "Speed: 2.6ms preprocess, 119.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_807.jpg\n",
      "Saved labels to: results6\\labels\\VIT_807.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_808.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_808.jpg: 640x480 24 handwrittens, 104.9ms\n",
      "Speed: 2.9ms preprocess, 104.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_808.jpg\n",
      "Saved labels to: results6\\labels\\VIT_808.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_809.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_809.jpg: 640x480 24 handwrittens, 161.7ms\n",
      "Speed: 3.6ms preprocess, 161.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_809.jpg\n",
      "Saved labels to: results6\\labels\\VIT_809.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_810.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_810.jpg: 640x480 27 handwrittens, 145.7ms\n",
      "Speed: 3.5ms preprocess, 145.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_810.jpg\n",
      "Saved labels to: results6\\labels\\VIT_810.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_811.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_811.jpg: 640x480 25 handwrittens, 233.9ms\n",
      "Speed: 3.6ms preprocess, 233.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_811.jpg\n",
      "Saved labels to: results6\\labels\\VIT_811.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_812.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_812.jpg: 640x480 22 handwrittens, 190.6ms\n",
      "Speed: 3.5ms preprocess, 190.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_812.jpg\n",
      "Saved labels to: results6\\labels\\VIT_812.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_813.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_813.jpg: 640x480 22 handwrittens, 135.6ms\n",
      "Speed: 4.1ms preprocess, 135.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_813.jpg\n",
      "Saved labels to: results6\\labels\\VIT_813.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_814.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_814.jpg: 640x480 24 handwrittens, 99.0ms\n",
      "Speed: 3.0ms preprocess, 99.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_814.jpg\n",
      "Saved labels to: results6\\labels\\VIT_814.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_815.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_815.jpg: 640x480 24 handwrittens, 102.6ms\n",
      "Speed: 3.7ms preprocess, 102.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_815.jpg\n",
      "Saved labels to: results6\\labels\\VIT_815.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_816.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_816.jpg: 640x480 25 handwrittens, 140.4ms\n",
      "Speed: 2.6ms preprocess, 140.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_816.jpg\n",
      "Saved labels to: results6\\labels\\VIT_816.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_817.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_817.jpg: 640x480 23 handwrittens, 188.9ms\n",
      "Speed: 3.6ms preprocess, 188.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_817.jpg\n",
      "Saved labels to: results6\\labels\\VIT_817.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_818.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_818.jpg: 640x480 23 handwrittens, 124.4ms\n",
      "Speed: 3.3ms preprocess, 124.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_818.jpg\n",
      "Saved labels to: results6\\labels\\VIT_818.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_819.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_819.jpg: 640x480 23 handwrittens, 126.1ms\n",
      "Speed: 3.9ms preprocess, 126.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_819.jpg\n",
      "Saved labels to: results6\\labels\\VIT_819.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_820.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_820.jpg: 640x480 23 handwrittens, 145.2ms\n",
      "Speed: 8.7ms preprocess, 145.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_820.jpg\n",
      "Saved labels to: results6\\labels\\VIT_820.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_821.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_821.jpg: 640x480 26 handwrittens, 103.1ms\n",
      "Speed: 2.3ms preprocess, 103.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_821.jpg\n",
      "Saved labels to: results6\\labels\\VIT_821.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_822.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_822.jpg: 640x480 27 handwrittens, 96.6ms\n",
      "Speed: 2.9ms preprocess, 96.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_822.jpg\n",
      "Saved labels to: results6\\labels\\VIT_822.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_823.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_823.jpg: 640x480 25 handwrittens, 101.4ms\n",
      "Speed: 2.6ms preprocess, 101.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_823.jpg\n",
      "Saved labels to: results6\\labels\\VIT_823.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_824.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_824.jpg: 640x480 26 handwrittens, 107.3ms\n",
      "Speed: 2.9ms preprocess, 107.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_824.jpg\n",
      "Saved labels to: results6\\labels\\VIT_824.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_825.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_825.jpg: 640x480 21 handwrittens, 111.5ms\n",
      "Speed: 3.7ms preprocess, 111.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_825.jpg\n",
      "Saved labels to: results6\\labels\\VIT_825.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_826.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_826.jpg: 640x480 28 handwrittens, 110.7ms\n",
      "Speed: 3.0ms preprocess, 110.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_826.jpg\n",
      "Saved labels to: results6\\labels\\VIT_826.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_827.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_827.jpg: 640x480 25 handwrittens, 162.0ms\n",
      "Speed: 3.2ms preprocess, 162.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_827.jpg\n",
      "Saved labels to: results6\\labels\\VIT_827.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_828.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_828.jpg: 640x480 21 handwrittens, 106.6ms\n",
      "Speed: 3.5ms preprocess, 106.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_828.jpg\n",
      "Saved labels to: results6\\labels\\VIT_828.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_829.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_829.jpg: 640x480 26 handwrittens, 103.7ms\n",
      "Speed: 7.0ms preprocess, 103.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_829.jpg\n",
      "Saved labels to: results6\\labels\\VIT_829.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_830.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_830.jpg: 640x480 22 handwrittens, 102.9ms\n",
      "Speed: 3.4ms preprocess, 102.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_830.jpg\n",
      "Saved labels to: results6\\labels\\VIT_830.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_831.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_831.jpg: 640x480 24 handwrittens, 96.4ms\n",
      "Speed: 3.0ms preprocess, 96.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_831.jpg\n",
      "Saved labels to: results6\\labels\\VIT_831.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_832.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_832.jpg: 640x480 22 handwrittens, 99.7ms\n",
      "Speed: 1.9ms preprocess, 99.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_832.jpg\n",
      "Saved labels to: results6\\labels\\VIT_832.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_833.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_833.jpg: 640x480 23 handwrittens, 152.7ms\n",
      "Speed: 2.6ms preprocess, 152.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_833.jpg\n",
      "Saved labels to: results6\\labels\\VIT_833.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_834.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_834.jpg: 640x480 20 handwrittens, 122.4ms\n",
      "Speed: 3.3ms preprocess, 122.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_834.jpg\n",
      "Saved labels to: results6\\labels\\VIT_834.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_835.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_835.jpg: 640x480 22 handwrittens, 106.7ms\n",
      "Speed: 3.1ms preprocess, 106.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_835.jpg\n",
      "Saved labels to: results6\\labels\\VIT_835.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_836.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_836.jpg: 640x480 23 handwrittens, 193.5ms\n",
      "Speed: 4.0ms preprocess, 193.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_836.jpg\n",
      "Saved labels to: results6\\labels\\VIT_836.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_837.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_837.jpg: 640x480 22 handwrittens, 188.6ms\n",
      "Speed: 28.9ms preprocess, 188.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_837.jpg\n",
      "Saved labels to: results6\\labels\\VIT_837.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_838.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_838.jpg: 640x480 21 handwrittens, 130.2ms\n",
      "Speed: 3.5ms preprocess, 130.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_838.jpg\n",
      "Saved labels to: results6\\labels\\VIT_838.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_839.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_839.jpg: 640x480 22 handwrittens, 116.4ms\n",
      "Speed: 2.5ms preprocess, 116.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_839.jpg\n",
      "Saved labels to: results6\\labels\\VIT_839.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_840.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_840.jpg: 640x480 22 handwrittens, 112.5ms\n",
      "Speed: 4.2ms preprocess, 112.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_840.jpg\n",
      "Saved labels to: results6\\labels\\VIT_840.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_841.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_841.jpg: 640x480 24 handwrittens, 111.2ms\n",
      "Speed: 4.7ms preprocess, 111.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_841.jpg\n",
      "Saved labels to: results6\\labels\\VIT_841.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_842.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_842.jpg: 640x480 21 handwrittens, 112.2ms\n",
      "Speed: 3.4ms preprocess, 112.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_842.jpg\n",
      "Saved labels to: results6\\labels\\VIT_842.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_843.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_843.jpg: 640x480 21 handwrittens, 125.4ms\n",
      "Speed: 2.9ms preprocess, 125.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_843.jpg\n",
      "Saved labels to: results6\\labels\\VIT_843.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_844.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_844.jpg: 640x480 21 handwrittens, 175.9ms\n",
      "Speed: 7.5ms preprocess, 175.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_844.jpg\n",
      "Saved labels to: results6\\labels\\VIT_844.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_845.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_845.jpg: 640x480 20 handwrittens, 167.5ms\n",
      "Speed: 3.4ms preprocess, 167.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_845.jpg\n",
      "Saved labels to: results6\\labels\\VIT_845.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_846.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_846.jpg: 640x480 21 handwrittens, 117.1ms\n",
      "Speed: 6.5ms preprocess, 117.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_846.jpg\n",
      "Saved labels to: results6\\labels\\VIT_846.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_847.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_847.jpg: 640x480 29 handwrittens, 121.1ms\n",
      "Speed: 3.8ms preprocess, 121.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_847.jpg\n",
      "Saved labels to: results6\\labels\\VIT_847.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_848.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_848.jpg: 640x480 23 handwrittens, 115.4ms\n",
      "Speed: 3.8ms preprocess, 115.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_848.jpg\n",
      "Saved labels to: results6\\labels\\VIT_848.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_849.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_849.jpg: 640x480 20 handwrittens, 108.8ms\n",
      "Speed: 3.3ms preprocess, 108.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_849.jpg\n",
      "Saved labels to: results6\\labels\\VIT_849.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_850.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_850.jpg: 640x480 21 handwrittens, 105.0ms\n",
      "Speed: 3.8ms preprocess, 105.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_850.jpg\n",
      "Saved labels to: results6\\labels\\VIT_850.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_851.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_851.jpg: 640x480 22 handwrittens, 153.9ms\n",
      "Speed: 3.9ms preprocess, 153.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_851.jpg\n",
      "Saved labels to: results6\\labels\\VIT_851.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_852.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_852.jpg: 640x480 21 handwrittens, 124.4ms\n",
      "Speed: 5.2ms preprocess, 124.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_852.jpg\n",
      "Saved labels to: results6\\labels\\VIT_852.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_853.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_853.jpg: 640x480 24 handwrittens, 130.2ms\n",
      "Speed: 6.4ms preprocess, 130.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_853.jpg\n",
      "Saved labels to: results6\\labels\\VIT_853.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_854.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_854.jpg: 640x480 26 handwrittens, 150.0ms\n",
      "Speed: 3.7ms preprocess, 150.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_854.jpg\n",
      "Saved labels to: results6\\labels\\VIT_854.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_855.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_855.jpg: 640x480 24 handwrittens, 116.8ms\n",
      "Speed: 3.3ms preprocess, 116.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_855.jpg\n",
      "Saved labels to: results6\\labels\\VIT_855.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_856.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_856.jpg: 640x480 22 handwrittens, 107.5ms\n",
      "Speed: 2.8ms preprocess, 107.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_856.jpg\n",
      "Saved labels to: results6\\labels\\VIT_856.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_857.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_857.jpg: 640x480 21 handwrittens, 93.8ms\n",
      "Speed: 2.3ms preprocess, 93.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_857.jpg\n",
      "Saved labels to: results6\\labels\\VIT_857.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_858.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_858.jpg: 640x480 22 handwrittens, 102.1ms\n",
      "Speed: 3.2ms preprocess, 102.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_858.jpg\n",
      "Saved labels to: results6\\labels\\VIT_858.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_859.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_859.jpg: 640x480 24 handwrittens, 152.5ms\n",
      "Speed: 2.7ms preprocess, 152.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_859.jpg\n",
      "Saved labels to: results6\\labels\\VIT_859.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_860.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_860.jpg: 640x480 27 handwrittens, 131.2ms\n",
      "Speed: 15.0ms preprocess, 131.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_860.jpg\n",
      "Saved labels to: results6\\labels\\VIT_860.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_861.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_861.jpg: 640x480 27 handwrittens, 111.8ms\n",
      "Speed: 4.2ms preprocess, 111.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_861.jpg\n",
      "Saved labels to: results6\\labels\\VIT_861.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_862.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_862.jpg: 640x480 23 handwrittens, 145.8ms\n",
      "Speed: 6.1ms preprocess, 145.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_862.jpg\n",
      "Saved labels to: results6\\labels\\VIT_862.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_863.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_863.jpg: 640x480 22 handwrittens, 142.9ms\n",
      "Speed: 3.6ms preprocess, 142.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_863.jpg\n",
      "Saved labels to: results6\\labels\\VIT_863.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_864.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_864.jpg: 640x480 22 handwrittens, 114.1ms\n",
      "Speed: 3.8ms preprocess, 114.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_864.jpg\n",
      "Saved labels to: results6\\labels\\VIT_864.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_865.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_865.jpg: 640x480 26 handwrittens, 114.1ms\n",
      "Speed: 3.0ms preprocess, 114.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_865.jpg\n",
      "Saved labels to: results6\\labels\\VIT_865.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_866.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_866.jpg: 640x480 24 handwrittens, 123.1ms\n",
      "Speed: 4.4ms preprocess, 123.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_866.jpg\n",
      "Saved labels to: results6\\labels\\VIT_866.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_867.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_867.jpg: 640x480 20 handwrittens, 151.5ms\n",
      "Speed: 4.2ms preprocess, 151.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_867.jpg\n",
      "Saved labels to: results6\\labels\\VIT_867.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_868.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_868.jpg: 640x480 23 handwrittens, 104.3ms\n",
      "Speed: 4.2ms preprocess, 104.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_868.jpg\n",
      "Saved labels to: results6\\labels\\VIT_868.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_869.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_869.jpg: 640x480 22 handwrittens, 105.1ms\n",
      "Speed: 3.0ms preprocess, 105.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_869.jpg\n",
      "Saved labels to: results6\\labels\\VIT_869.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_870.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_870.jpg: 640x480 25 handwrittens, 103.8ms\n",
      "Speed: 2.6ms preprocess, 103.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_870.jpg\n",
      "Saved labels to: results6\\labels\\VIT_870.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_871.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_871.jpg: 640x480 25 handwrittens, 117.9ms\n",
      "Speed: 3.3ms preprocess, 117.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_871.jpg\n",
      "Saved labels to: results6\\labels\\VIT_871.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_872.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_872.jpg: 640x480 23 handwrittens, 118.2ms\n",
      "Speed: 4.1ms preprocess, 118.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_872.jpg\n",
      "Saved labels to: results6\\labels\\VIT_872.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_873.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_873.jpg: 640x480 23 handwrittens, 93.3ms\n",
      "Speed: 3.0ms preprocess, 93.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_873.jpg\n",
      "Saved labels to: results6\\labels\\VIT_873.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_874.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_874.jpg: 640x480 25 handwrittens, 111.7ms\n",
      "Speed: 4.2ms preprocess, 111.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_874.jpg\n",
      "Saved labels to: results6\\labels\\VIT_874.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_875.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_875.jpg: 640x480 21 handwrittens, 138.4ms\n",
      "Speed: 3.4ms preprocess, 138.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_875.jpg\n",
      "Saved labels to: results6\\labels\\VIT_875.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_876.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_876.jpg: 640x480 24 handwrittens, 124.1ms\n",
      "Speed: 6.6ms preprocess, 124.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_876.jpg\n",
      "Saved labels to: results6\\labels\\VIT_876.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_877.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_877.jpg: 640x480 22 handwrittens, 155.6ms\n",
      "Speed: 7.8ms preprocess, 155.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_877.jpg\n",
      "Saved labels to: results6\\labels\\VIT_877.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_878.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_878.jpg: 640x480 22 handwrittens, 108.6ms\n",
      "Speed: 3.2ms preprocess, 108.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_878.jpg\n",
      "Saved labels to: results6\\labels\\VIT_878.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_879.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_879.jpg: 640x480 21 handwrittens, 107.9ms\n",
      "Speed: 3.7ms preprocess, 107.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_879.jpg\n",
      "Saved labels to: results6\\labels\\VIT_879.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_880.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_880.jpg: 640x480 22 handwrittens, 119.3ms\n",
      "Speed: 3.6ms preprocess, 119.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_880.jpg\n",
      "Saved labels to: results6\\labels\\VIT_880.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_881.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_881.jpg: 640x480 21 handwrittens, 134.6ms\n",
      "Speed: 6.7ms preprocess, 134.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_881.jpg\n",
      "Saved labels to: results6\\labels\\VIT_881.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_882.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_882.jpg: 640x480 25 handwrittens, 143.3ms\n",
      "Speed: 7.8ms preprocess, 143.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_882.jpg\n",
      "Saved labels to: results6\\labels\\VIT_882.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_883.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_883.jpg: 640x480 26 handwrittens, 111.0ms\n",
      "Speed: 3.1ms preprocess, 111.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_883.jpg\n",
      "Saved labels to: results6\\labels\\VIT_883.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_884.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_884.jpg: 640x480 21 handwrittens, 124.4ms\n",
      "Speed: 7.8ms preprocess, 124.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_884.jpg\n",
      "Saved labels to: results6\\labels\\VIT_884.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_885.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_885.jpg: 640x480 24 handwrittens, 113.7ms\n",
      "Speed: 3.4ms preprocess, 113.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_885.jpg\n",
      "Saved labels to: results6\\labels\\VIT_885.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_886.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_886.jpg: 640x480 22 handwrittens, 133.2ms\n",
      "Speed: 10.0ms preprocess, 133.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_886.jpg\n",
      "Saved labels to: results6\\labels\\VIT_886.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_887.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_887.jpg: 640x480 22 handwrittens, 115.7ms\n",
      "Speed: 3.1ms preprocess, 115.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_887.jpg\n",
      "Saved labels to: results6\\labels\\VIT_887.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_888.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_888.jpg: 640x480 22 handwrittens, 101.2ms\n",
      "Speed: 4.9ms preprocess, 101.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_888.jpg\n",
      "Saved labels to: results6\\labels\\VIT_888.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_889.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_889.jpg: 640x480 22 handwrittens, 121.6ms\n",
      "Speed: 3.3ms preprocess, 121.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_889.jpg\n",
      "Saved labels to: results6\\labels\\VIT_889.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_890.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_890.jpg: 640x480 20 handwrittens, 252.7ms\n",
      "Speed: 4.3ms preprocess, 252.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_890.jpg\n",
      "Saved labels to: results6\\labels\\VIT_890.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_891.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_891.jpg: 640x480 21 handwrittens, 122.8ms\n",
      "Speed: 2.9ms preprocess, 122.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_891.jpg\n",
      "Saved labels to: results6\\labels\\VIT_891.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_892.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_892.jpg: 640x480 22 handwrittens, 115.8ms\n",
      "Speed: 3.3ms preprocess, 115.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_892.jpg\n",
      "Saved labels to: results6\\labels\\VIT_892.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_893.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_893.jpg: 640x480 23 handwrittens, 116.6ms\n",
      "Speed: 3.2ms preprocess, 116.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_893.jpg\n",
      "Saved labels to: results6\\labels\\VIT_893.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_894.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_894.jpg: 640x480 20 handwrittens, 120.0ms\n",
      "Speed: 3.2ms preprocess, 120.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_894.jpg\n",
      "Saved labels to: results6\\labels\\VIT_894.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_895.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_895.jpg: 640x480 22 handwrittens, 116.4ms\n",
      "Speed: 3.5ms preprocess, 116.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_895.jpg\n",
      "Saved labels to: results6\\labels\\VIT_895.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_896.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_896.jpg: 640x480 23 handwrittens, 116.1ms\n",
      "Speed: 3.7ms preprocess, 116.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_896.jpg\n",
      "Saved labels to: results6\\labels\\VIT_896.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_897.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_897.jpg: 640x480 21 handwrittens, 113.3ms\n",
      "Speed: 2.9ms preprocess, 113.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_897.jpg\n",
      "Saved labels to: results6\\labels\\VIT_897.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_898.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_898.jpg: 640x480 23 handwrittens, 154.1ms\n",
      "Speed: 7.3ms preprocess, 154.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_898.jpg\n",
      "Saved labels to: results6\\labels\\VIT_898.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_899.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_899.jpg: 640x480 21 handwrittens, 113.5ms\n",
      "Speed: 2.7ms preprocess, 113.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_899.jpg\n",
      "Saved labels to: results6\\labels\\VIT_899.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_900.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_900.jpg: 640x480 23 handwrittens, 147.5ms\n",
      "Speed: 3.0ms preprocess, 147.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_900.jpg\n",
      "Saved labels to: results6\\labels\\VIT_900.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_901.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_901.jpg: 640x480 23 handwrittens, 127.7ms\n",
      "Speed: 4.2ms preprocess, 127.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_901.jpg\n",
      "Saved labels to: results6\\labels\\VIT_901.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_902.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_902.jpg: 640x480 24 handwrittens, 153.9ms\n",
      "Speed: 7.4ms preprocess, 153.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_902.jpg\n",
      "Saved labels to: results6\\labels\\VIT_902.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_903.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_903.jpg: 640x480 21 handwrittens, 106.1ms\n",
      "Speed: 2.2ms preprocess, 106.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_903.jpg\n",
      "Saved labels to: results6\\labels\\VIT_903.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_904.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_904.jpg: 640x480 20 handwrittens, 103.8ms\n",
      "Speed: 3.1ms preprocess, 103.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_904.jpg\n",
      "Saved labels to: results6\\labels\\VIT_904.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_905.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_905.jpg: 640x480 22 handwrittens, 106.5ms\n",
      "Speed: 3.2ms preprocess, 106.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_905.jpg\n",
      "Saved labels to: results6\\labels\\VIT_905.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_906.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_906.jpg: 640x480 22 handwrittens, 165.6ms\n",
      "Speed: 6.7ms preprocess, 165.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_906.jpg\n",
      "Saved labels to: results6\\labels\\VIT_906.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_907.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_907.jpg: 640x480 22 handwrittens, 162.1ms\n",
      "Speed: 3.9ms preprocess, 162.1ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_907.jpg\n",
      "Saved labels to: results6\\labels\\VIT_907.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_908.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_908.jpg: 640x480 22 handwrittens, 134.8ms\n",
      "Speed: 3.1ms preprocess, 134.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_908.jpg\n",
      "Saved labels to: results6\\labels\\VIT_908.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_909.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_909.jpg: 640x480 19 handwrittens, 116.3ms\n",
      "Speed: 4.1ms preprocess, 116.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_909.jpg\n",
      "Saved labels to: results6\\labels\\VIT_909.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_910.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_910.jpg: 640x480 21 handwrittens, 101.1ms\n",
      "Speed: 2.7ms preprocess, 101.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_910.jpg\n",
      "Saved labels to: results6\\labels\\VIT_910.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_911.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_911.jpg: 640x480 20 handwrittens, 98.1ms\n",
      "Speed: 6.9ms preprocess, 98.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_911.jpg\n",
      "Saved labels to: results6\\labels\\VIT_911.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_912.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_912.jpg: 640x480 23 handwrittens, 96.3ms\n",
      "Speed: 2.9ms preprocess, 96.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_912.jpg\n",
      "Saved labels to: results6\\labels\\VIT_912.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_913.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_913.jpg: 640x480 21 handwrittens, 97.9ms\n",
      "Speed: 4.9ms preprocess, 97.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_913.jpg\n",
      "Saved labels to: results6\\labels\\VIT_913.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_914.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_914.jpg: 640x480 22 handwrittens, 108.5ms\n",
      "Speed: 3.1ms preprocess, 108.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_914.jpg\n",
      "Saved labels to: results6\\labels\\VIT_914.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_915.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_915.jpg: 640x480 20 handwrittens, 96.9ms\n",
      "Speed: 3.0ms preprocess, 96.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_915.jpg\n",
      "Saved labels to: results6\\labels\\VIT_915.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_916.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_916.jpg: 640x480 27 handwrittens, 174.8ms\n",
      "Speed: 3.2ms preprocess, 174.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_916.jpg\n",
      "Saved labels to: results6\\labels\\VIT_916.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_917.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_917.jpg: 640x480 21 handwrittens, 117.8ms\n",
      "Speed: 3.3ms preprocess, 117.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_917.jpg\n",
      "Saved labels to: results6\\labels\\VIT_917.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_918.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_918.jpg: 640x480 24 handwrittens, 144.3ms\n",
      "Speed: 18.6ms preprocess, 144.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_918.jpg\n",
      "Saved labels to: results6\\labels\\VIT_918.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_919.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_919.jpg: 640x480 24 handwrittens, 107.4ms\n",
      "Speed: 2.6ms preprocess, 107.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_919.jpg\n",
      "Saved labels to: results6\\labels\\VIT_919.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_920.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_920.jpg: 640x480 24 handwrittens, 91.0ms\n",
      "Speed: 2.4ms preprocess, 91.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_920.jpg\n",
      "Saved labels to: results6\\labels\\VIT_920.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_921.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_921.jpg: 640x480 29 handwrittens, 108.3ms\n",
      "Speed: 5.1ms preprocess, 108.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_921.jpg\n",
      "Saved labels to: results6\\labels\\VIT_921.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_922.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_922.jpg: 640x480 27 handwrittens, 95.5ms\n",
      "Speed: 3.4ms preprocess, 95.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_922.jpg\n",
      "Saved labels to: results6\\labels\\VIT_922.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_923.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_923.jpg: 640x480 27 handwrittens, 120.4ms\n",
      "Speed: 3.5ms preprocess, 120.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_923.jpg\n",
      "Saved labels to: results6\\labels\\VIT_923.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_924.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_924.jpg: 640x480 26 handwrittens, 101.8ms\n",
      "Speed: 3.0ms preprocess, 101.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_924.jpg\n",
      "Saved labels to: results6\\labels\\VIT_924.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_925.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_925.jpg: 640x480 21 handwrittens, 141.6ms\n",
      "Speed: 6.0ms preprocess, 141.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_925.jpg\n",
      "Saved labels to: results6\\labels\\VIT_925.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_926.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_926.jpg: 640x480 25 handwrittens, 160.7ms\n",
      "Speed: 3.7ms preprocess, 160.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_926.jpg\n",
      "Saved labels to: results6\\labels\\VIT_926.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_927.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_927.jpg: 640x480 20 handwrittens, 154.5ms\n",
      "Speed: 4.1ms preprocess, 154.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_927.jpg\n",
      "Saved labels to: results6\\labels\\VIT_927.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_928.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_928.jpg: 640x480 21 handwrittens, 108.2ms\n",
      "Speed: 2.8ms preprocess, 108.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_928.jpg\n",
      "Saved labels to: results6\\labels\\VIT_928.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_929.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_929.jpg: 640x480 23 handwrittens, 122.4ms\n",
      "Speed: 7.2ms preprocess, 122.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_929.jpg\n",
      "Saved labels to: results6\\labels\\VIT_929.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_930.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_930.jpg: 640x480 22 handwrittens, 144.2ms\n",
      "Speed: 6.1ms preprocess, 144.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_930.jpg\n",
      "Saved labels to: results6\\labels\\VIT_930.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_931.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_931.jpg: 640x480 24 handwrittens, 107.6ms\n",
      "Speed: 3.3ms preprocess, 107.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_931.jpg\n",
      "Saved labels to: results6\\labels\\VIT_931.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_932.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_932.jpg: 640x480 20 handwrittens, 102.4ms\n",
      "Speed: 1.9ms preprocess, 102.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_932.jpg\n",
      "Saved labels to: results6\\labels\\VIT_932.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_933.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_933.jpg: 640x480 23 handwrittens, 145.1ms\n",
      "Speed: 3.6ms preprocess, 145.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_933.jpg\n",
      "Saved labels to: results6\\labels\\VIT_933.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_934.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_934.jpg: 640x480 23 handwrittens, 148.5ms\n",
      "Speed: 21.0ms preprocess, 148.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_934.jpg\n",
      "Saved labels to: results6\\labels\\VIT_934.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_935.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_935.jpg: 640x480 23 handwrittens, 146.7ms\n",
      "Speed: 4.2ms preprocess, 146.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_935.jpg\n",
      "Saved labels to: results6\\labels\\VIT_935.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_936.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_936.jpg: 640x480 19 handwrittens, 129.6ms\n",
      "Speed: 3.9ms preprocess, 129.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_936.jpg\n",
      "Saved labels to: results6\\labels\\VIT_936.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_937.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_937.jpg: 640x480 22 handwrittens, 116.5ms\n",
      "Speed: 3.3ms preprocess, 116.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_937.jpg\n",
      "Saved labels to: results6\\labels\\VIT_937.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_938.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_938.jpg: 640x480 21 handwrittens, 121.2ms\n",
      "Speed: 3.0ms preprocess, 121.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_938.jpg\n",
      "Saved labels to: results6\\labels\\VIT_938.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_939.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_939.jpg: 640x480 21 handwrittens, 110.3ms\n",
      "Speed: 4.1ms preprocess, 110.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_939.jpg\n",
      "Saved labels to: results6\\labels\\VIT_939.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_940.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_940.jpg: 640x480 22 handwrittens, 118.4ms\n",
      "Speed: 3.2ms preprocess, 118.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_940.jpg\n",
      "Saved labels to: results6\\labels\\VIT_940.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_941.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_941.jpg: 640x480 25 handwrittens, 181.4ms\n",
      "Speed: 3.1ms preprocess, 181.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_941.jpg\n",
      "Saved labels to: results6\\labels\\VIT_941.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_942.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_942.jpg: 640x480 22 handwrittens, 101.8ms\n",
      "Speed: 3.6ms preprocess, 101.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_942.jpg\n",
      "Saved labels to: results6\\labels\\VIT_942.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_943.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_943.jpg: 640x480 21 handwrittens, 112.5ms\n",
      "Speed: 3.5ms preprocess, 112.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_943.jpg\n",
      "Saved labels to: results6\\labels\\VIT_943.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_944.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_944.jpg: 640x480 22 handwrittens, 119.7ms\n",
      "Speed: 3.3ms preprocess, 119.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_944.jpg\n",
      "Saved labels to: results6\\labels\\VIT_944.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_945.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_945.jpg: 640x480 22 handwrittens, 157.7ms\n",
      "Speed: 4.8ms preprocess, 157.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_945.jpg\n",
      "Saved labels to: results6\\labels\\VIT_945.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_946.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_946.jpg: 640x480 20 handwrittens, 106.3ms\n",
      "Speed: 2.3ms preprocess, 106.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_946.jpg\n",
      "Saved labels to: results6\\labels\\VIT_946.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_947.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_947.jpg: 640x480 24 handwrittens, 93.5ms\n",
      "Speed: 2.4ms preprocess, 93.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_947.jpg\n",
      "Saved labels to: results6\\labels\\VIT_947.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_948.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_948.jpg: 640x480 24 handwrittens, 136.6ms\n",
      "Speed: 3.5ms preprocess, 136.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_948.jpg\n",
      "Saved labels to: results6\\labels\\VIT_948.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_949.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_949.jpg: 640x480 24 handwrittens, 127.8ms\n",
      "Speed: 2.5ms preprocess, 127.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_949.jpg\n",
      "Saved labels to: results6\\labels\\VIT_949.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_950.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_950.jpg: 640x480 24 handwrittens, 112.7ms\n",
      "Speed: 3.2ms preprocess, 112.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_950.jpg\n",
      "Saved labels to: results6\\labels\\VIT_950.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_951.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_951.jpg: 640x480 24 handwrittens, 92.3ms\n",
      "Speed: 2.1ms preprocess, 92.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_951.jpg\n",
      "Saved labels to: results6\\labels\\VIT_951.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_952.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_952.jpg: 640x480 21 handwrittens, 105.6ms\n",
      "Speed: 2.9ms preprocess, 105.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_952.jpg\n",
      "Saved labels to: results6\\labels\\VIT_952.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_953.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_953.jpg: 640x480 18 handwrittens, 121.9ms\n",
      "Speed: 3.3ms preprocess, 121.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_953.jpg\n",
      "Saved labels to: results6\\labels\\VIT_953.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_954.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_954.jpg: 640x480 21 handwrittens, 115.1ms\n",
      "Speed: 2.1ms preprocess, 115.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_954.jpg\n",
      "Saved labels to: results6\\labels\\VIT_954.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_955.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_955.jpg: 640x480 22 handwrittens, 106.3ms\n",
      "Speed: 3.6ms preprocess, 106.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_955.jpg\n",
      "Saved labels to: results6\\labels\\VIT_955.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_956.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_956.jpg: 640x480 23 handwrittens, 105.3ms\n",
      "Speed: 3.1ms preprocess, 105.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_956.jpg\n",
      "Saved labels to: results6\\labels\\VIT_956.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_957.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_957.jpg: 640x480 23 handwrittens, 116.4ms\n",
      "Speed: 11.2ms preprocess, 116.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_957.jpg\n",
      "Saved labels to: results6\\labels\\VIT_957.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_958.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_958.jpg: 640x480 22 handwrittens, 130.8ms\n",
      "Speed: 3.6ms preprocess, 130.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_958.jpg\n",
      "Saved labels to: results6\\labels\\VIT_958.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_959.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_959.jpg: 640x480 25 handwrittens, 114.5ms\n",
      "Speed: 4.9ms preprocess, 114.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_959.jpg\n",
      "Saved labels to: results6\\labels\\VIT_959.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_960.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_960.jpg: 640x480 26 handwrittens, 118.0ms\n",
      "Speed: 3.8ms preprocess, 118.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_960.jpg\n",
      "Saved labels to: results6\\labels\\VIT_960.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_961.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_961.jpg: 640x480 21 handwrittens, 143.3ms\n",
      "Speed: 14.6ms preprocess, 143.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_961.jpg\n",
      "Saved labels to: results6\\labels\\VIT_961.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_962.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_962.jpg: 640x480 23 handwrittens, 110.2ms\n",
      "Speed: 3.1ms preprocess, 110.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_962.jpg\n",
      "Saved labels to: results6\\labels\\VIT_962.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_963.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_963.jpg: 640x480 20 handwrittens, 114.9ms\n",
      "Speed: 3.4ms preprocess, 114.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_963.jpg\n",
      "Saved labels to: results6\\labels\\VIT_963.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_964.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_964.jpg: 640x480 20 handwrittens, 137.2ms\n",
      "Speed: 2.6ms preprocess, 137.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_964.jpg\n",
      "Saved labels to: results6\\labels\\VIT_964.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_965.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_965.jpg: 640x480 24 handwrittens, 132.9ms\n",
      "Speed: 43.2ms preprocess, 132.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_965.jpg\n",
      "Saved labels to: results6\\labels\\VIT_965.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_966.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_966.jpg: 640x480 24 handwrittens, 122.2ms\n",
      "Speed: 3.6ms preprocess, 122.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_966.jpg\n",
      "Saved labels to: results6\\labels\\VIT_966.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_967.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_967.jpg: 640x480 22 handwrittens, 125.3ms\n",
      "Speed: 2.9ms preprocess, 125.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_967.jpg\n",
      "Saved labels to: results6\\labels\\VIT_967.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_968.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_968.jpg: 640x480 19 handwrittens, 123.9ms\n",
      "Speed: 4.2ms preprocess, 123.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_968.jpg\n",
      "Saved labels to: results6\\labels\\VIT_968.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_969.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_969.jpg: 640x480 20 handwrittens, 146.6ms\n",
      "Speed: 11.5ms preprocess, 146.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_969.jpg\n",
      "Saved labels to: results6\\labels\\VIT_969.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_970.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_970.jpg: 640x480 22 handwrittens, 113.2ms\n",
      "Speed: 3.1ms preprocess, 113.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_970.jpg\n",
      "Saved labels to: results6\\labels\\VIT_970.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_971.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_971.jpg: 640x480 21 handwrittens, 116.9ms\n",
      "Speed: 3.6ms preprocess, 116.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_971.jpg\n",
      "Saved labels to: results6\\labels\\VIT_971.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_972.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_972.jpg: 640x480 21 handwrittens, 162.7ms\n",
      "Speed: 3.7ms preprocess, 162.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_972.jpg\n",
      "Saved labels to: results6\\labels\\VIT_972.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_973.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_973.jpg: 640x480 20 handwrittens, 124.6ms\n",
      "Speed: 3.7ms preprocess, 124.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_973.jpg\n",
      "Saved labels to: results6\\labels\\VIT_973.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_974.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_974.jpg: 640x480 23 handwrittens, 107.3ms\n",
      "Speed: 2.4ms preprocess, 107.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_974.jpg\n",
      "Saved labels to: results6\\labels\\VIT_974.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_975.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_975.jpg: 640x480 20 handwrittens, 128.8ms\n",
      "Speed: 3.4ms preprocess, 128.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_975.jpg\n",
      "Saved labels to: results6\\labels\\VIT_975.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_976.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_976.jpg: 640x480 20 handwrittens, 156.3ms\n",
      "Speed: 3.6ms preprocess, 156.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_976.jpg\n",
      "Saved labels to: results6\\labels\\VIT_976.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_977.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_977.jpg: 640x480 21 handwrittens, 224.1ms\n",
      "Speed: 5.8ms preprocess, 224.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_977.jpg\n",
      "Saved labels to: results6\\labels\\VIT_977.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_978.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_978.jpg: 640x480 22 handwrittens, 178.5ms\n",
      "Speed: 3.2ms preprocess, 178.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_978.jpg\n",
      "Saved labels to: results6\\labels\\VIT_978.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_979.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_979.jpg: 640x480 21 handwrittens, 199.2ms\n",
      "Speed: 7.1ms preprocess, 199.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_979.jpg\n",
      "Saved labels to: results6\\labels\\VIT_979.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_980.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_980.jpg: 640x480 21 handwrittens, 128.2ms\n",
      "Speed: 3.1ms preprocess, 128.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_980.jpg\n",
      "Saved labels to: results6\\labels\\VIT_980.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_981.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_981.jpg: 640x480 22 handwrittens, 124.9ms\n",
      "Speed: 3.5ms preprocess, 124.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_981.jpg\n",
      "Saved labels to: results6\\labels\\VIT_981.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_982.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_982.jpg: 640x480 20 handwrittens, 125.4ms\n",
      "Speed: 2.6ms preprocess, 125.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_982.jpg\n",
      "Saved labels to: results6\\labels\\VIT_982.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_983.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_983.jpg: 640x480 26 handwrittens, 113.2ms\n",
      "Speed: 3.1ms preprocess, 113.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_983.jpg\n",
      "Saved labels to: results6\\labels\\VIT_983.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_984.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_984.jpg: 640x480 22 handwrittens, 113.0ms\n",
      "Speed: 3.2ms preprocess, 113.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_984.jpg\n",
      "Saved labels to: results6\\labels\\VIT_984.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_985.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_985.jpg: 640x480 22 handwrittens, 109.8ms\n",
      "Speed: 3.3ms preprocess, 109.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_985.jpg\n",
      "Saved labels to: results6\\labels\\VIT_985.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_986.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_986.jpg: 640x480 23 handwrittens, 162.2ms\n",
      "Speed: 1.9ms preprocess, 162.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_986.jpg\n",
      "Saved labels to: results6\\labels\\VIT_986.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_987.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_987.jpg: 640x480 26 handwrittens, 128.2ms\n",
      "Speed: 5.5ms preprocess, 128.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_987.jpg\n",
      "Saved labels to: results6\\labels\\VIT_987.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_988.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_988.jpg: 640x480 22 handwrittens, 120.2ms\n",
      "Speed: 4.5ms preprocess, 120.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_988.jpg\n",
      "Saved labels to: results6\\labels\\VIT_988.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_989.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_989.jpg: 640x480 21 handwrittens, 134.2ms\n",
      "Speed: 46.3ms preprocess, 134.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_989.jpg\n",
      "Saved labels to: results6\\labels\\VIT_989.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_990.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_990.jpg: 640x480 20 handwrittens, 139.4ms\n",
      "Speed: 3.0ms preprocess, 139.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_990.jpg\n",
      "Saved labels to: results6\\labels\\VIT_990.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_991.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_991.jpg: 640x480 20 handwrittens, 116.5ms\n",
      "Speed: 3.3ms preprocess, 116.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_991.jpg\n",
      "Saved labels to: results6\\labels\\VIT_991.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_992.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_992.jpg: 640x480 21 handwrittens, 115.6ms\n",
      "Speed: 3.5ms preprocess, 115.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_992.jpg\n",
      "Saved labels to: results6\\labels\\VIT_992.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_993.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_993.jpg: 640x480 22 handwrittens, 150.8ms\n",
      "Speed: 3.4ms preprocess, 150.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_993.jpg\n",
      "Saved labels to: results6\\labels\\VIT_993.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_994.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_994.jpg: 640x480 22 handwrittens, 124.6ms\n",
      "Speed: 3.3ms preprocess, 124.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_994.jpg\n",
      "Saved labels to: results6\\labels\\VIT_994.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_995.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_995.jpg: 640x480 23 handwrittens, 157.4ms\n",
      "Speed: 7.6ms preprocess, 157.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_995.jpg\n",
      "Saved labels to: results6\\labels\\VIT_995.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_996.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_996.jpg: 640x480 21 handwrittens, 335.8ms\n",
      "Speed: 3.5ms preprocess, 335.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_996.jpg\n",
      "Saved labels to: results6\\labels\\VIT_996.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_997.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_997.jpg: 640x480 21 handwrittens, 158.7ms\n",
      "Speed: 3.3ms preprocess, 158.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_997.jpg\n",
      "Saved labels to: results6\\labels\\VIT_997.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_998.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_998.jpg: 640x480 17 handwrittens, 145.5ms\n",
      "Speed: 3.0ms preprocess, 145.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_998.jpg\n",
      "Saved labels to: results6\\labels\\VIT_998.txt\n",
      "Processing: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_999.jpg\n",
      "\n",
      "image 1/1 D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\\VIT_999.jpg: 640x480 22 handwrittens, 129.3ms\n",
      "Speed: 3.2ms preprocess, 129.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved image to: results6\\VIT_999.jpg\n",
      "Saved labels to: results6\\labels\\VIT_999.txt\n"
     ]
    }
   ],
   "source": [
    "# --- PROCESS IMAGES ---\n",
    "for filename in notebook_tqdm(os.listdir(IMAGE_DIR), desc=\"Processing images\"):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        image_path = os.path.join(IMAGE_DIR, filename)\n",
    "        print(f\"Processing: {image_path}\")\n",
    "        # Run inference\n",
    "        results = model(image_path, conf=CONFIDENCE_THRESHOLD)\n",
    "        for result in results:\n",
    "            # Sort bounding boxes: top-to-bottom, then left-to-right\n",
    "            # Each box: box.xyxy[0] = [x1, y1, x2, y2]\n",
    "            boxes_with_idx = [\n",
    "                (idx, box, int(box.xyxy[0][0]), int(box.xyxy[0][1]))\n",
    "                for idx, box in enumerate(result.boxes)\n",
    "            ]\n",
    "            # Sort by y1 (top), then x1 (left)\n",
    "            boxes_with_idx_sorted = sorted(boxes_with_idx, key=lambda x: (x[3], x[2]))\n",
    "            # Save annotated image\n",
    "            annotated_img = result.plot()\n",
    "            output_img_path = os.path.join(RESULT_DIR, filename)\n",
    "            cv2.imwrite(output_img_path, annotated_img)\n",
    "            # Save labels with bbox index (sorted)\n",
    "            label_path = os.path.join(LABEL_DIR, filename.rsplit('.', 1)[0] + '.txt')\n",
    "            with open(label_path, 'w') as f:\n",
    "                for new_idx, (orig_idx, box, _, _) in enumerate(boxes_with_idx_sorted):\n",
    "                    cls_id = int(box.cls[0])\n",
    "                    conf = float(box.conf[0])\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0]) # Bounding box\n",
    "                    # YOLO format: cls_id conf x1 y1 x2 y2\n",
    "                    # Add index and Write custom YOLO format: index cls_id conf x1 y1 x2 y2\n",
    "                    f.write(f'{new_idx+1} {cls_id} {conf:.2f} {x1} {y1} {x2} {y2}\\n')\n",
    "            print(f\"Saved image to: {output_img_path}\")\n",
    "            print(f\"Saved labels to: {label_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc0c479",
   "metadata": {},
   "source": [
    "<H4># DATA PREPROCESSING<H4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42e99d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if running in Colab\n",
    "'''\n",
    "LABELS_DIR = '/content/drive/MyDrive/DeHaDo-AI/results/labels'\n",
    "IMAGES_DIR = '/content/drive/MyDrive/DeHaDo-AI/DEHADO-AI_TRAINING_DATASET/IMAGES_750'\n",
    "OCR_TXT_DIR = '/content/drive/MyDrive/DeHaDo-AI/DEHADO-AI_TRAINING_DATASET/LABELS_750'\n",
    "OUTPUT_DIR = '/content/drive/MyDrive/DeHaDo-AI/results/output'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b79dec0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABELS_DIR =>  results6\\labels\n",
      "OUTPUT_DIR =>  results6\\output\n",
      "SKIPPED_FILES_LIST =>  results6\\output\\skipped_files.txt\n"
     ]
    }
   ],
   "source": [
    "# Uncomment if running in a local environment\n",
    "LABELS_DIR = os.path.join(RESULT_DIR, 'labels')\n",
    "OUTPUT_DIR = os.path.join(RESULT_DIR, 'output')\n",
    "SKIPPED_FILES_LIST = os.path.join(RESULT_DIR, 'output\\skipped_files.txt')\n",
    "IMAGES_DIR = r'D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750'\n",
    "OCR_TXT_DIR = r'D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\LABELS_750'\n",
    "\n",
    "print('LABELS_DIR => ',LABELS_DIR)\n",
    "print('OUTPUT_DIR => ',OUTPUT_DIR)\n",
    "print('SKIPPED_FILES_LIST => ',SKIPPED_FILES_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3bb410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(LABELS_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "if not os.path.exists(SKIPPED_FILES_LIST):\n",
    "    with open(SKIPPED_FILES_LIST, 'w'   ) as f:\n",
    "        f.write('skipped_files.txt\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b4ce046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import cv2\n",
    "import json\n",
    "from tqdm.notebook import tqdm as notebook_tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "839a2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img_path, bbox, img_height, img_width):\n",
    "    \"\"\"\n",
    "    Crop image to bbox, resize and normalize for OCR model.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Ensure bbox coordinates are within image bounds\n",
    "    h, w = img.shape[:2]\n",
    "    x1, y1, x2, y2 = map(int, bbox)\n",
    "    x1, y1, x2, y2 = max(0, x1), max(0, y1), min(w, x2), min(h, y2)\n",
    "    # Handle invalid bounding boxes\n",
    "    if x1 >= x2 or y1 >= y2:\n",
    "        return None   # return None to indicate a skipped crop\n",
    "\n",
    "    cropped = img[y1:y2, x1:x2]\n",
    "    resized = cv2.resize(cropped, (img_width, img_height))\n",
    "    normed = resized.astype(np.float32) / 255.0\n",
    "    normed = np.expand_dims(normed, axis=-1)\n",
    "    return normed\n",
    "\n",
    "def read_label_file(label_path):\n",
    "    \"\"\"\n",
    "    Read YOLO label file and return list of bounding boxes.\n",
    "    \"\"\"\n",
    "    bboxes = []\n",
    "    if not os.path.exists(label_path):\n",
    "        return bboxes # Return empty list if file doesn't exist\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            # custom YOLO format: index cls_id conf x1 y1 x2 y2\n",
    "            if len(parts) >= 7:\n",
    "                try:\n",
    "                    # parts[0] is the index \n",
    "                    # parts[1] is the class id \n",
    "                    # parts[2] is the confidence score                    \n",
    "                    # parts 3-6 are the int bounding box coordinates\n",
    "                    idx = int(parts[0])                    \n",
    "                    x1, y1, x2, y2 = map(int, parts[3:7])\n",
    "                    bboxes.append((idx, (x1, y1, x2, y2)))\n",
    "                except ValueError:\n",
    "                    continue # Skip this line if conversion fails\n",
    "    return bboxes\n",
    "\n",
    "def read_gt_text(txt_path):\n",
    "    \"\"\"\n",
    "    Read ground truth JSON file and return list of text values.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    if not os.path.exists(txt_path):\n",
    "        return result # Return empty list if file doesn't exist\n",
    "    try:\n",
    "        with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            # Assuming `data` is a list where each element is an object containing 'Field value'            \n",
    "            if isinstance(data, list):\n",
    "                for item in data:\n",
    "                    if isinstance(item, dict) and 'Field value' in item:\n",
    "                        value = item['Field value']\n",
    "                        if isinstance(value, str):\n",
    "                            result.append(value.strip())\n",
    "                        elif isinstance(value, list) and value: # Handle lists of strings\n",
    "                            result.append(' '.join(map(str, value)).strip()) # Join elements if it's a list\n",
    "                        else:\n",
    "                            result.append('') # Append empty string for unexpected formats\n",
    "                    else:\n",
    "                        print(f\"Warning: Skipping unexpected item format in JSON file: {item}\")                        \n",
    "                        pass\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON from {txt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading ground truth text from {txt_path}: {e}\")\n",
    "\n",
    "    return result # Return a list of strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa02f51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabet:  &'()+,-./0123456789:ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "Number of characters: 76\n"
     ]
    }
   ],
   "source": [
    "# BUILD ALPHABET FROM DATASET LABELS\n",
    "all_chars = set()\n",
    "for img_file in os.listdir(IMAGES_DIR):\n",
    "    if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        continue\n",
    "    base_filename = os.path.splitext(img_file)[0]\n",
    "    gt_txt_path = os.path.join(OCR_TXT_DIR, base_filename + '.json')\n",
    "    gt_texts = read_gt_text(gt_txt_path)\n",
    "    for text in gt_texts:\n",
    "        all_chars.update(text)\n",
    "alphabet = ''.join(sorted(list(all_chars)))\n",
    "num_chars = len(alphabet) + 1  # +1 for CTC blank\n",
    "\n",
    "print(f\"Alphabet: {alphabet}\")\n",
    "print(f\"Number of characters: {num_chars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ba558e",
   "metadata": {},
   "source": [
    "<H4># TRAINING CONFIG<H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6468d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_TRAIN_FROM_SCRATCH = True # Uncomment if you want to train the model\n",
    "MODEL_TRAIN_FROM_SCRATCH = False # Uncomment if you have a trained model\n",
    "TRAINED_MODEL_FILE_NAME = 'ocr_model_trained3.h5'\n",
    "PRED_MODEL_FILE_NAME = 'ocr_model_pred3.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bdf8873",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCH_SIZE = 1000\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff53099",
   "metadata": {},
   "source": [
    "<H4># 1. Load dataset<H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f7d18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ LABELS AND IMAGES\n",
    "def load_data(images_dir, labels_dir, ocr_txt_dir, IMG_HEIGHT, IMG_WIDTH):\n",
    "    \"\"\"\n",
    "    Load images and labels from the specified directories.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    print(f\"Loading data from:\")\n",
    "    print(f\"  Images: {images_dir}\")\n",
    "    print(f\"  Labels: {labels_dir}\")\n",
    "    print(f\"  OCR Text: {ocr_txt_dir}\")\n",
    "\n",
    "    processed_count = 0\n",
    "    skipped_count = 0\n",
    "    skipped_files = []\n",
    "    for img_file in os.listdir(images_dir):\n",
    "        if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(images_dir, img_file)\n",
    "        base_filename = os.path.splitext(img_file)[0]\n",
    "        label_path = os.path.join(labels_dir, base_filename + '.txt')\n",
    "        gt_txt_path = os.path.join(ocr_txt_dir, base_filename + '.json')\n",
    "\n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"  Skipping {img_file}: Label file not found at {label_path}\")\n",
    "            skipped_files.append(img_file)\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        if not os.path.exists(gt_txt_path):\n",
    "            print(f\"  Skipping {img_file}: Ground truth text file not found at {gt_txt_path}\")\n",
    "            skipped_files.append(img_file)\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        bboxes = read_label_file(label_path)\n",
    "        gt_texts = read_gt_text(gt_txt_path)\n",
    "\n",
    "        if len(bboxes) != len(gt_texts):\n",
    "            print(f\"  Skipping {img_file}: Mismatch between number of bounding boxes ({len(bboxes)}) and ground truth texts ({len(gt_texts)})\")\n",
    "            skipped_files.append(img_file)\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        if not bboxes:\n",
    "            print(f\"  Skipping {img_file}: No bounding boxes found in label file\")\n",
    "            skipped_files.append(img_file)\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        for (idx, bbox), text in zip(bboxes, gt_texts):\n",
    "            try:\n",
    "                crop = preprocess_img(img_path, bbox, IMG_HEIGHT, IMG_WIDTH)\n",
    "                if crop is not None: # Only append if crop was successful\n",
    "                    X.append((idx, crop))  # Store as (idx, crop)\n",
    "                    y.append(text)\n",
    "                    processed_count += 1\n",
    "                else:\n",
    "                    print(f\"  Skipping crop for {img_file} with bbox {bbox}: Invalid bbox\")\n",
    "                    skipped_files.append(img_file)\n",
    "                    skipped_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing {img_file} with bbox {bbox}: {e}\")\n",
    "                skipped_files.append(img_file)\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "    \n",
    "    print(f\"Finished loading data.\")\n",
    "    print(f\"Total files processed: {processed_count + skipped_count}\")\n",
    "    print(f\"Successfully loaded {processed_count} samples.\")    \n",
    "    if skipped_count > 0:\n",
    "        print(f\"Skipped {skipped_count} files/samples.\")\n",
    "        #print(f\"Skipped files: {skipped_files}\")\n",
    "        print(f\"Skipped files have been logged to {SKIPPED_FILES_LIST}\")\n",
    "        # Save skipped files to a text file\n",
    "        with open(SKIPPED_FILES_LIST, 'w') as f:\n",
    "            for file in skipped_files:\n",
    "                f.write(f\"{file}\\n\")\n",
    "\n",
    "    return np.array(X, dtype=object), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3cf4279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from:\n",
      "  Images: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750\n",
      "  Labels: results6\\labels\n",
      "  OCR Text: D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\LABELS_750\n",
      "  Skipping MIT_1.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_10.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_102.jpg: Mismatch between number of bounding boxes (28) and ground truth texts (20)\n",
      "  Skipping MIT_103.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_104.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_105.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_106.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_108.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_109.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_11.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_110.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (19)\n",
      "  Skipping MIT_111.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping MIT_112.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_113.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (17)\n",
      "  Skipping MIT_114.jpg: Mismatch between number of bounding boxes (29) and ground truth texts (20)\n",
      "  Skipping MIT_115.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_116.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_117.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_118.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (21)\n",
      "  Skipping MIT_12.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_120.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_121.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_122.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_125.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_126.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_127.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_128.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_129.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_130.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping MIT_131.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_132.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_134.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_137.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_138.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_139.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_14.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping MIT_141.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_142.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_143.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_145.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_147.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_148.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_149.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_15.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_150.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_151.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_154.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_155.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_156.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_159.jpg: Mismatch between number of bounding boxes (19) and ground truth texts (18)\n",
      "  Skipping MIT_16.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_160.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_162.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_163.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (21)\n",
      "  Skipping MIT_164.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_165.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_166.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_167.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_168.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_169.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_17.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_170.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping MIT_171.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_172.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_173.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_174.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (21)\n",
      "  Skipping MIT_175.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (21)\n",
      "  Skipping MIT_176.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_177.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping MIT_178.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_179.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_18.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_180.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_181.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_182.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping MIT_183.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_184.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_185.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_186.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_187.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (21)\n",
      "  Skipping MIT_188.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_189.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_19.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_190.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_192.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_193.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_194.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_195.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_196.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_197.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_199.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_2.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_20.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_200.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_202.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_203.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_204.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (18)\n",
      "  Skipping MIT_205.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_206.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_207.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_209.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_21.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_210.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_211.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_213.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_215.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_217.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_218.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_22.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_220.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_221.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_222.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_223.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_224.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_225.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_226.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_227.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping MIT_228.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (21)\n",
      "  Skipping MIT_229.jpg: Mismatch between number of bounding boxes (29) and ground truth texts (20)\n",
      "  Skipping MIT_23.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_230.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_231.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_232.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_234.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_235.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_236.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_237.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_238.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (21)\n",
      "  Skipping MIT_24.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_240.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_241.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_242.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_243.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (21)\n",
      "  Skipping MIT_244.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_246.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping MIT_248.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_249.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_25.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_251.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_252.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping MIT_253.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_254.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_255.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_256.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_257.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_258.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_259.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_26.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_260.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_261.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_262.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_264.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_265.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_266.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping MIT_268.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_269.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_27.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_271.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_272.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping MIT_273.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_274.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_275.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_277.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_278.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_28.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_281.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_282.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_283.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_284.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_285.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_286.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_288.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_29.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_290.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_291.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_293.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_294.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (21)\n",
      "  Skipping MIT_295.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_296.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_298.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_299.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_3.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_30.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_300.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_301.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_302.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_303.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_304.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_305.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (21)\n",
      "  Skipping MIT_306.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_307.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_308.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_309.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_31.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping MIT_310.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping MIT_311.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_313.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_314.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_315.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_316.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_317.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping MIT_318.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (21)\n",
      "  Skipping MIT_32.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_320.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_322.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_323.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_324.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_326.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_327.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_328.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_329.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_33.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (21)\n",
      "  Skipping MIT_330.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_331.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_332.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_334.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_336.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_337.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_338.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_339.jpg: Mismatch between number of bounding boxes (19) and ground truth texts (18)\n",
      "  Skipping MIT_34.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping MIT_340.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping MIT_341.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_343.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_344.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_345.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_346.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_348.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_349.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (21)\n",
      "  Skipping MIT_35.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_350.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_351.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_352.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_353.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_354.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_355.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_356.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_357.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_358.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_359.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (21)\n",
      "  Skipping MIT_36.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_360.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_361.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (21)\n",
      "  Skipping MIT_363.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_364.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_365.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_366.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_368.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_369.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_37.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_370.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_373.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_375.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_376.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_377.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_378.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_379.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_38.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_380.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_381.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_382.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_383.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_384.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_387.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_388.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_389.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_39.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_392.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping MIT_393.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping MIT_395.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_396.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_397.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_398.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_399.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_4.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_40.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_400.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_401.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_402.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_403.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_404.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_405.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_406.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_407.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_408.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_409.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_41.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_410.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_412.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_415.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_416.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_417.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_42.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (21)\n",
      "  Skipping MIT_420.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_422.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_424.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_425.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_426.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (16)\n",
      "  Skipping MIT_427.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping MIT_428.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (21)\n",
      "  Skipping MIT_429.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_43.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_431.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_433.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_434.jpg: Mismatch between number of bounding boxes (37) and ground truth texts (20)\n",
      "  Skipping MIT_435.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_436.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_438.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_439.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_44.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_440.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_442.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_443.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_444.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_445.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_446.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_447.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping MIT_448.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (21)\n",
      "  Skipping MIT_449.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_45.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_450.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_452.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_453.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_454.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_455.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_456.jpg: Mismatch between number of bounding boxes (28) and ground truth texts (20)\n",
      "  Skipping MIT_457.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_458.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_459.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_46.jpg: Mismatch between number of bounding boxes (28) and ground truth texts (20)\n",
      "  Skipping MIT_460.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_462.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_463.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_464.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_466.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_467.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_468.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_469.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_471.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_472.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_473.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_474.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_475.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_477.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_478.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_479.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_48.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_480.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_481.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_482.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_483.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping MIT_484.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (21)\n",
      "  Skipping MIT_485.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_486.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (21)\n",
      "  Skipping MIT_487.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_488.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_489.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_49.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping MIT_490.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_491.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (15)\n",
      "  Skipping MIT_492.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_493.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_494.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping MIT_496.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (17)\n",
      "  Skipping MIT_498.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_499.jpg: Mismatch between number of bounding boxes (29) and ground truth texts (20)\n",
      "  Skipping MIT_5.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_50.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_500.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_501.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_502.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping MIT_503.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (21)\n",
      "  Skipping MIT_504.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_506.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping MIT_507.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_508.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_509.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_510.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_511.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_512.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_513.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_514.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_516.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_517.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_519.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (21)\n",
      "  Skipping MIT_52.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_520.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_521.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping MIT_522.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_523.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (19)\n",
      "  Skipping MIT_524.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_525.jpg: Mismatch between number of bounding boxes (28) and ground truth texts (20)\n",
      "  Skipping MIT_526.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_527.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (19)\n",
      "  Skipping MIT_528.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_529.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_530.jpg: Mismatch between number of bounding boxes (28) and ground truth texts (20)\n",
      "  Skipping MIT_531.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_532.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_533.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_536.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_538.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_539.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (21)\n",
      "  Skipping MIT_54.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_540.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_541.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_542.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_543.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_544.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_545.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_546.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_547.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_548.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_549.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_55.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_550.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_551.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping MIT_552.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_553.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_554.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_555.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_556.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_557.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping MIT_559.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_56.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_560.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_561.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping MIT_562.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_563.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_564.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_565.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_566.jpg: Mismatch between number of bounding boxes (31) and ground truth texts (20)\n",
      "  Skipping MIT_567.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (21)\n",
      "  Skipping MIT_568.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_569.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_57.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_570.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_571.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_572.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_575.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_576.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_577.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_578.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_58.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_580.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_581.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_582.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_583.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_584.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping MIT_586.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_587.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_588.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_589.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_59.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (21)\n",
      "  Skipping MIT_590.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_591.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_593.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_594.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_595.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_596.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping MIT_597.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_599.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_6.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_60.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_600.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_601.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_602.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (21)\n",
      "  Skipping MIT_603.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_604.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_605.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_606.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_607.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_608.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_609.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_61.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_610.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_613.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_615.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_616.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_617.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_618.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_619.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping MIT_62.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_620.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_621.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_622.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_623.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_624.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_625.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_628.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_629.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_63.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping MIT_630.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_631.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_634.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_635.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_636.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_64.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_640.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_641.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_642.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_643.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_645.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_646.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_647.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_648.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_649.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_65.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_650.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_651.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping MIT_652.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_654.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_655.jpg: Mismatch between number of bounding boxes (30) and ground truth texts (20)\n",
      "  Skipping MIT_657.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_659.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_66.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping MIT_660.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_661.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping MIT_662.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (21)\n",
      "  Skipping MIT_663.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (21)\n",
      "  Skipping MIT_664.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_665.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_666.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (18)\n",
      "  Skipping MIT_667.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping MIT_668.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_67.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_670.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_671.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_672.jpg: Mismatch between number of bounding boxes (19) and ground truth texts (18)\n",
      "  Skipping MIT_673.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_674.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping MIT_675.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_676.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_677.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_679.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (21)\n",
      "  Skipping MIT_68.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_681.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_682.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_683.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_685.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_686.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_687.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_688.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping MIT_689.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_69.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (21)\n",
      "  Skipping MIT_690.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_692.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_693.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_694.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_695.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_696.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_697.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_698.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_699.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_7.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_70.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_700.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_72.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_73.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_74.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (21)\n",
      "  Skipping MIT_75.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping MIT_77.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping MIT_8.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (21)\n",
      "  Skipping MIT_80.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (21)\n",
      "  Skipping MIT_81.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_82.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_84.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_85.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_86.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_87.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_89.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_9.jpg: Mismatch between number of bounding boxes (30) and ground truth texts (19)\n",
      "  Skipping MIT_90.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_92.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping MIT_93.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_94.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_95.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_96.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping MIT_97.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping MIT_98.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping MIT_99.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping TCE_1001.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (19)\n",
      "  Skipping TCE_1002.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (17)\n",
      "  Skipping TCE_1003.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (19)\n",
      "  Skipping TCE_1004.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (17)\n",
      "  Skipping TCE_1005.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping TCE_1006.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1007.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1008.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1009.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1010.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1011.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1012.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (19)\n",
      "  Skipping TCE_1013.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1014.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1015.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (19)\n",
      "  Skipping TCE_1017.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (19)\n",
      "  Skipping TCE_1019.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1021.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1022.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1023.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1024.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1025.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1027.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1028.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1030.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1032.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1033.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1036.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1041.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1042.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1044.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1048.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1049.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1050.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1051.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1052.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1054.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1055.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1056.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1057.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1058.jpg: Mismatch between number of bounding boxes (18) and ground truth texts (17)\n",
      "  Skipping TCE_1059.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1060.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1061.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1062.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (17)\n",
      "  Skipping TCE_1063.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (17)\n",
      "  Skipping TCE_1064.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (17)\n",
      "  Skipping TCE_1065.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1066.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1067.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1068.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (17)\n",
      "  Skipping TCE_1069.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (17)\n",
      "  Skipping TCE_1070.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (16)\n",
      "  Skipping TCE_1072.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1073.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1074.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1075.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1076.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1077.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1078.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (19)\n",
      "  Skipping TCE_1079.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (19)\n",
      "  Skipping TCE_1080.jpg: Mismatch between number of bounding boxes (29) and ground truth texts (19)\n",
      "  Skipping TCE_1081.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1082.jpg: Mismatch between number of bounding boxes (28) and ground truth texts (19)\n",
      "  Skipping TCE_1083.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping TCE_1086.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1087.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1088.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (19)\n",
      "  Skipping TCE_1089.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1090.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1093.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (19)\n",
      "  Skipping TCE_1096.jpg: Mismatch between number of bounding boxes (31) and ground truth texts (19)\n",
      "  Skipping TCE_1097.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1098.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1099.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1100.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1101.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1103.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1104.jpg: Mismatch between number of bounding boxes (28) and ground truth texts (19)\n",
      "  Skipping TCE_1106.jpg: Mismatch between number of bounding boxes (29) and ground truth texts (17)\n",
      "  Skipping TCE_1107.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (19)\n",
      "  Skipping TCE_1109.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1110.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1111.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (19)\n",
      "  Skipping TCE_1112.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1113.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1114.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1115.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1116.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1117.jpg: Mismatch between number of bounding boxes (18) and ground truth texts (15)\n",
      "  Skipping TCE_1119.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1120.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (21)\n",
      "  Skipping TCE_1122.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1123.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1125.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1126.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1128.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1129.jpg: Mismatch between number of bounding boxes (19) and ground truth texts (17)\n",
      "  Skipping TCE_1130.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1132.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1133.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1136.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1137.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1139.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1140.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1141.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1142.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1143.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1144.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1145.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1146.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1147.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1148.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1149.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1150.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1151.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1152.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1153.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1154.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1155.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1156.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1157.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1158.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1159.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (19)\n",
      "  Skipping TCE_1160.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping TCE_1161.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping TCE_1162.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1163.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (19)\n",
      "  Skipping TCE_1164.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1165.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1166.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1170.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping TCE_1171.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1172.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1173.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (19)\n",
      "  Skipping TCE_1174.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1175.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1176.jpg: Mismatch between number of bounding boxes (28) and ground truth texts (19)\n",
      "  Skipping TCE_1177.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (19)\n",
      "  Skipping TCE_1178.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1179.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1180.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping TCE_1181.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping TCE_1182.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1183.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1184.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1185.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (19)\n",
      "  Skipping TCE_1186.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1187.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1188.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1189.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1190.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1191.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1193.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1194.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1195.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1196.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1197.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1198.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1199.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1201.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1202.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1203.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1205.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (18)\n",
      "  Skipping TCE_1206.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (19)\n",
      "  Skipping TCE_1212.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1219.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1220.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1221.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1222.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1223.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1224.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (19)\n",
      "  Skipping TCE_1225.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1226.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1228.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1229.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (19)\n",
      "  Skipping TCE_1230.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1231.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1232.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1233.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1235.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1236.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1237.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1238.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1239.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1240.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1241.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1242.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1244.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1245.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1246.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1247.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1248.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1249.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1250.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1251.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1252.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1253.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1254.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1255.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1256.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1257.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1258.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1259.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1260.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1261.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1262.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1263.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1264.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1265.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (19)\n",
      "  Skipping TCE_1266.jpg: Mismatch between number of bounding boxes (30) and ground truth texts (19)\n",
      "  Skipping TCE_1267.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (19)\n",
      "  Skipping TCE_1268.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1269.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1270.jpg: Mismatch between number of bounding boxes (28) and ground truth texts (19)\n",
      "  Skipping TCE_1271.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1272.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping TCE_1273.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1275.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping TCE_1276.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1277.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1279.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1280.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1281.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (19)\n",
      "  Skipping TCE_1282.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1283.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1284.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1285.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1286.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1287.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1288.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1289.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1290.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1291.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (17)\n",
      "  Skipping TCE_1292.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (19)\n",
      "  Skipping TCE_1293.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1294.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1295.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1296.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1297.jpg: Mismatch between number of bounding boxes (28) and ground truth texts (19)\n",
      "  Skipping TCE_1298.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1299.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (18)\n",
      "  Skipping TCE_1300.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1301.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1302.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1303.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1304.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1305.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1307.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (18)\n",
      "  Skipping TCE_1308.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1309.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1310.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1311.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1312.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1313.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1314.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1315.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1316.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1317.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1318.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1319.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (19)\n",
      "  Skipping TCE_1320.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1321.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1322.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1323.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1325.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (17)\n",
      "  Skipping TCE_1327.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1328.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1329.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1330.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1331.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1332.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1333.jpg: Mismatch between number of bounding boxes (19) and ground truth texts (18)\n",
      "  Skipping TCE_1334.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1335.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1337.jpg: Mismatch between number of bounding boxes (19) and ground truth texts (18)\n",
      "  Skipping TCE_1338.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1339.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1340.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1341.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1342.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1343.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1344.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1346.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1347.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (19)\n",
      "  Skipping TCE_1348.jpg: Mismatch between number of bounding boxes (19) and ground truth texts (17)\n",
      "  Skipping TCE_1349.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1351.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1352.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (19)\n",
      "  Skipping TCE_1353.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1354.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1355.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1356.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (19)\n",
      "  Skipping TCE_1357.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1358.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (19)\n",
      "  Skipping TCE_1359.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1360.jpg: Mismatch between number of bounding boxes (30) and ground truth texts (19)\n",
      "  Skipping TCE_1361.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (21)\n",
      "  Skipping TCE_1362.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1363.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1365.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping TCE_1366.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1367.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1369.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1370.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1371.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1372.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1373.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1375.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1377.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1380.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1381.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1382.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1383.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1384.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (18)\n",
      "  Skipping TCE_1385.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1387.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1388.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1389.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1390.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1391.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (17)\n",
      "  Skipping TCE_1392.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1393.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1394.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping TCE_1395.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping TCE_1398.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1400.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1401.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1402.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping TCE_1403.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1405.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1406.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1407.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1408.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1409.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1412.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1413.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (18)\n",
      "  Skipping TCE_1414.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping TCE_1415.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping TCE_1416.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1419.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1420.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1422.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1423.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1424.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1425.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1427.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1429.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1430.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1431.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1432.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1433.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1435.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1436.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1437.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1438.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1440.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1441.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1442.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1443.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1444.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1445.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1447.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1448.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1449.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1450.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (19)\n",
      "  Skipping TCE_1451.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1452.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1454.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1455.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1456.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1457.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1458.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1460.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1461.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1462.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1463.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1464.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1465.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (18)\n",
      "  Skipping TCE_1469.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1471.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (18)\n",
      "  Skipping TCE_1472.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (19)\n",
      "  Skipping TCE_1473.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1475.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (18)\n",
      "  Skipping TCE_1476.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1477.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1478.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1480.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1482.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1483.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1484.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1485.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1487.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1489.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1490.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1491.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping TCE_1492.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping TCE_1493.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1494.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping TCE_1495.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping TCE_1496.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping TCE_1499.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping TCE_1500.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping VIT_1000.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping VIT_701.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_702.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_703.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_704.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_705.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_706.jpg: Mismatch between number of bounding boxes (28) and ground truth texts (20)\n",
      "  Skipping VIT_707.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_708.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping VIT_709.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_710.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_711.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_712.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping VIT_713.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_714.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_715.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_716.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping VIT_717.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_718.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping VIT_719.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping VIT_720.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping VIT_721.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_722.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_723.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_724.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (21)\n",
      "  Skipping VIT_725.jpg: Mismatch between number of bounding boxes (28) and ground truth texts (20)\n",
      "  Skipping VIT_726.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_727.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_728.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_729.jpg: Mismatch between number of bounding boxes (28) and ground truth texts (21)\n",
      "  Skipping VIT_730.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_731.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping VIT_732.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping VIT_733.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_734.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_735.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_736.jpg: Mismatch between number of bounding boxes (29) and ground truth texts (20)\n",
      "  Skipping VIT_737.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (17)\n",
      "  Skipping VIT_738.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_739.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping VIT_740.jpg: Mismatch between number of bounding boxes (28) and ground truth texts (20)\n",
      "  Skipping VIT_741.jpg: Mismatch between number of bounding boxes (28) and ground truth texts (20)\n",
      "  Skipping VIT_742.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_743.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_744.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_745.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_746.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_747.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_748.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_749.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_750.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_751.jpg: Mismatch between number of bounding boxes (29) and ground truth texts (20)\n",
      "  Skipping VIT_752.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_753.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping VIT_754.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_755.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_756.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_757.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_758.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_759.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping VIT_760.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_761.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_762.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_763.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (21)\n",
      "  Skipping VIT_764.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_765.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_768.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_770.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_771.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_772.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_773.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_774.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_775.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_776.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_777.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping VIT_778.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (21)\n",
      "  Skipping VIT_779.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_780.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_781.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_782.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_783.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_784.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_785.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_786.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_787.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_788.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_789.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping VIT_790.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_791.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_792.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_793.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_794.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_795.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (18)\n",
      "  Skipping VIT_796.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_797.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_798.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_799.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping VIT_800.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_801.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (21)\n",
      "  Skipping VIT_802.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_803.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_804.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_805.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_806.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_807.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping VIT_808.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_809.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_810.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping VIT_811.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_812.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_813.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_814.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (21)\n",
      "  Skipping VIT_815.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (21)\n",
      "  Skipping VIT_816.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_817.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping VIT_818.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping VIT_819.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_820.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_821.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping VIT_822.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping VIT_823.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_824.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping VIT_825.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_826.jpg: Mismatch between number of bounding boxes (28) and ground truth texts (20)\n",
      "  Skipping VIT_827.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (21)\n",
      "  Skipping VIT_828.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_829.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (21)\n",
      "  Skipping VIT_830.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_831.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping VIT_832.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_833.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_835.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_836.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_837.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_838.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_839.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_840.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_841.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_842.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_843.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_844.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_846.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_847.jpg: Mismatch between number of bounding boxes (29) and ground truth texts (20)\n",
      "  Skipping VIT_848.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_850.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_851.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_852.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_853.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (21)\n",
      "  Skipping VIT_854.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping VIT_855.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_856.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_857.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_858.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_859.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_860.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping VIT_861.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping VIT_862.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping VIT_863.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_864.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_865.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (21)\n",
      "  Skipping VIT_866.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_868.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_869.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_870.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_871.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_872.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_873.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_874.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_875.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_876.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (19)\n",
      "  Skipping VIT_877.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_878.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_879.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_880.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_881.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_882.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_883.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping VIT_884.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_885.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_886.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_887.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping VIT_888.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_889.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_891.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_892.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_893.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_895.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping VIT_896.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_897.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_898.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_899.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_900.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_901.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_902.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_903.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_905.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping VIT_906.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping VIT_907.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping VIT_908.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping VIT_910.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_912.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_913.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_914.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_916.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (21)\n",
      "  Skipping VIT_917.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_918.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_919.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (21)\n",
      "  Skipping VIT_920.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_921.jpg: Mismatch between number of bounding boxes (29) and ground truth texts (20)\n",
      "  Skipping VIT_922.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (19)\n",
      "  Skipping VIT_923.jpg: Mismatch between number of bounding boxes (27) and ground truth texts (20)\n",
      "  Skipping VIT_924.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping VIT_925.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_926.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_927.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping VIT_928.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping VIT_929.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (19)\n",
      "  Skipping VIT_930.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_931.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_933.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_934.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_935.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_936.jpg: Mismatch between number of bounding boxes (19) and ground truth texts (16)\n",
      "  Skipping VIT_937.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (19)\n",
      "  Skipping VIT_938.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping VIT_939.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_940.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_941.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_942.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_943.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (19)\n",
      "  Skipping VIT_944.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_945.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_947.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_948.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_949.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_950.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_951.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (21)\n",
      "  Skipping VIT_954.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_955.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_956.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_957.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_958.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_959.jpg: Mismatch between number of bounding boxes (25) and ground truth texts (20)\n",
      "  Skipping VIT_960.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (21)\n",
      "  Skipping VIT_961.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_962.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_965.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_966.jpg: Mismatch between number of bounding boxes (24) and ground truth texts (20)\n",
      "  Skipping VIT_967.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_970.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (21)\n",
      "  Skipping VIT_971.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_972.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_974.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_975.jpg: Mismatch between number of bounding boxes (20) and ground truth texts (19)\n",
      "  Skipping VIT_977.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_978.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_980.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_981.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_983.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping VIT_984.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_985.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_986.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (21)\n",
      "  Skipping VIT_987.jpg: Mismatch between number of bounding boxes (26) and ground truth texts (20)\n",
      "  Skipping VIT_988.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_989.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_992.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_993.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_994.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (20)\n",
      "  Skipping VIT_995.jpg: Mismatch between number of bounding boxes (23) and ground truth texts (20)\n",
      "  Skipping VIT_997.jpg: Mismatch between number of bounding boxes (21) and ground truth texts (20)\n",
      "  Skipping VIT_999.jpg: Mismatch between number of bounding boxes (22) and ground truth texts (18)\n",
      "Finished loading data.\n",
      "Total files processed: 6060\n",
      "Successfully loaded 4805 samples.\n",
      "Skipped 1255 files/samples.\n",
      "Skipped files have been logged to results6\\output\\skipped_files.txt\n"
     ]
    }
   ],
   "source": [
    "# Load data (images and labels)\n",
    "X, y = load_data(IMAGES_DIR, LABELS_DIR, OCR_TXT_DIR, IMG_HEIGHT, IMG_WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a352c0",
   "metadata": {},
   "source": [
    "<H4># 2. Build alphabet and encode labels<H4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59d3b70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabet:  +,-./0123456789:ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "Number of characters: 71\n"
     ]
    }
   ],
   "source": [
    "# BUILD ALPHABET FROM OCR LABELS excluding skipped images\n",
    "if len(y) > 0:\n",
    "    all_chars = set()\n",
    "    for text in y:\n",
    "        all_chars.update(text)\n",
    "    alphabet = ''.join(sorted(list(all_chars)))\n",
    "    num_chars = len(alphabet) + 1  # +1 for CTC blank\n",
    "else:\n",
    "    print(\"No data loaded, cannot build alphabet or proceed with training.\")\n",
    "    alphabet = ''\n",
    "    num_chars = 1\n",
    "\n",
    "print(f\"Alphabet: {alphabet}\")\n",
    "print(f\"Number of characters: {num_chars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d1533",
   "metadata": {},
   "source": [
    "<H4># 3. Split train/test<H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf251710",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SPLIT=0.3\n",
    "RANDOM_STATE=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c71bd835",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X) == 0:\n",
    "    print(\"Error: No data loaded. Cannot perform train_test_split.\")\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RANDOM_STATE, shuffle=True)\n",
    "\n",
    "    # Encode labels\n",
    "    def encode_labels(texts, alphabet):\n",
    "        char_to_idx = {c: i for i, c in enumerate(alphabet)}\n",
    "        blank_index = len(alphabet)\n",
    "        encoded = []\n",
    "        for t in texts:\n",
    "            encoded.append([char_to_idx.get(c, blank_index) for c in t])\n",
    "        return pad_sequences(encoded, padding='post', value=blank_index, dtype='float32')\n",
    "    y_train_encoded = encode_labels(y_train, alphabet)\n",
    "    y_test_encoded = encode_labels(y_test, alphabet)\n",
    "\n",
    "    # Prepare input/label lengths for CTC\n",
    "    output_timesteps = IMG_HEIGHT // 4\n",
    "    train_label_length = np.array([[len(t)] for t in y_train])\n",
    "    test_label_length = np.array([[len(t)] for t in y_test])\n",
    "    train_input_length = np.ones((len(X_train), 1)) * output_timesteps\n",
    "    test_input_length = np.ones((len(X_test), 1)) * output_timesteps\n",
    "\n",
    "    # Filter samples where label length > output_timesteps or label is empty\n",
    "    def filter_by_label_length(X, y, y_encoded, label_length, max_len):\n",
    "        indices = [i for i, l in enumerate(label_length) if 0 < l[0] <= max_len]\n",
    "        crops = []\n",
    "        for i in indices:\n",
    "            crop = X[i][1]\n",
    "            crop = np.asarray(crop)\n",
    "            if crop.ndim == 2:\n",
    "                crop = np.expand_dims(crop, axis=-1)\n",
    "            crops.append(crop)\n",
    "        X_f = np.stack(crops, axis=0)\n",
    "        y_f = y[indices]\n",
    "        y_encoded_f = y_encoded[indices]\n",
    "        label_length_f = label_length[indices]\n",
    "        return X_f, y_f, y_encoded_f, label_length_f\n",
    "\n",
    "    X_train_filtered, y_train_filtered, y_train_encoded_filtered, train_label_length_filtered = filter_by_label_length(\n",
    "        X_train, y_train, y_train_encoded, train_label_length, output_timesteps\n",
    "    )\n",
    "    X_test_filtered, y_test_filtered, y_test_encoded_filtered, test_label_length_filtered = filter_by_label_length(\n",
    "        X_test, y_test, y_test_encoded, test_label_length, output_timesteps\n",
    "    )\n",
    "\n",
    "    X_train_filtered = X_train_filtered.astype(np.float32)\n",
    "    X_test_filtered = X_test_filtered.astype(np.float32)\n",
    "    train_input_length_filtered = np.ones((len(X_train_filtered), 1)) * output_timesteps\n",
    "    test_input_length_filtered = np.ones((len(X_test_filtered), 1)) * output_timesteps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1d4f49",
   "metadata": {},
   "source": [
    "<H4># 4. Create model<H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b185a01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image (InputLayer)             [(None, 128, 512, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 128, 512, 32  320         ['image[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 256, 32)  0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 64, 256, 32)  128        ['max_pooling2d[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 64, 256, 64)  18496       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 32, 128, 64)  0          ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 128, 64)  256        ['max_pooling2d_1[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 128, 128  73856       ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 128, 128  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 128, 128  147584      ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 16, 128, 128  0          ['conv2d_3[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 16, 128, 128  512        ['max_pooling2d_2[0][0]']        \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 32, 8192)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 32, 256)      8520704     ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 256)     1024        ['bidirectional[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 32, 256)     394240      ['batch_normalization_4[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 256)     1024        ['bidirectional_1[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " the_labels (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32, 71)       18247       ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " input_length (InputLayer)      [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " label_length (InputLayer)      [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " ctc_loss (CTCLayer)            (None, 32, 71)       0           ['the_labels[0][0]',             \n",
      "                                                                  'dense[0][0]',                  \n",
      "                                                                  'input_length[0][0]',           \n",
      "                                                                  'label_length[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,176,903\n",
      "Trainable params: 9,175,175\n",
      "Non-trainable params: 1,728\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if len(X) == 0:\n",
    "    print(\"Error: No data loaded. Cannot perform train_test_split.\")\n",
    "else:\n",
    "    def create_ocr_model_with_ctc(IMG_HEIGHT, IMG_WIDTH, num_chars):\n",
    "        input_img = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1), name='image')\n",
    "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2, 1), strides=(2, 1))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Reshape(target_shape=(IMG_HEIGHT // 4, -1))(x)\n",
    "        x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        output = layers.Dense(num_chars, activation='softmax')(x)\n",
    "\n",
    "        input_label = layers.Input(name='the_labels', shape=[None], dtype='float32')\n",
    "        input_len = layers.Input(name='input_length', shape=[None], dtype='int64')\n",
    "        label_len = layers.Input(name='label_length', shape=[None], dtype='int64')\n",
    "\n",
    "        class CTCLayer(layers.Layer):\n",
    "            def __init__(self, name=None):\n",
    "                super().__init__(name=name)\n",
    "                self.loss_fn = tf.keras.backend.ctc_batch_cost\n",
    "            def call(self, y_true, y_pred, input_length, label_length):\n",
    "                y_true_int = tf.cast(y_true, dtype=tf.int32)\n",
    "                input_length_int = tf.cast(input_length, dtype=tf.int32)\n",
    "                label_length_int = tf.cast(label_length, dtype=tf.int32)\n",
    "                loss = self.loss_fn(y_true=y_true_int, y_pred=y_pred, input_length=input_length_int, label_length=label_length_int)\n",
    "                self.add_loss(tf.reduce_mean(loss))\n",
    "                return y_pred\n",
    "\n",
    "        ctc_layer = CTCLayer(name='ctc_loss')(input_label, output, input_len, label_len)\n",
    "        model = models.Model(inputs=[input_img, input_label, input_len, label_len], outputs=ctc_layer)\n",
    "        model.compile(optimizer='adam', loss=None)\n",
    "        prediction_model = models.Model(inputs=input_img, outputs=output)\n",
    "        return model, prediction_model\n",
    "\n",
    "    ocr_model_train, ocr_model_predict = create_ocr_model_with_ctc(IMG_HEIGHT, IMG_WIDTH, num_chars)\n",
    "    ocr_model_train.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aaaf15",
   "metadata": {},
   "source": [
    "<H4># 5. Train and save model<H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "807e7978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "95/95 [==============================] - 8s 87ms/step - loss: inf - val_loss: inf\n",
      "Epoch 2/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 3/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 4/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 5/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 6/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 7/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 8/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 9/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 10/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 11/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 12/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 13/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 14/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 15/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 16/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 17/1000\n",
      "95/95 [==============================] - 8s 87ms/step - loss: inf - val_loss: inf\n",
      "Epoch 18/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 19/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 20/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 21/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 22/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 23/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 24/1000\n",
      "95/95 [==============================] - 8s 87ms/step - loss: inf - val_loss: inf\n",
      "Epoch 25/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 26/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 27/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 28/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 29/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 30/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 31/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 32/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 33/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 34/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 35/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 36/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 37/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 38/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 39/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 40/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 41/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 42/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 43/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 44/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 45/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 46/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 47/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 48/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 49/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 50/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 51/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 52/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 53/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 54/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 55/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 56/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 57/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 58/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 59/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 60/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 61/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 62/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 63/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 64/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 65/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 66/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 67/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 68/1000\n",
      "95/95 [==============================] - 9s 92ms/step - loss: inf - val_loss: inf\n",
      "Epoch 69/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 70/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 71/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 72/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 73/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 74/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 75/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 76/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 77/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 78/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 79/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 80/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 81/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 82/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 83/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 84/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 85/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 86/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 87/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 88/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 89/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 90/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 91/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 92/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 93/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 94/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 95/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 96/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 97/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 98/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 99/1000\n",
      "89/95 [===========================>..] - ETA: 0s - loss: inf\n",
      "Epoch 99: saving model to OCR_Model-0099.h5\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 100/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 101/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 102/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 103/1000\n",
      "95/95 [==============================] - 7s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 104/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 105/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 106/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 107/1000\n",
      "95/95 [==============================] - 7s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 108/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 109/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 110/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 111/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 112/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 113/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 114/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 115/1000\n",
      "95/95 [==============================] - 7s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 116/1000\n",
      "95/95 [==============================] - 7s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 117/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 118/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 119/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 120/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 121/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 122/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 123/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 124/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 125/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 126/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 127/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 128/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 129/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 130/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 131/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 132/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 133/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 134/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 135/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 136/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 137/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 138/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 139/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 140/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 141/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 142/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 143/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 144/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 145/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 146/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 147/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 148/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 149/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 150/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 151/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 152/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 153/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 154/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 155/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 156/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 157/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 158/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 159/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 160/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 161/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 162/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 163/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 164/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 165/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 166/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 167/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 168/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 169/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 170/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 171/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 172/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 173/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 174/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 175/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 176/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 177/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 178/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 179/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 180/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 181/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 182/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 183/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 184/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 185/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 186/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 187/1000\n",
      "95/95 [==============================] - 8s 87ms/step - loss: inf - val_loss: inf\n",
      "Epoch 188/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 189/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 190/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 191/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 192/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 193/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 194/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 195/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 196/1000\n",
      "95/95 [==============================] - 8s 87ms/step - loss: inf - val_loss: inf\n",
      "Epoch 197/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 198/1000\n",
      "84/95 [=========================>....] - ETA: 0s - loss: inf\n",
      "Epoch 198: saving model to OCR_Model-0198.h5\n",
      "95/95 [==============================] - 8s 87ms/step - loss: inf - val_loss: inf\n",
      "Epoch 199/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 200/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 201/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 202/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 203/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 204/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 205/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 206/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 207/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 208/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 209/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 210/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 211/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 212/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 213/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 214/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 215/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 216/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 217/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 218/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 219/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 220/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 221/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 222/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 223/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 224/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 225/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 226/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 227/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 228/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 229/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 230/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 231/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 232/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 233/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 234/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 235/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 236/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 237/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 238/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 239/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 240/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 241/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 242/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 243/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 244/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 245/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 246/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 247/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 248/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 249/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 250/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 251/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 252/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 253/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 254/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 255/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 256/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 257/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 258/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 259/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 260/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 261/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 262/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 263/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 264/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 265/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 266/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 267/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 268/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 269/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 270/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 271/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 272/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 273/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 274/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 275/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 276/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 277/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 278/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 279/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 280/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 281/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 282/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 283/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 284/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 285/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 286/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 287/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 288/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 289/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 290/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 291/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 292/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 293/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 294/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 295/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 296/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 297/1000\n",
      "79/95 [=======================>......] - ETA: 1s - loss: inf\n",
      "Epoch 297: saving model to OCR_Model-0297.h5\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 298/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 299/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 300/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 301/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 302/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 303/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 304/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 305/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 306/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 307/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 308/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 309/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 310/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 311/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 312/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 313/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 314/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 315/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 316/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 317/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 318/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 319/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 320/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 321/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 322/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 323/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 324/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 325/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 326/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 327/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 328/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 329/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 330/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 331/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 332/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 333/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 334/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 335/1000\n",
      "95/95 [==============================] - 8s 87ms/step - loss: inf - val_loss: inf\n",
      "Epoch 336/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 337/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 338/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 339/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 340/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 341/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 342/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 343/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 344/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 345/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 346/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 347/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 348/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 349/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 350/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 351/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 352/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 353/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 354/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 355/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 356/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 357/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 358/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 359/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 360/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 361/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 362/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 363/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 364/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 365/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 366/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 367/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 368/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 369/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 370/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 371/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 372/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 373/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 374/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 375/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 376/1000\n",
      "95/95 [==============================] - 7s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 377/1000\n",
      "95/95 [==============================] - 7s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 378/1000\n",
      "95/95 [==============================] - 7s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 379/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 380/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 381/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 382/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 383/1000\n",
      "95/95 [==============================] - 7s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 384/1000\n",
      "95/95 [==============================] - 7s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 385/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 386/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 387/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 388/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 389/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 390/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 391/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 392/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 393/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 394/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 395/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 396/1000\n",
      "74/95 [======================>.......] - ETA: 1s - loss: inf\n",
      "Epoch 396: saving model to OCR_Model-0396.h5\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 397/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 398/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 399/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 400/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 401/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 402/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 403/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 404/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 405/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 406/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 407/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 408/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 409/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 410/1000\n",
      "95/95 [==============================] - 7s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 411/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 412/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 413/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 414/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 415/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 416/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 417/1000\n",
      "95/95 [==============================] - 7s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 418/1000\n",
      "95/95 [==============================] - 7s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 419/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 420/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 421/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 422/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 423/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 424/1000\n",
      "95/95 [==============================] - 7s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 425/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 426/1000\n",
      "95/95 [==============================] - 7s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 427/1000\n",
      "95/95 [==============================] - 7s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 428/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 429/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 430/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 431/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 432/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 433/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 434/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 435/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 436/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 437/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 438/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 439/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 440/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 441/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 442/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 443/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 444/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 445/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 446/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 447/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 448/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 449/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 450/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 451/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 452/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 453/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 454/1000\n",
      "95/95 [==============================] - 8s 89ms/step - loss: inf - val_loss: inf\n",
      "Epoch 455/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 456/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 457/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 458/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 459/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 460/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 461/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 462/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 463/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 464/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 465/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 466/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 467/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 468/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 469/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 470/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 471/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 472/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 473/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 474/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 475/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 476/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 477/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 478/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 479/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 480/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 481/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 482/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 483/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 484/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 485/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 486/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 487/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 488/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 489/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 490/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 491/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 492/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 493/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 494/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 495/1000\n",
      "69/95 [====================>.........] - ETA: 1s - loss: inf\n",
      "Epoch 495: saving model to OCR_Model-0495.h5\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 496/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 497/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 498/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 499/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 500/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 501/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 502/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 503/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 504/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 505/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 506/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 507/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 508/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 509/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 510/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 511/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 512/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 513/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 514/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 515/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 516/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 517/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 518/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 519/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 520/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 521/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 522/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 523/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 524/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 525/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 526/1000\n",
      "95/95 [==============================] - 8s 89ms/step - loss: inf - val_loss: inf\n",
      "Epoch 527/1000\n",
      "95/95 [==============================] - 10s 107ms/step - loss: inf - val_loss: inf\n",
      "Epoch 528/1000\n",
      "95/95 [==============================] - 9s 95ms/step - loss: inf - val_loss: inf\n",
      "Epoch 529/1000\n",
      "95/95 [==============================] - 9s 91ms/step - loss: inf - val_loss: inf\n",
      "Epoch 530/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 531/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 532/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 533/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 534/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 535/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 536/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 537/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 538/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 539/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 540/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 541/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 542/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 543/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 544/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 545/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 546/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 547/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 548/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 549/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 550/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 551/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 552/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 553/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 554/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 555/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 556/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 557/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 558/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 559/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 560/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 561/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 562/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 563/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 564/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 565/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 566/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 567/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 568/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 569/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 570/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 571/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 572/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 573/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 574/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 575/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 576/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 577/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 578/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 579/1000\n",
      "95/95 [==============================] - 8s 87ms/step - loss: inf - val_loss: inf\n",
      "Epoch 580/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 581/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 582/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 583/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 584/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 585/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 586/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 587/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 588/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 589/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 590/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 591/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 592/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 593/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 594/1000\n",
      "64/95 [===================>..........] - ETA: 2s - loss: inf\n",
      "Epoch 594: saving model to OCR_Model-0594.h5\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 595/1000\n",
      "95/95 [==============================] - 8s 89ms/step - loss: inf - val_loss: inf\n",
      "Epoch 596/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 597/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 598/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 599/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 600/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 601/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 602/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 603/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 604/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 605/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 606/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 607/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 608/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 609/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 610/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 611/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 612/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 613/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 614/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 615/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 616/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 617/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 618/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 619/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 620/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 621/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 622/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 623/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 624/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 625/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 626/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 627/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 628/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 629/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 630/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 631/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 632/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 633/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 634/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 635/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 636/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 637/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 638/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 639/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 640/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 641/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 642/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 643/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 644/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 645/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 646/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 647/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 648/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 649/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 650/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 651/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 652/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 653/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 654/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 655/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 656/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 657/1000\n",
      "95/95 [==============================] - 9s 92ms/step - loss: inf - val_loss: inf\n",
      "Epoch 658/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 659/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 660/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 661/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 662/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 663/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 664/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 665/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 666/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 667/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 668/1000\n",
      "95/95 [==============================] - 8s 90ms/step - loss: inf - val_loss: inf\n",
      "Epoch 669/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 670/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 671/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 672/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 673/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 674/1000\n",
      "95/95 [==============================] - 8s 88ms/step - loss: inf - val_loss: inf\n",
      "Epoch 675/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 676/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 677/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 678/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 679/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 680/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 681/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 682/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 683/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 684/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 685/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 686/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 687/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 688/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 689/1000\n",
      "95/95 [==============================] - 8s 89ms/step - loss: inf - val_loss: inf\n",
      "Epoch 690/1000\n",
      "95/95 [==============================] - 8s 88ms/step - loss: inf - val_loss: inf\n",
      "Epoch 691/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 692/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 693/1000\n",
      "59/95 [=================>............] - ETA: 2s - loss: inf\n",
      "Epoch 693: saving model to OCR_Model-0693.h5\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 694/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 695/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 696/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 697/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 698/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 699/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 700/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 701/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 702/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 703/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 704/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 705/1000\n",
      "95/95 [==============================] - 8s 87ms/step - loss: inf - val_loss: inf\n",
      "Epoch 706/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 707/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 708/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 709/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 710/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 711/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 712/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 713/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 714/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 715/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 716/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 717/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 718/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 719/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 720/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 721/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 722/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 723/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 724/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 725/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 726/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 727/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 728/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 729/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 730/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 731/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 732/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 733/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 734/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 735/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 736/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 737/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 738/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 739/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 740/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 741/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 742/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 743/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 744/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 745/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 746/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 747/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 748/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 749/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 750/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 751/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 752/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 753/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 754/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 755/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 756/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 757/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 758/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 759/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 760/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 761/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 762/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 763/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 764/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 765/1000\n",
      "95/95 [==============================] - 7s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 766/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 767/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 768/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 769/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 770/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 771/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 772/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 773/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 774/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 775/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 776/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 777/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 778/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 779/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 780/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 781/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 782/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 783/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 784/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 785/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 786/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 787/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 788/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 789/1000\n",
      "95/95 [==============================] - 8s 89ms/step - loss: inf - val_loss: inf\n",
      "Epoch 790/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 791/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 792/1000\n",
      "54/95 [================>.............] - ETA: 2s - loss: inf\n",
      "Epoch 792: saving model to OCR_Model-0792.h5\n",
      "95/95 [==============================] - 8s 87ms/step - loss: inf - val_loss: inf\n",
      "Epoch 793/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 794/1000\n",
      "95/95 [==============================] - 8s 87ms/step - loss: inf - val_loss: inf\n",
      "Epoch 795/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 796/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 797/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 798/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 799/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 800/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 801/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 802/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 803/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 804/1000\n",
      "95/95 [==============================] - 8s 87ms/step - loss: inf - val_loss: inf\n",
      "Epoch 805/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 806/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 807/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 808/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 809/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 810/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 811/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 812/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 813/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 814/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 815/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 816/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 817/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 818/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 819/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 820/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 821/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 822/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 823/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 824/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 825/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 826/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 827/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 828/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 829/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 830/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 831/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 832/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 833/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 834/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 835/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 836/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 837/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 838/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 839/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 840/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 841/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 842/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 843/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 844/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 845/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 846/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 847/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 848/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 849/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 850/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 851/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 852/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 853/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 854/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 855/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 856/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 857/1000\n",
      "95/95 [==============================] - 8s 87ms/step - loss: inf - val_loss: inf\n",
      "Epoch 858/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 859/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 860/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 861/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 862/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 863/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 864/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 865/1000\n",
      "95/95 [==============================] - 8s 87ms/step - loss: inf - val_loss: inf\n",
      "Epoch 866/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 867/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 868/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 869/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 870/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 871/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 872/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 873/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 874/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 875/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 876/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 877/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 878/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 879/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 880/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 881/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 882/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 883/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 884/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 885/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 886/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 887/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 888/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 889/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 890/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 891/1000\n",
      "49/95 [==============>...............] - ETA: 3s - loss: inf\n",
      "Epoch 891: saving model to OCR_Model-0891.h5\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 892/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 893/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 894/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 895/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 896/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 897/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 898/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 899/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 900/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 901/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 902/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 903/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 904/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 905/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 906/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 907/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 908/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 909/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 910/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 911/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 912/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 913/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 914/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 915/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 916/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 917/1000\n",
      "95/95 [==============================] - 7s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 918/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 919/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 920/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 921/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 922/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 923/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 924/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 925/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 926/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 927/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 928/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 929/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 930/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 931/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 932/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 933/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 934/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 935/1000\n",
      "95/95 [==============================] - 8s 87ms/step - loss: inf - val_loss: inf\n",
      "Epoch 936/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 937/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 938/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 939/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 940/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 941/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 942/1000\n",
      "95/95 [==============================] - 8s 87ms/step - loss: inf - val_loss: inf\n",
      "Epoch 943/1000\n",
      "95/95 [==============================] - 8s 87ms/step - loss: inf - val_loss: inf\n",
      "Epoch 944/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 945/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 946/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 947/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 948/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 949/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 950/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 951/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 952/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 953/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 954/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 955/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 956/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 957/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 958/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 959/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 960/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 961/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 962/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 963/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 964/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 965/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 966/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 967/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 968/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 969/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 970/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 971/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 972/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 973/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 974/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 975/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 976/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 977/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 978/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 979/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 980/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 981/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 982/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 983/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 984/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 985/1000\n",
      "95/95 [==============================] - 7s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 986/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 987/1000\n",
      "95/95 [==============================] - 8s 83ms/step - loss: inf - val_loss: inf\n",
      "Epoch 988/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 989/1000\n",
      "95/95 [==============================] - 8s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 990/1000\n",
      "44/95 [============>.................] - ETA: 3s - loss: inf\n",
      "Epoch 990: saving model to OCR_Model-0990.h5\n",
      "95/95 [==============================] - 8s 87ms/step - loss: inf - val_loss: inf\n",
      "Epoch 991/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 992/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 993/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 994/1000\n",
      "95/95 [==============================] - 8s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 995/1000\n",
      "95/95 [==============================] - 8s 81ms/step - loss: inf - val_loss: inf\n",
      "Epoch 996/1000\n",
      "95/95 [==============================] - 8s 86ms/step - loss: inf - val_loss: inf\n",
      "Epoch 997/1000\n",
      "95/95 [==============================] - 8s 84ms/step - loss: inf - val_loss: inf\n",
      "Epoch 998/1000\n",
      "95/95 [==============================] - 8s 82ms/step - loss: inf - val_loss: inf\n",
      "Epoch 999/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 1000/1000\n",
      "95/95 [==============================] - 8s 80ms/step - loss: inf - val_loss: inf\n",
      "Model saved to :ocr_model_trained3.h5\n",
      "Model loaded from :ocr_model_trained3.h5\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"OCR_Model-{epoch:04d}.h5\",\n",
    "    save_freq=100 * (len(X_train_filtered) // BATCH_SIZE),  # Save every 100 epochs\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "if len(X) == 0:\n",
    "    print(\"Error: No data loaded. Cannot perform train_test_split.\")\n",
    "else:\n",
    "    if len(X_train_filtered) == 0:\n",
    "        print(\"No training data left after filtering. Skipping training.\")\n",
    "    else:\n",
    "        if(MODEL_TRAIN_FROM_SCRATCH==True):\n",
    "            history = ocr_model_train.fit(\n",
    "                x=[X_train_filtered, y_train_encoded_filtered, train_input_length_filtered, train_label_length_filtered],\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=EPOCH_SIZE,\n",
    "                validation_data=([X_test_filtered, y_test_encoded_filtered, test_input_length_filtered, test_label_length_filtered], None),\n",
    "                verbose=1,\n",
    "                callbacks=[checkpoint_cb],\n",
    "                shuffle=True\n",
    "            )\n",
    "            # Save the model            \n",
    "            ocr_model_train.save(TRAINED_MODEL_FILE_NAME)\n",
    "            ocr_model_train.save_weights(TRAINED_MODEL_FILE_NAME)  # Save the model weights\n",
    "            print(\"Model saved to :\" + TRAINED_MODEL_FILE_NAME)\n",
    "            # Load the prediction model separately            \n",
    "            ocr_model_predict.load_weights(TRAINED_MODEL_FILE_NAME)\n",
    "            print(\"Model loaded from :\" + TRAINED_MODEL_FILE_NAME) \n",
    "        else:\n",
    "            ocr_model_predict.load_weights(PRED_MODEL_FILE_NAME) \n",
    "            print(\"Model loaded from :\" + PRED_MODEL_FILE_NAME)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefcc881",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_model_train.save(TRAINED_MODEL_FILE_NAME)\n",
    "print(\"Model saved to :\" + TRAINED_MODEL_FILE_NAME)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0376a52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from :ocr_model_trained3.h5\n"
     ]
    }
   ],
   "source": [
    "ocr_model_train.load_weights(TRAINED_MODEL_FILE_NAME)\n",
    "print(\"Model loaded from :\" + TRAINED_MODEL_FILE_NAME)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d979a63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from :ocr_model_trained3.h5\n"
     ]
    }
   ],
   "source": [
    "ocr_model_predict.load_weights(TRAINED_MODEL_FILE_NAME) \n",
    "print(\"Model loaded from :\" + TRAINED_MODEL_FILE_NAME)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fea6852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from :ocr_model_pred2.h5\n"
     ]
    }
   ],
   "source": [
    "ocr_model_predict.load_weights(PRED_MODEL_FILE_NAME) \n",
    "print(\"Model loaded from :\" + PRED_MODEL_FILE_NAME)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d89ede3",
   "metadata": {},
   "source": [
    "<H4># Inference 1 for full dataset (excluding skipped images)<H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38840779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edd1cd6366b40478ff56ed3292eac47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "OCR on images:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 11s 11s/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- CTC DECODE ---\n",
    "def decode_prediction(pred, alphabet):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    results = tf.keras.backend.ctc_decode(pred, input_length=tf.cast(input_len, dtype=tf.int32), greedy=True)[0][0].numpy()\n",
    "    texts = []\n",
    "    for res in results:\n",
    "        text = ''.join([alphabet[i] for i in res if i >= 0 and i < len(alphabet)])\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "# --- OCR INFERENCE AND OUTPUT ---\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "ocr_results = []\n",
    "gt_results = []\n",
    "\n",
    "for img_file in notebook_tqdm(os.listdir(IMAGES_DIR), desc=\"OCR on images\"):\n",
    "    if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        continue\n",
    "    img_path = os.path.join(IMAGES_DIR, img_file)\n",
    "    base_filename = os.path.splitext(img_file)[0]\n",
    "    label_path = os.path.join(LABELS_DIR, base_filename + '.txt')\n",
    "    gt_txt_path = os.path.join(OCR_TXT_DIR, base_filename + '.json')\n",
    "    output_txt_path = os.path.join(OUTPUT_DIR, base_filename + '.txt')\n",
    "\n",
    "    bboxes = read_label_file(label_path)\n",
    "    gt_texts = read_gt_text(gt_txt_path)\n",
    "    if len(bboxes) != len(gt_texts) or not bboxes:\n",
    "        continue\n",
    "\n",
    "    img_crops = []\n",
    "    valid_gt_texts = []\n",
    "    for (_, bbox), gt_text in zip(bboxes, gt_texts):\n",
    "        crop = preprocess_img(img_path, bbox, IMG_HEIGHT, IMG_WIDTH)\n",
    "        if crop is not None:\n",
    "            img_crops.append(crop)\n",
    "            valid_gt_texts.append(gt_text)\n",
    "    if not img_crops:\n",
    "        continue\n",
    "\n",
    "    img_crops = np.array(img_crops)\n",
    "    preds = ocr_model_predict.predict(img_crops)\n",
    "    pred_texts = decode_prediction(preds, alphabet)\n",
    "\n",
    "    with open(output_txt_path, 'w', encoding='utf-8') as f:\n",
    "        for text in pred_texts:\n",
    "            f.write(text + '\\n')\n",
    "\n",
    "    ocr_results.extend(pred_texts)\n",
    "    gt_results.extend(valid_gt_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efcecb6",
   "metadata": {},
   "source": [
    "<H4># Metrics 1<H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44683f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR Line Accuracy: 0.6273\n",
      "OCR Character Accuracy: 0.5574\n"
     ]
    }
   ],
   "source": [
    "# --- METRICS ---\n",
    "\n",
    "min_len = min(len(ocr_results), len(gt_results))\n",
    "ocr_results = ocr_results[:min_len]\n",
    "gt_results = gt_results[:min_len]\n",
    "\n",
    "if ocr_results and gt_results:\n",
    "    line_acc = accuracy_score(gt_results, ocr_results)\n",
    "    def char_accuracy(y_true, y_pred):\n",
    "        correct_chars = 0\n",
    "        total_chars = 0\n",
    "        for t, p in zip(y_true, y_pred):\n",
    "            correct_chars += sum(a == b for a, b in zip(t, p))\n",
    "            total_chars += max(len(t), len(p))\n",
    "        return correct_chars / total_chars if total_chars > 0 else 1.0\n",
    "    char_acc = char_accuracy(gt_results, ocr_results)\n",
    "    print(f\"OCR Line Accuracy: {line_acc:.4f}\")\n",
    "    print(f\"OCR Character Accuracy: {char_acc:.4f}\")\n",
    "else:\n",
    "    print(\"No OCR results to compare.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bb2a55",
   "metadata": {},
   "source": [
    "<H4># Inference 2 for full dataset (excluding skipped images)<H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9881bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc69aaab1a0e46f5b634a010fb2e1ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "OCR on images:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "[1500] Elapsed: 0.31s | Avg mem: 7314.00MB | Avg time/doc: 0.0001s | Efficiency: 2.124173\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "\n",
    "# --- CTC DECODE ---\n",
    "def decode_prediction(pred, alphabet):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    results = tf.keras.backend.ctc_decode(pred, input_length=tf.cast(input_len, dtype=tf.int32), greedy=True)[0][0].numpy()\n",
    "    texts = []\n",
    "    for res in results:\n",
    "        text = ''.join([alphabet[i] for i in res if i >= 0 and i < len(alphabet)])\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "# --- OCR INFERENCE AND OUTPUT ---\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "ocr_results = []\n",
    "gt_results = []\n",
    "\n",
    "# Efficiency tracking variables\n",
    "process = psutil.Process()\n",
    "mem_usage_samples = []\n",
    "start_time = None\n",
    "\n",
    "for idx, img_file in enumerate(notebook_tqdm(os.listdir(IMAGES_DIR), desc=\"OCR on images\")):\n",
    "    if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        continue\n",
    "    img_path = os.path.join(IMAGES_DIR, img_file)\n",
    "    base_filename = os.path.splitext(img_file)[0]\n",
    "    label_path = os.path.join(LABELS_DIR, base_filename + '.txt')\n",
    "    gt_txt_path = os.path.join(OCR_TXT_DIR, base_filename + '.json')\n",
    "    output_txt_path = os.path.join(OUTPUT_DIR, base_filename + '.txt')\n",
    "\n",
    "    bboxes = read_label_file(label_path)\n",
    "    gt_texts = read_gt_text(gt_txt_path)\n",
    "    if len(bboxes) != len(gt_texts) or not bboxes:\n",
    "        continue\n",
    "\n",
    "    # Start timing and memory tracking before prediction for each image\n",
    "    start_time = time.time()\n",
    "    mem_usage_samples = []\n",
    "\n",
    "    img_crops = []\n",
    "    valid_gt_texts = []\n",
    "    for (_, bbox), gt_text in zip(bboxes, gt_texts):\n",
    "        crop = preprocess_img(img_path, bbox, IMG_HEIGHT, IMG_WIDTH)\n",
    "        if crop is not None:\n",
    "            img_crops.append(crop)\n",
    "            valid_gt_texts.append(gt_text)\n",
    "    if not img_crops:\n",
    "        continue\n",
    "\n",
    "    img_crops = np.array(img_crops)\n",
    "    preds = ocr_model_predict.predict(img_crops)\n",
    "    pred_texts = decode_prediction(preds, alphabet)\n",
    "\n",
    "    with open(output_txt_path, 'w', encoding='utf-8') as f:\n",
    "        for text in pred_texts:\n",
    "            f.write(text + '\\n')\n",
    "\n",
    "    ocr_results.extend(pred_texts)\n",
    "    gt_results.extend(valid_gt_texts)\n",
    "\n",
    "    # Update memory usage after each prediction\n",
    "    mem_usage_samples.append(process.memory_info().rss / (1024 * 1024))  # MB\n",
    "\n",
    "    # Efficiency metrics after each image\n",
    "    elapsed_time = time.time() - start_time if start_time else 0.0\n",
    "\n",
    "num_preds = len(ocr_results)\n",
    "avg_time_per_doc = (elapsed_time / num_preds) if num_preds > 0 else 1.0\n",
    "avg_mem_mb = np.mean(mem_usage_samples) if mem_usage_samples else 1.0\n",
    "\n",
    "# Compute efficiency: 1 / ((avg processing time per doc in sec) * (avg memory usage in MB))\n",
    "compute_efficiency = 1 / (avg_time_per_doc * avg_mem_mb) if avg_mem_mb > 0 else 0.0\n",
    "\n",
    "print(f\"[{idx+1}] Elapsed: {elapsed_time:.2f}s | Avg mem: {avg_mem_mb:.2f}MB | Avg time/doc: {avg_time_per_doc:.4f}s | Efficiency: {compute_efficiency:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09715572",
   "metadata": {},
   "source": [
    "<H4># Metrics 2<H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4630be7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OCR Model Metrics:\n",
      "Word Error Rate (WER): 0.4804\n",
      "Character Error Rate (CER): 0.3662\n",
      "Field Accuracy: 0.6273\n",
      "Document Level Accuracy: 0.0000\n",
      "Final Score: 40.4633\n",
      "Compute Efficiency: 2.124173 (1/(sec*MB))\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "\n",
    "# --- METRICS & EFFICIENCY ---\n",
    "def levenshtein_distance(s1, s2):\n",
    "    if isinstance(s1, str):\n",
    "        s1 = list(s1)\n",
    "    if isinstance(s2, str):\n",
    "        s2 = list(s2)\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n",
    "\n",
    "def word_error_rate(y_true, y_pred):\n",
    "    total_words = 0\n",
    "    total_errors = 0\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        t_words = t.split()\n",
    "        p_words = p.split()\n",
    "        total_words += len(t_words)\n",
    "        total_errors += levenshtein_distance(t_words, p_words)\n",
    "    return total_errors / total_words if total_words > 0 else 0.0\n",
    "\n",
    "def char_error_rate(y_true, y_pred):\n",
    "    total_chars = 0\n",
    "    total_errors = 0\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        total_chars += len(t)\n",
    "        total_errors += levenshtein_distance(t, p)\n",
    "    return total_errors / total_chars if total_chars > 0 else 0.0\n",
    "\n",
    "def field_accuracy(y_true, y_pred):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "def document_level_accuracy(y_true, y_pred, doc_ids):\n",
    "    from collections import defaultdict\n",
    "    doc_true = defaultdict(list)\n",
    "    doc_pred = defaultdict(list)\n",
    "    for doc_id, t, p in zip(doc_ids, y_true, y_pred):\n",
    "        doc_true[doc_id].append(t)\n",
    "        doc_pred[doc_id].append(p)\n",
    "    correct_docs = 0\n",
    "    for doc_id in doc_true:\n",
    "        if doc_true[doc_id] == doc_pred[doc_id]:\n",
    "            correct_docs += 1\n",
    "    return correct_docs / len(doc_true) if doc_true else 0.0\n",
    "\n",
    "min_len = min(len(ocr_results), len(gt_results))\n",
    "ocr_results = ocr_results[:min_len]\n",
    "gt_results = gt_results[:min_len]\n",
    "\n",
    "# Build doc_ids as the image file name for each field\n",
    "# You must collect doc_ids in the same order as ocr_results/gt_results\n",
    "doc_ids = []\n",
    "for img_file in os.listdir(IMAGES_DIR):\n",
    "    if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        continue\n",
    "    base_filename = os.path.splitext(img_file)[0]\n",
    "    label_path = os.path.join(LABELS_DIR, base_filename + '.txt')\n",
    "    gt_txt_path = os.path.join(OCR_TXT_DIR, base_filename + '.json')\n",
    "    if not os.path.exists(label_path) or not os.path.exists(gt_txt_path):\n",
    "        continue\n",
    "    bboxes = read_label_file(label_path)\n",
    "    gt_texts_file = read_gt_text(gt_txt_path)\n",
    "    if len(bboxes) != len(gt_texts_file) or not bboxes:\n",
    "        continue\n",
    "    for _ in range(len(bboxes)):\n",
    "        doc_ids.append(base_filename)\n",
    "\n",
    "# Truncate doc_ids to match ocr_results length\n",
    "doc_ids = doc_ids[:min_len]\n",
    "\n",
    "if not ocr_results or not gt_results:\n",
    "    print(\"\\nNo samples available to compute metrics.\")\n",
    "else:\n",
    "    # Metrics\n",
    "    wer = word_error_rate(gt_results, ocr_results)\n",
    "    cer = char_error_rate(gt_results, ocr_results)\n",
    "    field_acc = field_accuracy(gt_results, ocr_results)\n",
    "    doc_acc = document_level_accuracy(gt_results, ocr_results, doc_ids)    \n",
    "    \n",
    "    # Final Score\n",
    "    final_score = (\n",
    "        0.35 * (100 - wer * 100) +\n",
    "        0.35 * (100 - cer * 100) +\n",
    "        0.15 * field_acc +\n",
    "        0.15 * doc_acc\n",
    "    )\n",
    "\n",
    "    print(f\"\\nOCR Model Metrics:\")\n",
    "    print(f\"Word Error Rate (WER): {wer:.4f}\")\n",
    "    print(f\"Character Error Rate (CER): {cer:.4f}\")\n",
    "    print(f\"Field Accuracy: {field_acc:.4f}\")\n",
    "    print(f\"Document Level Accuracy: {doc_acc:.4f}\")\n",
    "    print(f\"Final Score: {final_score:.4f}\")\n",
    "    print(f\"Compute Efficiency: {compute_efficiency:.6f} (1/(sec*MB))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c13b6",
   "metadata": {},
   "source": [
    "<H4># Inference 3 for full dataset (including skipped images)<H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383ced38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcef85654e294696ba97a643e6af2237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "OCR on images:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MIT_1.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Processing MIT_10.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_102.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_103.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_104.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_105.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_106.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_108.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_109.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_11.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Processing MIT_110.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing MIT_111.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_112.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_113.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "Processing MIT_114.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_115.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_116.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_117.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_118.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_12.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_120.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_121.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "Processing MIT_122.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing MIT_125.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_126.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_127.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_128.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_129.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_130.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_131.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_132.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing MIT_134.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_137.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_138.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_139.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Processing MIT_14.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_141.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_142.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_143.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_145.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_147.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "Processing MIT_148.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_149.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing MIT_15.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_150.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_151.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_154.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_155.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_156.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_159.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing MIT_16.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "Processing MIT_160.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_162.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_163.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_164.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_165.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_166.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_167.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_168.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_169.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_17.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_170.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_171.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_172.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_173.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_174.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing MIT_175.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_176.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_177.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_178.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_179.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_18.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_180.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_181.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_182.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_183.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_184.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_185.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_186.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_187.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_188.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_189.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_19.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_190.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_192.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_193.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_194.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_195.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_196.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_197.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_199.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_2.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_20.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_200.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_202.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_203.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_204.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_205.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_206.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_207.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_209.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_21.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_210.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_211.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_213.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing MIT_215.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_217.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_218.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Processing MIT_22.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_220.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_221.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_222.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_223.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_224.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Processing MIT_225.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_226.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "Processing MIT_227.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing MIT_228.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "Processing MIT_229.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_23.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Processing MIT_230.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_231.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "Processing MIT_232.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing MIT_234.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_235.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Processing MIT_236.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing MIT_237.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_238.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_24.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_240.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_241.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_242.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_243.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_244.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing MIT_246.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_248.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_249.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_25.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_251.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_252.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_253.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_254.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_255.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_256.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_257.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_258.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_259.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_26.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_260.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_261.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_262.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_264.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_265.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_266.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_268.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_269.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_27.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_271.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_272.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing MIT_273.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_274.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_275.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_277.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_278.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_28.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_281.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_282.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_283.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_284.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_285.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_286.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_288.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_29.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Processing MIT_290.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_291.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_293.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing MIT_294.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing MIT_295.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_296.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_298.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_299.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_3.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_30.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_300.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_301.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_302.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_303.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_304.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_305.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing MIT_306.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_307.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_308.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_309.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_31.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_310.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing MIT_311.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_313.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_314.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing MIT_315.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_316.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_317.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_318.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_32.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_320.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_322.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_323.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "Processing MIT_324.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_326.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_327.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_328.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_329.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_33.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_330.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_331.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_332.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing MIT_334.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_336.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_337.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_338.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_339.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_34.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_340.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_341.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_343.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_344.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_345.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_346.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing MIT_348.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing MIT_349.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Processing MIT_35.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_350.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_351.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Processing MIT_352.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing MIT_353.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing MIT_354.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_355.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_356.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_357.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_358.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_359.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing MIT_36.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_360.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_361.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing MIT_363.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_364.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_365.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_366.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_368.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_369.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_37.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_370.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_373.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_375.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing MIT_376.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_377.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Processing MIT_378.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_379.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Processing MIT_38.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "Processing MIT_380.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_381.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_382.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_383.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "Processing MIT_384.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "Processing MIT_387.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing MIT_388.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing MIT_389.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing MIT_39.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Processing MIT_392.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing MIT_393.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Processing MIT_395.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Processing MIT_396.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Processing MIT_397.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Processing MIT_398.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Processing MIT_399.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Processing MIT_4.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "Processing MIT_40.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "Processing MIT_400.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "Processing MIT_401.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_402.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_403.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Processing MIT_404.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_405.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_406.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing MIT_407.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_408.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_409.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "Processing MIT_41.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_410.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_412.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_415.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing MIT_416.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_417.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_42.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Processing MIT_420.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_422.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_424.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_425.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_426.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "Processing MIT_427.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "Processing MIT_428.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_429.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "Processing MIT_43.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_431.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_433.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_434.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_435.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_436.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing MIT_438.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_439.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Processing MIT_44.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_440.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_442.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing MIT_443.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_444.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_445.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_446.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_447.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing MIT_448.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_449.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_45.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_450.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_452.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_453.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "Processing MIT_454.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_455.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "Processing MIT_456.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_457.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_458.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_459.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_46.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_460.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_462.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_463.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_464.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "Processing MIT_466.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_467.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing MIT_468.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_469.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing MIT_471.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_472.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_473.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_474.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_475.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_477.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_478.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_479.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_48.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_480.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_481.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_482.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_483.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_484.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "Processing MIT_485.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing MIT_486.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_487.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_488.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_489.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_49.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_490.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_491.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing MIT_492.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing MIT_493.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_494.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_496.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_498.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "Processing MIT_499.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing MIT_5.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_50.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_500.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_501.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_502.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_503.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing MIT_504.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_506.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_507.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Processing MIT_508.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_509.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_510.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_511.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_512.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Processing MIT_513.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_514.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "Processing MIT_516.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_517.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_519.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_52.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_520.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_521.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing MIT_522.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_523.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "Processing MIT_524.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_525.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_526.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_527.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_528.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_529.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_530.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_531.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing MIT_532.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_533.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing MIT_536.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_538.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_539.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_54.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_540.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_541.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Processing MIT_542.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_543.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Processing MIT_544.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_545.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_546.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing MIT_547.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_548.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_549.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_55.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_550.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_551.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing MIT_552.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_553.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_554.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_555.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "Processing MIT_556.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_557.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_559.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_56.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_560.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_561.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_562.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_563.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_564.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_565.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "Processing MIT_566.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_567.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "Processing MIT_568.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_569.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Processing MIT_57.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing MIT_570.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing MIT_571.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_572.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_575.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing MIT_576.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_577.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_578.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_58.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing MIT_580.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_581.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_582.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_583.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_584.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_586.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Processing MIT_587.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_588.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Processing MIT_589.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_59.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Processing MIT_590.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_591.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing MIT_593.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing MIT_594.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_595.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing MIT_596.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_597.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_599.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_6.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_60.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_600.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "Processing MIT_601.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing MIT_602.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing MIT_603.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_604.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_605.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_606.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_607.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_608.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_609.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_61.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_610.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_613.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_615.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_616.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Processing MIT_617.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_618.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "Processing MIT_619.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_62.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing MIT_620.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_621.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_622.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_623.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_624.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_625.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_628.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_629.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_63.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_630.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_631.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_634.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_635.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "Processing MIT_636.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_64.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_640.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_641.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing MIT_642.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_643.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_645.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_646.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_647.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_648.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_649.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_65.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_650.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Processing MIT_651.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing MIT_652.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_654.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_655.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing MIT_657.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_659.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_66.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_660.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_661.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_662.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing MIT_663.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing MIT_664.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing MIT_665.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Processing MIT_666.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_667.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing MIT_668.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_67.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_670.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_671.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_672.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Processing MIT_673.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_674.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_675.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "Processing MIT_676.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_677.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_679.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing MIT_68.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_681.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_682.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_683.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_685.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_686.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_687.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_688.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_689.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_69.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing MIT_690.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing MIT_692.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_693.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_694.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_695.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_696.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_697.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_698.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_699.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_7.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "Processing MIT_70.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_700.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_72.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Processing MIT_73.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing MIT_74.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_75.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing MIT_77.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_8.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Processing MIT_80.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_81.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_82.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_84.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing MIT_85.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_86.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing MIT_87.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_89.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing MIT_9.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing MIT_90.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing MIT_92.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing MIT_93.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_94.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing MIT_95.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing MIT_96.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing MIT_97.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing MIT_98.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing MIT_99.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1001.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1002.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "Processing TCE_1003.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing TCE_1004.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "Processing TCE_1005.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing TCE_1006.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1007.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1008.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1009.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1010.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1011.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing TCE_1012.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1013.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1014.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Processing TCE_1015.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing TCE_1017.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1019.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1021.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1022.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1023.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1024.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1025.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "Processing TCE_1027.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1028.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1030.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1032.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1033.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1036.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing TCE_1041.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1042.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1044.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Processing TCE_1048.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1049.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1050.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing TCE_1051.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1052.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1054.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1055.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1056.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1057.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1058.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing TCE_1059.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing TCE_1060.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1061.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1062.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Processing TCE_1063.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "Processing TCE_1064.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Processing TCE_1065.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1066.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1067.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1068.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Processing TCE_1069.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "Processing TCE_1070.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1072.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1073.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1074.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing TCE_1075.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1076.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1077.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1078.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1079.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1080.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Processing TCE_1081.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1082.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Processing TCE_1083.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1086.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1087.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "Processing TCE_1088.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing TCE_1089.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1090.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1093.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1096.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Processing TCE_1097.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1098.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1099.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1100.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1101.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1103.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1104.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1106.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "Processing TCE_1107.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "Processing TCE_1109.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing TCE_1110.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1111.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1112.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing TCE_1113.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1114.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1115.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing TCE_1116.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1117.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1119.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1120.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1122.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1123.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1125.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1126.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Processing TCE_1128.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1129.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "Processing TCE_1130.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1132.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1133.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Processing TCE_1136.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1137.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1139.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "Processing TCE_1140.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Processing TCE_1141.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1142.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1143.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing TCE_1144.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1145.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1146.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1147.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1148.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1149.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1150.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1151.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "Processing TCE_1152.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1153.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1154.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1155.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing TCE_1156.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1157.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1158.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing TCE_1159.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1160.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing TCE_1161.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing TCE_1162.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1163.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1164.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1165.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "Processing TCE_1166.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1170.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1171.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing TCE_1172.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing TCE_1173.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1174.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1175.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1176.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1177.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "Processing TCE_1178.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1179.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1180.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1181.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing TCE_1182.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1183.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1184.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing TCE_1185.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1186.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1187.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1188.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing TCE_1189.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1190.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1191.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1193.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1194.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing TCE_1195.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1196.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1197.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1198.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1199.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "Processing TCE_1201.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1202.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1203.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1205.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing TCE_1206.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing TCE_1212.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1219.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1220.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing TCE_1221.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing TCE_1222.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1223.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1224.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing TCE_1225.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1226.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing TCE_1228.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Processing TCE_1229.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1230.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1231.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1232.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1233.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing TCE_1235.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1236.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1237.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Processing TCE_1238.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1239.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing TCE_1240.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1241.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1242.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1244.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing TCE_1245.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1246.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1247.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1248.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing TCE_1249.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1250.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1251.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "Processing TCE_1252.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1253.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1254.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1255.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1256.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1257.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1258.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Processing TCE_1259.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1260.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1261.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing TCE_1262.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1263.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1264.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1265.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Processing TCE_1266.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1267.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1268.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1269.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1270.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1271.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1272.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Processing TCE_1273.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1275.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing TCE_1276.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1277.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1279.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "Processing TCE_1280.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1281.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1282.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing TCE_1283.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing TCE_1284.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1285.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing TCE_1286.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Processing TCE_1287.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1288.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1289.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1290.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1291.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "Processing TCE_1292.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1293.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing TCE_1294.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1295.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1296.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing TCE_1297.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1298.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Processing TCE_1299.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1300.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1301.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1302.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1303.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1304.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing TCE_1305.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1307.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "Processing TCE_1308.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1309.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1310.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "Processing TCE_1311.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1312.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1313.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Processing TCE_1314.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1315.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1316.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1317.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "Processing TCE_1318.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1319.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1320.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1321.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1322.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing TCE_1323.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Processing TCE_1325.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1327.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing TCE_1328.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1329.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "Processing TCE_1330.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1331.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "Processing TCE_1332.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1333.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing TCE_1334.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing TCE_1335.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1337.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing TCE_1338.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "Processing TCE_1339.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing TCE_1340.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1341.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1342.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1343.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1344.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1346.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing TCE_1347.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Processing TCE_1348.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "Processing TCE_1349.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1351.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1352.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1353.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1354.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "Processing TCE_1355.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1356.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "Processing TCE_1357.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1358.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1359.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1360.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1361.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing TCE_1362.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1363.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1365.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1366.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1367.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1369.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing TCE_1370.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1371.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1372.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1373.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing TCE_1375.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Processing TCE_1377.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1380.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1381.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1382.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1383.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "Processing TCE_1384.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "Processing TCE_1385.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1387.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1388.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1389.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Processing TCE_1390.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1391.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "Processing TCE_1392.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1393.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1394.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1395.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1398.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1400.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing TCE_1401.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1402.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1403.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1405.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1406.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1407.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing TCE_1408.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1409.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1412.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1413.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "Processing TCE_1414.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1415.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing TCE_1416.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1419.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Processing TCE_1420.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1422.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1423.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing TCE_1424.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1425.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1427.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1429.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing TCE_1430.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1431.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "Processing TCE_1432.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing TCE_1433.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1435.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1436.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1437.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1438.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1440.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1441.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1442.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1443.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing TCE_1444.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1445.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1447.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1448.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1449.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1450.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "Processing TCE_1451.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1452.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1454.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1455.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1456.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1457.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1458.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1460.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1461.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1462.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "Processing TCE_1463.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1464.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1465.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1469.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1471.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1472.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1473.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "Processing TCE_1475.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1476.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1477.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1478.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1480.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing TCE_1482.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1483.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "Processing TCE_1484.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1485.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing TCE_1487.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing TCE_1489.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing TCE_1490.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "Processing TCE_1491.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1492.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "Processing TCE_1493.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing TCE_1494.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing TCE_1495.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing TCE_1496.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing TCE_1499.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing TCE_1500.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing VIT_1000.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing VIT_701.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing VIT_702.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_703.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_704.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_705.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_706.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_707.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_708.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_709.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_710.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing VIT_711.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_712.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing VIT_713.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_714.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_715.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_716.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing VIT_717.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_718.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing VIT_719.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing VIT_720.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing VIT_721.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing VIT_722.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Processing VIT_723.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_724.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "Processing VIT_725.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_726.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_727.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_728.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing VIT_729.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing VIT_730.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing VIT_731.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "Processing VIT_732.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_733.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "Processing VIT_734.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing VIT_735.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "Processing VIT_736.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing VIT_737.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "Processing VIT_738.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_739.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing VIT_740.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_741.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_742.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_743.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing VIT_744.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing VIT_745.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing VIT_746.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing VIT_747.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing VIT_748.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_749.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_750.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing VIT_751.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_752.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing VIT_753.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing VIT_754.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "Processing VIT_755.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_756.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "Processing VIT_757.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_758.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "Processing VIT_759.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_760.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_761.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_762.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_763.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing VIT_764.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_765.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing VIT_768.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_770.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_771.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_772.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_773.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_774.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_775.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_776.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_777.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Processing VIT_778.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_779.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing VIT_780.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing VIT_781.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Processing VIT_782.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing VIT_783.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "Processing VIT_784.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing VIT_785.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "Processing VIT_786.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_787.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_788.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_789.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing VIT_790.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_791.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_792.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_793.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing VIT_794.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_795.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "Processing VIT_796.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing VIT_797.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_798.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing VIT_799.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_800.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing VIT_801.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing VIT_802.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing VIT_803.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_804.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_805.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "Processing VIT_806.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_807.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Processing VIT_808.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_809.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "Processing VIT_810.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_811.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "Processing VIT_812.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_813.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "Processing VIT_814.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing VIT_815.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Processing VIT_816.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_817.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_818.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing VIT_819.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_820.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing VIT_821.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing VIT_822.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_823.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing VIT_824.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_825.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing VIT_826.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing VIT_827.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing VIT_828.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_829.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing VIT_830.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_831.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing VIT_832.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing VIT_833.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_835.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_836.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "Processing VIT_837.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing VIT_838.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "Processing VIT_839.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing VIT_840.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_841.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_842.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_843.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_844.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing VIT_846.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_847.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_848.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_850.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing VIT_851.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing VIT_852.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing VIT_853.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing VIT_854.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_855.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_856.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing VIT_857.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "Processing VIT_858.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing VIT_859.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_860.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_861.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing VIT_862.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing VIT_863.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_864.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_865.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing VIT_866.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing VIT_868.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_869.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_870.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_871.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_872.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing VIT_873.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_874.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_875.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_876.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "Processing VIT_877.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing VIT_878.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing VIT_879.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_880.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing VIT_881.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing VIT_882.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_883.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_884.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing VIT_885.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_886.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing VIT_887.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing VIT_888.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_889.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_891.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "Processing VIT_892.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_893.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing VIT_895.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Processing VIT_896.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_897.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_898.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_899.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing VIT_900.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_901.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_902.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_903.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_905.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_906.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "Processing VIT_907.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing VIT_908.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Processing VIT_910.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_912.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_913.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_914.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_916.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing VIT_917.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_918.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_919.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_920.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_921.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Processing VIT_922.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing VIT_923.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "Processing VIT_924.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_925.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "Processing VIT_926.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing VIT_927.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing VIT_928.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing VIT_929.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing VIT_930.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_931.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_933.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing VIT_934.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_935.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing VIT_936.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "Processing VIT_937.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_938.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "Processing VIT_939.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing VIT_940.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_941.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Processing VIT_942.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_943.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Processing VIT_944.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_945.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_947.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Processing VIT_948.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_949.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Processing VIT_950.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_951.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "Processing VIT_954.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_955.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_956.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_957.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_958.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_959.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Processing VIT_960.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "Processing VIT_961.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_962.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_965.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_966.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_967.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_970.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Processing VIT_971.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_972.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_974.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing VIT_975.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Processing VIT_977.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Processing VIT_978.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Processing VIT_980.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_981.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_983.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Processing VIT_984.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Processing VIT_985.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "Processing VIT_986.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing VIT_987.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "Processing VIT_988.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_989.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Processing VIT_992.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Processing VIT_993.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_994.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Processing VIT_995.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Processing VIT_997.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Processing VIT_999.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "[1500] Elapsed: 0.44s | Avg mem: 2341.17MB | Avg time/doc: 0.0000s | Efficiency: 28.513292\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "\n",
    "# --- CTC DECODE ---\n",
    "def decode_prediction(pred, alphabet):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    results = tf.keras.backend.ctc_decode(pred, input_length=tf.cast(input_len, dtype=tf.int32), greedy=True)[0][0].numpy()\n",
    "    texts = []\n",
    "    for res in results:\n",
    "        text = ''.join([alphabet[i] for i in res if i >= 0 and i < len(alphabet)])\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "# --- OCR INFERENCE AND OUTPUT ---\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "ocr_results = []\n",
    "gt_results = []\n",
    "\n",
    "# Efficiency tracking variables\n",
    "process = psutil.Process()\n",
    "mem_usage_samples = []\n",
    "start_time = None\n",
    "\n",
    "for idx, img_file in enumerate(notebook_tqdm(os.listdir(IMAGES_DIR), desc=\"OCR on images\")):\n",
    "    if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        continue\n",
    "    img_path = os.path.join(IMAGES_DIR, img_file)\n",
    "    base_filename = os.path.splitext(img_file)[0]\n",
    "    label_path = os.path.join(LABELS_DIR, base_filename + '.txt')\n",
    "    gt_txt_path = os.path.join(OCR_TXT_DIR, base_filename + '.json')\n",
    "    output_txt_path = os.path.join(OUTPUT_DIR, base_filename + '.txt')\n",
    "\n",
    "    bboxes = read_label_file(label_path)\n",
    "    gt_texts = read_gt_text(gt_txt_path)\n",
    "    if len(bboxes) != len(gt_texts) or not bboxes:\n",
    "        print(f\"Processing {img_file}: Mismatch between number of bounding boxes and ground truth texts\")        \n",
    "\n",
    "    # Start timing and memory tracking before prediction for each image\n",
    "    start_time = time.time()\n",
    "    mem_usage_samples = []\n",
    "\n",
    "    img_crops = []\n",
    "    valid_gt_texts = []\n",
    "    for (_, bbox), gt_text in zip(bboxes, gt_texts):\n",
    "        crop = preprocess_img(img_path, bbox, IMG_HEIGHT, IMG_WIDTH)\n",
    "        if crop is not None:\n",
    "            img_crops.append(crop)\n",
    "            valid_gt_texts.append(gt_text)\n",
    "    if not img_crops:\n",
    "        continue\n",
    "\n",
    "    img_crops = np.array(img_crops)\n",
    "    preds = ocr_model_predict.predict(img_crops)\n",
    "    pred_texts = decode_prediction(preds, alphabet)\n",
    "\n",
    "    with open(output_txt_path, 'w', encoding='utf-8') as f:\n",
    "        for text in pred_texts:\n",
    "            f.write(text + '\\n')\n",
    "\n",
    "    ocr_results.extend(pred_texts)\n",
    "    gt_results.extend(valid_gt_texts)\n",
    "\n",
    "    # Update memory usage after each prediction\n",
    "    mem_usage_samples.append(process.memory_info().rss / (1024 * 1024))  # MB\n",
    "\n",
    "    # Efficiency metrics after each image\n",
    "    elapsed_time = time.time() - start_time if start_time else 0.0\n",
    "\n",
    "num_preds = len(ocr_results)\n",
    "avg_time_per_doc = (elapsed_time / num_preds) if num_preds > 0 else 1.0\n",
    "avg_mem_mb = np.mean(mem_usage_samples) if mem_usage_samples else 1.0\n",
    "\n",
    "# Compute efficiency: 1 / ((avg processing time per doc in sec) * (avg memory usage in MB))\n",
    "compute_efficiency = 1 / (avg_time_per_doc * avg_mem_mb) if avg_mem_mb > 0 else 0.0\n",
    "\n",
    "print(f\"[{idx+1}] Elapsed: {elapsed_time:.2f}s | Avg mem: {avg_mem_mb:.2f}MB | Avg time/doc: {avg_time_per_doc:.4f}s | Efficiency: {compute_efficiency:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89f8337",
   "metadata": {},
   "source": [
    "<H4># Metrics 3<H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3d83936e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OCR Model Metrics:\n",
      "Word Error Rate (WER): 1.0680\n",
      "Character Error Rate (CER): 0.8546\n",
      "Field Accuracy: 0.1281\n",
      "Document Level Accuracy: 0.0000\n",
      "Final Score: 2.7273\n",
      "Compute Efficiency: 28.513292 (1/(sec*MB))\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "\n",
    "# --- METRICS & EFFICIENCY ---\n",
    "def levenshtein_distance(s1, s2):\n",
    "    if isinstance(s1, str):\n",
    "        s1 = list(s1)\n",
    "    if isinstance(s2, str):\n",
    "        s2 = list(s2)\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n",
    "\n",
    "def word_error_rate(y_true, y_pred):\n",
    "    total_words = 0\n",
    "    total_errors = 0\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        t_words = t.split()\n",
    "        p_words = p.split()\n",
    "        total_words += len(t_words)\n",
    "        total_errors += levenshtein_distance(t_words, p_words)\n",
    "    return total_errors / total_words if total_words > 0 else 0.0\n",
    "\n",
    "def char_error_rate(y_true, y_pred):\n",
    "    total_chars = 0\n",
    "    total_errors = 0\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        total_chars += len(t)\n",
    "        total_errors += levenshtein_distance(t, p)\n",
    "    return total_errors / total_chars if total_chars > 0 else 0.0\n",
    "\n",
    "def field_accuracy(y_true, y_pred):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "def document_level_accuracy(y_true, y_pred, doc_ids):\n",
    "    from collections import defaultdict\n",
    "    doc_true = defaultdict(list)\n",
    "    doc_pred = defaultdict(list)\n",
    "    for doc_id, t, p in zip(doc_ids, y_true, y_pred):\n",
    "        doc_true[doc_id].append(t)\n",
    "        doc_pred[doc_id].append(p)\n",
    "    correct_docs = 0\n",
    "    for doc_id in doc_true:\n",
    "        if doc_true[doc_id] == doc_pred[doc_id]:\n",
    "            correct_docs += 1\n",
    "    return correct_docs / len(doc_true) if doc_true else 0.0\n",
    "\n",
    "min_len = min(len(ocr_results), len(gt_results))\n",
    "ocr_results = ocr_results[:min_len]\n",
    "gt_results = gt_results[:min_len]\n",
    "\n",
    "# Build doc_ids as the image file name for each field\n",
    "# You must collect doc_ids in the same order as ocr_results/gt_results\n",
    "doc_ids = []\n",
    "for img_file in os.listdir(IMAGES_DIR):\n",
    "    if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        continue\n",
    "    base_filename = os.path.splitext(img_file)[0]\n",
    "    label_path = os.path.join(LABELS_DIR, base_filename + '.txt')\n",
    "    gt_txt_path = os.path.join(OCR_TXT_DIR, base_filename + '.json')\n",
    "    if not os.path.exists(label_path) or not os.path.exists(gt_txt_path):\n",
    "        continue\n",
    "    bboxes = read_label_file(label_path)\n",
    "    gt_texts_file = read_gt_text(gt_txt_path)\n",
    "    if len(bboxes) != len(gt_texts_file) or not bboxes:\n",
    "        continue\n",
    "    for _ in range(len(bboxes)):\n",
    "        doc_ids.append(base_filename)\n",
    "\n",
    "# Truncate doc_ids to match ocr_results length\n",
    "doc_ids = doc_ids[:min_len]\n",
    "\n",
    "if not ocr_results or not gt_results:\n",
    "    print(\"\\nNo samples available to compute metrics.\")\n",
    "else:\n",
    "    # Metrics\n",
    "    wer = word_error_rate(gt_results, ocr_results)\n",
    "    cer = char_error_rate(gt_results, ocr_results)\n",
    "    field_acc = field_accuracy(gt_results, ocr_results)\n",
    "    doc_acc = document_level_accuracy(gt_results, ocr_results, doc_ids)    \n",
    "    \n",
    "    # Final Score\n",
    "    final_score = (\n",
    "        0.35 * (100 - wer * 100) +\n",
    "        0.35 * (100 - cer * 100) +\n",
    "        0.15 * field_acc +\n",
    "        0.15 * doc_acc\n",
    "    )\n",
    "\n",
    "    print(f\"\\nOCR Model Metrics:\")\n",
    "    print(f\"Word Error Rate (WER): {wer:.4f}\")\n",
    "    print(f\"Character Error Rate (CER): {cer:.4f}\")\n",
    "    print(f\"Field Accuracy: {field_acc:.4f}\")\n",
    "    print(f\"Document Level Accuracy: {doc_acc:.4f}\")\n",
    "    print(f\"Final Score: {final_score:.4f}\")\n",
    "    print(f\"Compute Efficiency: {compute_efficiency:.6f} (1/(sec*MB))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461ca3f3",
   "metadata": {},
   "source": [
    "<H4># Evaluation for single image using trained model<H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1887b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OCR PROCESSING FOR LABELS ---\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def test_single_img (img_name, label_path, gt_txt_path, output_txt_path, ocr_model_predict, alphabet):\n",
    "    \"\"\"\n",
    "    Test a single image with the OCR model.\n",
    "    \"\"\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    ocr_results = []\n",
    "    gt_results = []\n",
    "\n",
    "    if not img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        print(f\"Skipping {img_name}: Not a valid image file\")\n",
    "    img_path = os.path.join(IMAGES_DIR, img_name)\n",
    "    base_filename = os.path.splitext(img_name)[0]\n",
    "    label_path = os.path.join(LABELS_DIR, base_filename + '.txt')\n",
    "    gt_txt_path = os.path.join(OCR_TXT_DIR, base_filename + '.json')\n",
    "    output_txt_path = os.path.join(OUTPUT_DIR, base_filename + '.txt')\n",
    "\n",
    "    bboxes = read_label_file(label_path)\n",
    "    gt_texts = read_gt_text(gt_txt_path)\n",
    "    if len(bboxes) != len(gt_texts) or not bboxes:\n",
    "        print(f\"Processing {img_name}: Mismatch between number of bounding boxes and ground truth texts\")\n",
    "\n",
    "    img_crops = []\n",
    "    valid_gt_texts = []\n",
    "    for (_, bbox), gt_text in zip(bboxes, gt_texts):\n",
    "        crop = preprocess_img(img_path, bbox, IMG_HEIGHT, IMG_WIDTH)\n",
    "        if crop is not None:\n",
    "            img_crops.append(crop)\n",
    "            valid_gt_texts.append(gt_text)\n",
    "    if not img_crops:\n",
    "        print(f\"Processing {img_name}: No valid crops found\")\n",
    "    else:\n",
    "        print(f\"Processing {img_name}: Found {len(img_crops)} valid crops\")\n",
    "        img_crops = np.array(img_crops)\n",
    "        preds = ocr_model_predict.predict(img_crops)\n",
    "        pred_texts = decode_prediction(preds, alphabet)\n",
    "\n",
    "        with open(output_txt_path, 'w', encoding='utf-8') as f:\n",
    "            for text in pred_texts:\n",
    "                f.write(text + '\\n')\n",
    "\n",
    "    ocr_results.extend(pred_texts)\n",
    "    gt_results.extend(valid_gt_texts)\n",
    "\n",
    "    print(\"Ground Truth:\")\n",
    "    for txt in gt_results:\n",
    "        print(txt)\n",
    "    print(\"\\nOCR Results:\")\n",
    "    for txt in ocr_results:\n",
    "        print(txt)\n",
    "\n",
    "    # --- METRICS ---\n",
    "\n",
    "    min_len = min(len(ocr_results), len(gt_results))\n",
    "    ocr_results = ocr_results[:min_len]\n",
    "    gt_results = gt_results[:min_len]\n",
    "\n",
    "    if ocr_results and gt_results:\n",
    "        line_acc = accuracy_score(gt_results, ocr_results)\n",
    "        def char_accuracy(y_true, y_pred):\n",
    "            correct_chars = 0\n",
    "            total_chars = 0\n",
    "            for t, p in zip(y_true, y_pred):\n",
    "                correct_chars += sum(a == b for a, b in zip(t, p))\n",
    "                total_chars += max(len(t), len(p))\n",
    "            return correct_chars / total_chars if total_chars > 0 else 1.0\n",
    "        char_acc = char_accuracy(gt_results, ocr_results)\n",
    "        print(f\"OCR Line Accuracy: {line_acc:.4f}\")\n",
    "        print(f\"OCR Character Accuracy: {char_acc:.4f}\")\n",
    "    else:\n",
    "        print(\"No OCR results to compare.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e890ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MIT_1.jpg: Mismatch between number of bounding boxes and ground truth texts\n",
      "Processing MIT_1.jpg: Found 20 valid crops\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Ground Truth:\n",
      "Dayita Bakshi\n",
      "Laksh Bakshi\n",
      "12/27/1975\n",
      "Post-Graduate\n",
      "Married\n",
      "Female\n",
      "Indian\n",
      "A+\n",
      "9 years at Dewan Ltd\n",
      "10 years at Chahal PLC\n",
      "H.No. 133, Bala Circle, Bongaigaon-379402\n",
      "H.No. 23, Chaudry Path, Nadiad-559407\n",
      "9787612803\n",
      "9351045691\n",
      "Marathi, English, Telugu, Hindi\n",
      "Kritika Brar - 7099406444\n",
      "Janaki Handa - 8634823848\n",
      "358000000000.0\n",
      "Dehradun\n",
      "6/17/2023\n",
      "\n",
      "OCR Results:\n",
      "Fed S4mas\n",
      "8/13/ydd05\n",
      "Id3\n",
      "Demian\n",
      "42t Tass\n",
      "91403470\n",
      "BhitTaa-044844\n",
      "Mas\n",
      "Mali\n",
      "Zayi ashl\n",
      "Gradian\n",
      "82662033\n",
      "O+\n",
      "Kjaria at  8/7462156\n",
      "DriraMawal\n",
      "Kali, Matta 708a4\n",
      "9D030a04\n",
      "9alr a615\n",
      "Iediale\n",
      "1/21/202025\n",
      "OCR Line Accuracy: 0.0000\n",
      "OCR Character Accuracy: 0.0319\n"
     ]
    }
   ],
   "source": [
    "TEST_IMAGE = 'MIT_1.jpg'\n",
    "LABELS_DIR = r'd:\\AI_Challenge\\DeHaDo-AI\\results6\\labels'\n",
    "IMAGES_DIR = r'D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750'\n",
    "OUTPUT_DIR = r'd:\\AI_Challenge\\DeHaDo-AI\\results6\\eval_output'\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 512\n",
    "test_single_img(TEST_IMAGE, LABELS_DIR, IMAGES_DIR, OUTPUT_DIR, ocr_model_predict, alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89be82cc",
   "metadata": {},
   "source": [
    "<H4># Evaluation for full dataset (excluding skipped images) using pytesseract<H4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4380a3",
   "metadata": {},
   "source": [
    "<H6>\n",
    "<br>Tesseract Installation For Windows\n",
    "<br>\n",
    "<br>1 - You need to have Tesseract OCR installed on your computer.\n",
    "<br>    get it from here. https://github.com/UB-Mannheim/tesseract/wiki\n",
    "<br>    Download the suitable version.\n",
    "<br>2 - Add Tesseract path to your System Environment. i.e. Edit system variables.\n",
    "<br>3 - Run pip install pytesseract and pip install tesseract\n",
    "<br>4 - Add this line to your python script every time\n",
    "<br>   pytesseract.pytesseract.tesseract_cmd = 'C:/OCR/Tesseract-OCR/tesseract.exe'  # your path may be different\n",
    "<br>5 - Run the code.\n",
    "<H6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f085746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (from pytesseract) (10.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tesseract in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (0.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages (10.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract\n",
    "!pip install tesseract\n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fedf3e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69793060a3864f38bafce351642e045a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing label files:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m         scaled_up_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(scaled_up_image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;66;03m# Perform OCR on the scaled image\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[43mpytesseract\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_up_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meng\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m         ocr_results\u001b[38;5;241m.\u001b[39mappend(text\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[0;32m     51\u001b[0m output_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUTPUT_DIR, label_file)\n",
      "File \u001b[1;32mc:\\Users\\Anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\pytesseract\\pytesseract.py:486\u001b[0m, in \u001b[0;36mimage_to_string\u001b[1;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[1;32m--> 486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBYTES\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDICT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTRING\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\pytesseract\\pytesseract.py:489\u001b[0m, in \u001b[0;36mimage_to_string.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    487\u001b[0m     Output\u001b[38;5;241m.\u001b[39mBYTES: \u001b[38;5;28;01mlambda\u001b[39;00m: run_and_get_output(\u001b[38;5;241m*\u001b[39m(args \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28;01mTrue\u001b[39;00m])),\n\u001b[0;32m    488\u001b[0m     Output\u001b[38;5;241m.\u001b[39mDICT: \u001b[38;5;28;01mlambda\u001b[39;00m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: run_and_get_output(\u001b[38;5;241m*\u001b[39margs)},\n\u001b[1;32m--> 489\u001b[0m     Output\u001b[38;5;241m.\u001b[39mSTRING: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    490\u001b[0m }[output_type]()\n",
      "File \u001b[1;32mc:\\Users\\Anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\pytesseract\\pytesseract.py:352\u001b[0m, in \u001b[0;36mrun_and_get_output\u001b[1;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save(image) \u001b[38;5;28;01mas\u001b[39;00m (temp_name, input_filename):\n\u001b[0;32m    342\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_filename\u001b[39m\u001b[38;5;124m'\u001b[39m: input_filename,\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m: temp_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[0;32m    350\u001b[0m     }\n\u001b[1;32m--> 352\u001b[0m     run_tesseract(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_output(\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextsep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    355\u001b[0m         return_bytes,\n\u001b[0;32m    356\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\pytesseract\\pytesseract.py:282\u001b[0m, in \u001b[0;36mrun_tesseract\u001b[1;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TesseractNotFoundError()\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m timeout_manager(proc, timeout) \u001b[38;5;28;01mas\u001b[39;00m error_string:\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mreturncode:\n\u001b[0;32m    284\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TesseractError(proc\u001b[38;5;241m.\u001b[39mreturncode, get_errors(error_string))\n",
      "File \u001b[1;32mc:\\Users\\Anand\\miniconda3\\envs\\tf_gpu\\lib\\contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Anand\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\pytesseract\\pytesseract.py:144\u001b[0m, in \u001b[0;36mtimeout_manager\u001b[1;34m(proc, seconds)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m seconds:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Anand\\miniconda3\\envs\\tf_gpu\\lib\\subprocess.py:1134\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Anand\\miniconda3\\envs\\tf_gpu\\lib\\subprocess.py:1524\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1520\u001b[0m \u001b[38;5;66;03m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;66;03m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1524\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remaining_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32mc:\\Users\\Anand\\miniconda3\\envs\\tf_gpu\\lib\\threading.py:1060\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1060\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Anand\\miniconda3\\envs\\tf_gpu\\lib\\threading.py:1080\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1079\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1080\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1081\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- OCR PROCESSING FOR LABELS ---\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "LABELS_DIR = r'd:\\AI_Challenge\\DeHaDo-AI\\results4\\labels'\n",
    "IMAGES_DIR = r'D:\\AI_Challenge\\DeHaDo-AI\\DEHADO-AI_TRAINING_DATASET\\IMAGES_750'\n",
    "OUTPUT_DIR = r'd:\\AI_Challenge\\DeHaDo-AI\\results4\\tesseract_output'\n",
    "pytesseract.pytesseract.tesseract_cmd = r'D:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Update this path if needed\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "for label_file in tqdm(os.listdir(LABELS_DIR), desc=\"Processing label files\"):\n",
    "    if not label_file.endswith('.txt'):\n",
    "        continue\n",
    "    label_path = os.path.join(LABELS_DIR, label_file)\n",
    "    image_name = os.path.splitext(label_file)[0] + '.jpg'\n",
    "    image_path = os.path.join(IMAGES_DIR, image_name)\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image not found for {label_file}\")\n",
    "        continue\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    ocr_results = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 6:\n",
    "                continue\n",
    "            x1, y1, x2, y2 = map(int, parts[3:7])\n",
    "            cropped = image.crop((x1, y1, x2, y2))\n",
    "\n",
    "            # Define scaling factors (e.g., 2 for doubling the size)\n",
    "            scale_x = .5\n",
    "            scale_y = .5\n",
    "            # Resize the image using cv2.resize()\n",
    "            # You can specify interpolation methods for better quality\n",
    "            # INTER_LINEAR is good for enlarging, INTER_CUBIC is slower but higher quality\n",
    "            cropped = np.array(cropped)\n",
    "            scaled_up_image = cv2.resize(cropped, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)\n",
    "            # Convert the scaled image to a format suitable for OCR\n",
    "            scaled_up_image = cv2.cvtColor(scaled_up_image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Perform OCR on the scaled image\n",
    "            text = pytesseract.image_to_string(scaled_up_image, lang='eng')\n",
    "            ocr_results.append(text.strip())\n",
    "\n",
    "    output_file = os.path.join(OUTPUT_DIR, label_file)\n",
    "    with open(output_file, 'w', encoding='utf-8') as out_f:\n",
    "        for text in ocr_results:\n",
    "            out_f.write(text + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
